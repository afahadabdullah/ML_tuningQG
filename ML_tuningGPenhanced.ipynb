{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a60f609-e1e2-4874-bb5d-a8e95600ec76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/panfs/ccds02/nobackup/people/afahad/pkgs/qg/lib/python3.10/site-packages/scipy/stats/_qmc.py:993: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  sample = self._random(n, workers=workers)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded high-res: 512x256\n",
      "\n",
      "✓ Starting new optimization (seed=42)\n",
      "\n",
      "======================================================================\n",
      "ENHANCED GP: WARM-START + 2-LEVEL MULTI-FIDELITY + VISUALIZATION\n",
      "======================================================================\n",
      "Features:\n",
      "  ✓ Warm-start from reference parameters\n",
      "  ✓ 8-model weighted ensemble\n",
      "  ✓ Local penalization (space coverage)\n",
      "  ✓ 2-level multi-fidelity strategy:\n",
      "    • Iterations 0-40:  30-day runs (fast exploration, ~6x speedup)\n",
      "    • Iterations 40+:   180-day runs (full precision)\n",
      "  ✓ Adaptive time windows for fair comparison:\n",
      "    • 30-day runs: compare entire simulation (days 0-30)\n",
      "    • 180-day runs: compare last 30 days (equilibrated)\n",
      "  ✓ Fidelity-aware baseline tracking\n",
      "  ✓ Thompson sampling (10% exploration)\n",
      "  ✓ Anti-stagnation (auto-restart)\n",
      "  ✓ 3-way comparison visualization\n",
      "  Max iterations: 80\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PHASE 1: WARM-START INITIALIZATION (seed=42)\n",
      "======================================================================\n",
      "\u001b[93m  ⚠ Clipped eddy_diffusivity: 5.000000e-03 → 1.000000e+03 (bounds: [1.000000e+03, 1.000000e+05])\u001b[0m\n",
      "\u001b[96m  ✓ Including reference parameters as warm-start\u001b[0m\n",
      "\u001b[96m  ✓ Generated 18 diverse initial samples (base_seed=42)\u001b[0m\n",
      "\n",
      "[Initial 1/18]\u001b[93m\u001b[1m★  DEFAULT PARAMETERS\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.000000e-01\n",
      "  drag_scale: 5.000000e-01\n",
      "  eddy_diffusivity: 1.000000e+03\n",
      "  smagorinsky_coeff: 1.500000e-02\n",
      "  energy_correction: -2.000000e-03\n",
      "  enstrophy_correction: 3.000000e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5\n",
      "  drag_scale: 0.5\n",
      "  eddy_diffusivity: 1000.0\n",
      "  smagorinsky_coeff: 0.015\n",
      "  energy_correction: -0.002\n",
      "  enstrophy_correction: 3e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 324.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.206844\u001b[0m\n",
      "\u001b[96m  → Baseline loss at FAST (30d): 0.206844\u001b[0m\n",
      "\u001b[93m\u001b[1m★ BASELINE SET: \u001b[92m0.206844\u001b[0m\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 2/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 6.774869e-01\n",
      "  drag_scale: 1.989922e+00\n",
      "  eddy_diffusivity: 1.337498e+03\n",
      "  smagorinsky_coeff: 1.544568e-02\n",
      "  energy_correction: 7.164037e-03\n",
      "  enstrophy_correction: 3.650586e-07\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.6774869474036614\n",
      "  drag_scale: 1.9899222664208966\n",
      "  eddy_diffusivity: 1337.4975968397164\n",
      "  smagorinsky_coeff: 0.015445681389968675\n",
      "  energy_correction: 0.007164036771964243\n",
      "  enstrophy_correction: 3.650586104933196e-07\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 326.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.673229\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 3/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.867484e+00\n",
      "  drag_scale: 2.789877e+00\n",
      "  eddy_diffusivity: 3.233648e+03\n",
      "  smagorinsky_coeff: 7.139004e-02\n",
      "  energy_correction: -3.505385e-03\n",
      "  enstrophy_correction: 2.074253e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8674844172548255\n",
      "  drag_scale: 2.789876932368572\n",
      "  eddy_diffusivity: 3233.6479744596813\n",
      "  smagorinsky_coeff: 0.0713900437744224\n",
      "  energy_correction: -0.0035053850089315775\n",
      "  enstrophy_correction: 2.074252999579448e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 333.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.369350\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 4/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.187129e+00\n",
      "  drag_scale: 1.189170e+00\n",
      "  eddy_diffusivity: 8.368006e+04\n",
      "  smagorinsky_coeff: 2.928210e-01\n",
      "  energy_correction: -1.940787e-03\n",
      "  enstrophy_correction: 3.873865e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.187129359069229\n",
      "  drag_scale: 1.189169747498674\n",
      "  eddy_diffusivity: 83680.05682894182\n",
      "  smagorinsky_coeff: 0.2928210435308442\n",
      "  energy_correction: -0.0019407868471381755\n",
      "  enstrophy_correction: 3.873865342265237e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 333.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.197949\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.197949\u001b[0m (+4.3% vs baseline @ FAST (30d))\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 5/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.967305e+00\n",
      "  drag_scale: 7.023465e-01\n",
      "  eddy_diffusivity: 3.503338e+03\n",
      "  smagorinsky_coeff: 1.758723e-01\n",
      "  energy_correction: 3.084264e-03\n",
      "  enstrophy_correction: 9.798582e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.9673046215098715\n",
      "  drag_scale: 0.7023465319636162\n",
      "  eddy_diffusivity: 3503.338117376563\n",
      "  smagorinsky_coeff: 0.17587231420125152\n",
      "  energy_correction: 0.0030842637295755183\n",
      "  enstrophy_correction: 9.798582080633145e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 335.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.315582\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 6/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.626418e+00\n",
      "  drag_scale: 1.105948e+00\n",
      "  eddy_diffusivity: 6.756305e+03\n",
      "  smagorinsky_coeff: 1.245367e-01\n",
      "  energy_correction: -5.613489e-03\n",
      "  enstrophy_correction: 4.545840e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.6264182870871982\n",
      "  drag_scale: 1.105948305626048\n",
      "  eddy_diffusivity: 6756.305107400128\n",
      "  smagorinsky_coeff: 0.12453669629461109\n",
      "  energy_correction: -0.005613488750453532\n",
      "  enstrophy_correction: 4.545840188712558e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 335.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.502367\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 7/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 4.598942e+00\n",
      "  drag_scale: 2.378106e+00\n",
      "  eddy_diffusivity: 1.438719e+04\n",
      "  smagorinsky_coeff: 2.556906e-01\n",
      "  energy_correction: 8.954058e-03\n",
      "  enstrophy_correction: 9.458294e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 4.598942389832971\n",
      "  drag_scale: 2.3781056057938317\n",
      "  eddy_diffusivity: 14387.190279374552\n",
      "  smagorinsky_coeff: 0.2556906295110365\n",
      "  energy_correction: 0.008954057752096017\n",
      "  enstrophy_correction: 9.458294099825533e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 334.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.853602\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 8/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.780536e+00\n",
      "  drag_scale: 2.179606e+00\n",
      "  eddy_diffusivity: 2.975981e+04\n",
      "  smagorinsky_coeff: 1.188568e-01\n",
      "  energy_correction: -8.634107e-03\n",
      "  enstrophy_correction: 1.477714e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.780535720455024\n",
      "  drag_scale: 2.1796063074039513\n",
      "  eddy_diffusivity: 29759.810107906498\n",
      "  smagorinsky_coeff: 0.11885677573125618\n",
      "  energy_correction: -0.008634107427173528\n",
      "  enstrophy_correction: 1.4777137517127707e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 333.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.770458\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 9/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.304892e+00\n",
      "  drag_scale: 1.629021e+00\n",
      "  eddy_diffusivity: 3.442151e+04\n",
      "  smagorinsky_coeff: 1.927324e-01\n",
      "  energy_correction: 7.924900e-04\n",
      "  enstrophy_correction: 2.365151e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.3048918970787171\n",
      "  drag_scale: 1.62902051103486\n",
      "  eddy_diffusivity: 34421.50581039572\n",
      "  smagorinsky_coeff: 0.19273236605371616\n",
      "  energy_correction: 0.0007924900122641687\n",
      "  enstrophy_correction: 2.365150620663817e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 336.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.142151\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.142151\u001b[0m (+31.3% vs baseline @ FAST (30d))\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 10/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.148196e+00\n",
      "  drag_scale: 2.178240e+00\n",
      "  eddy_diffusivity: 7.461857e+03\n",
      "  smagorinsky_coeff: 7.722090e-02\n",
      "  energy_correction: 3.058761e-03\n",
      "  enstrophy_correction: 7.512995e-07\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.148195870288128\n",
      "  drag_scale: 2.1782397526371\n",
      "  eddy_diffusivity: 7461.856571746482\n",
      "  smagorinsky_coeff: 0.07722089570774614\n",
      "  energy_correction: 0.003058761176270146\n",
      "  enstrophy_correction: 7.512995148282372e-07\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 331.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.601855\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 11/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.920133e+00\n",
      "  drag_scale: 9.989707e-01\n",
      "  eddy_diffusivity: 4.583889e+04\n",
      "  smagorinsky_coeff: 2.448067e-01\n",
      "  energy_correction: -1.731248e-03\n",
      "  enstrophy_correction: 7.163147e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.920133499005554\n",
      "  drag_scale: 0.998970657979364\n",
      "  eddy_diffusivity: 45838.890271949225\n",
      "  smagorinsky_coeff: 0.24480670588954595\n",
      "  energy_correction: -0.0017312475392629798\n",
      "  enstrophy_correction: 7.163146548200682e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 335.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.172113\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 12/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 4.078492e+00\n",
      "  drag_scale: 2.401404e+00\n",
      "  eddy_diffusivity: 1.066812e+03\n",
      "  smagorinsky_coeff: 1.186592e-01\n",
      "  energy_correction: -5.017058e-03\n",
      "  enstrophy_correction: 4.232747e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 4.07849206767501\n",
      "  drag_scale: 2.401403632371049\n",
      "  eddy_diffusivity: 1066.8116345493222\n",
      "  smagorinsky_coeff: 0.1186591901292304\n",
      "  energy_correction: -0.005017058123727063\n",
      "  enstrophy_correction: 4.232746556990272e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 328.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.463595\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 13/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.033674e+00\n",
      "  drag_scale: 1.340064e+00\n",
      "  eddy_diffusivity: 2.865982e+04\n",
      "  smagorinsky_coeff: 1.685150e-01\n",
      "  energy_correction: 7.864718e-03\n",
      "  enstrophy_correction: 9.029302e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.0336744163427602\n",
      "  drag_scale: 1.3400636320346062\n",
      "  eddy_diffusivity: 28659.82328912357\n",
      "  smagorinsky_coeff: 0.16851500471433478\n",
      "  energy_correction: 0.007864717919407673\n",
      "  enstrophy_correction: 9.029301586998585e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 334.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.685881\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 14/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.324935e+00\n",
      "  drag_scale: 3.000000e+00\n",
      "  eddy_diffusivity: 9.117700e+04\n",
      "  smagorinsky_coeff: 2.075527e-01\n",
      "  energy_correction: 7.308711e-03\n",
      "  enstrophy_correction: 2.177598e-07\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.3249353765128506\n",
      "  drag_scale: 3.0\n",
      "  eddy_diffusivity: 91177.00098646595\n",
      "  smagorinsky_coeff: 0.20755266616222615\n",
      "  energy_correction: 0.007308710682515604\n",
      "  enstrophy_correction: 2.1775980466485145e-07\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 327.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.642898\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 15/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 4.779699e+00\n",
      "  drag_scale: 1.540167e+00\n",
      "  eddy_diffusivity: 3.503542e+03\n",
      "  smagorinsky_coeff: 6.788247e-02\n",
      "  energy_correction: -8.586745e-03\n",
      "  enstrophy_correction: 1.486931e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 4.77969927781104\n",
      "  drag_scale: 1.5401670383792347\n",
      "  eddy_diffusivity: 3503.5419364209883\n",
      "  smagorinsky_coeff: 0.06788246923723039\n",
      "  energy_correction: -0.008586744608135737\n",
      "  enstrophy_correction: 1.486931432307541e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 333.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.759859\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 16/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.902973e+00\n",
      "  drag_scale: 1.901126e+00\n",
      "  eddy_diffusivity: 1.437635e+04\n",
      "  smagorinsky_coeff: 2.832548e-01\n",
      "  energy_correction: -4.394814e-03\n",
      "  enstrophy_correction: 1.059712e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.9029734123341333\n",
      "  drag_scale: 1.901125604969048\n",
      "  eddy_diffusivity: 14376.345232540336\n",
      "  smagorinsky_coeff: 0.28325484761388675\n",
      "  energy_correction: -0.004394814169035547\n",
      "  enstrophy_correction: 1.0597121347382134e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 328.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.392308\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 17/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.579578e+00\n",
      "  drag_scale: 5.095629e-01\n",
      "  eddy_diffusivity: 1.945003e+03\n",
      "  smagorinsky_coeff: 3.801838e-02\n",
      "  energy_correction: 1.406071e-03\n",
      "  enstrophy_correction: 1.227741e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.5795778041372457\n",
      "  drag_scale: 0.5095629279405485\n",
      "  eddy_diffusivity: 1945.0029366827066\n",
      "  smagorinsky_coeff: 0.03801837927206248\n",
      "  energy_correction: 0.0014060705589659765\n",
      "  enstrophy_correction: 1.2277408648686915e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 334.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.170696\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "[Initial 18/18]\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.635420e+00\n",
      "  drag_scale: 2.586237e+00\n",
      "  eddy_diffusivity: 1.567594e+04\n",
      "  smagorinsky_coeff: 1.107746e-01\n",
      "  energy_correction: -1.186002e-03\n",
      "  enstrophy_correction: 4.215350e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.6354202218763074\n",
      "  drag_scale: 2.5862367606847836\n",
      "  eddy_diffusivity: 15675.943387028776\n",
      "  smagorinsky_coeff: 0.11077461168242138\n",
      "  energy_correction: -0.001186001951420419\n",
      "  enstrophy_correction: 4.215350209728931e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 327.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.166733\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: BAYESIAN OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 19/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m18\u001b[0m/18\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 45.730 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 39.462 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.639 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.361 (\u001b[96mmed\u001b[0m)\n",
      "    5. drag_scale: 0.195 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.028 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.305862e+00\n",
      "  drag_scale: 1.931225e+00\n",
      "  eddy_diffusivity: 6.090681e+04\n",
      "  smagorinsky_coeff: 1.736817e-01\n",
      "  energy_correction: 1.399949e-03\n",
      "  enstrophy_correction: 2.926279e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.3058624991466936\n",
      "  drag_scale: 1.931224647376078\n",
      "  eddy_diffusivity: 60906.81314541288\n",
      "  smagorinsky_coeff: 0.17368173193740388\n",
      "  energy_correction: 0.0013999490940309126\n",
      "  enstrophy_correction: 2.9262786993781853e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 339.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.196028\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m19\u001b[0m/19\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.142151\u001b[0m \u001b[96m(discovered at iteration 9)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+31.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 20/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m19\u001b[0m/19\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 42.461 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 36.477 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.721 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.277 (\u001b[96mmed\u001b[0m)\n",
      "    5. drag_scale: 0.039 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.034 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.177667e+00\n",
      "  drag_scale: 2.083046e+00\n",
      "  eddy_diffusivity: 2.178606e+04\n",
      "  smagorinsky_coeff: 1.277943e-01\n",
      "  energy_correction: -2.303217e-04\n",
      "  enstrophy_correction: 1.145316e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.1776667891598667\n",
      "  drag_scale: 2.083046114356864\n",
      "  eddy_diffusivity: 21786.06313948121\n",
      "  smagorinsky_coeff: 0.12779426291603077\n",
      "  energy_correction: -0.00023032172071275545\n",
      "  enstrophy_correction: 1.1453160592046641e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 332.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.149299\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m20\u001b[0m/20\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.142151\u001b[0m \u001b[96m(discovered at iteration 9)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+31.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 21/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m20\u001b[0m/20\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 39.503 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 29.236 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. smagorinsky_coeff: 1.245 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.609 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.145 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.070 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.874236e+00\n",
      "  drag_scale: 2.049755e+00\n",
      "  eddy_diffusivity: 1.622440e+04\n",
      "  smagorinsky_coeff: 2.306922e-01\n",
      "  energy_correction: -7.977439e-05\n",
      "  enstrophy_correction: 1.045073e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.874236333129936\n",
      "  drag_scale: 2.049754804876165\n",
      "  eddy_diffusivity: 16224.401829557546\n",
      "  smagorinsky_coeff: 0.23069220816854413\n",
      "  energy_correction: -7.977439042991356e-05\n",
      "  enstrophy_correction: 1.0450734468406742e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 336.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.136504\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.136504\u001b[0m (+34.0% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m21\u001b[0m/21\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.136504\u001b[0m \u001b[96m(discovered at iteration 21)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+34.0%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 22/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m21\u001b[0m/21\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 71.282 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 60.762 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. smagorinsky_coeff: 0.930 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.853 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.230 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.135 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.186507e+00\n",
      "  drag_scale: 2.123928e+00\n",
      "  eddy_diffusivity: 4.750342e+04\n",
      "  smagorinsky_coeff: 2.785681e-01\n",
      "  energy_correction: 5.731146e-05\n",
      "  enstrophy_correction: 2.431525e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1865065190180002\n",
      "  drag_scale: 2.1239277791800806\n",
      "  eddy_diffusivity: 47503.41972005649\n",
      "  smagorinsky_coeff: 0.2785681221707918\n",
      "  energy_correction: 5.731145857585003e-05\n",
      "  enstrophy_correction: 2.4315252769666414e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 331.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.128670\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.128670\u001b[0m (+37.8% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m22\u001b[0m/22\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.128670\u001b[0m \u001b[96m(discovered at iteration 22)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+37.8%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 23/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m22\u001b[0m/22\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 50.949 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 46.755 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. drag_scale: 1.138 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.840 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.062 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.043 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.875742e+00\n",
      "  drag_scale: 2.670656e+00\n",
      "  eddy_diffusivity: 9.683081e+04\n",
      "  smagorinsky_coeff: 2.070798e-01\n",
      "  energy_correction: 9.577767e-04\n",
      "  enstrophy_correction: 1.949867e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.875742043518606\n",
      "  drag_scale: 2.6706563595123445\n",
      "  eddy_diffusivity: 96830.81174975389\n",
      "  smagorinsky_coeff: 0.20707984274458677\n",
      "  energy_correction: 0.000957776659092198\n",
      "  enstrophy_correction: 1.9498672045548673e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 335.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.205515\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m23\u001b[0m/23\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.128670\u001b[0m \u001b[96m(discovered at iteration 22)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+37.8%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 24/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m23\u001b[0m/23\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 58.218 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 5.068 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. smagorinsky_coeff: 1.417 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. enstrophy_correction: 0.583 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.044 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.044 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.706658e+00\n",
      "  drag_scale: 1.535865e+00\n",
      "  eddy_diffusivity: 6.101690e+04\n",
      "  smagorinsky_coeff: 2.910795e-01\n",
      "  energy_correction: 2.804993e-04\n",
      "  enstrophy_correction: 4.914367e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.7066576907425617\n",
      "  drag_scale: 1.535864966577119\n",
      "  eddy_diffusivity: 61016.89535038263\n",
      "  smagorinsky_coeff: 0.29107945279179603\n",
      "  energy_correction: 0.0002804992883065349\n",
      "  enstrophy_correction: 4.91436650418167e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 338.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.116605\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.116605\u001b[0m (+43.6% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m24\u001b[0m/24\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.116605\u001b[0m \u001b[96m(discovered at iteration 24)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+43.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 25/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m24\u001b[0m/24\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 52.231 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 4.750 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. smagorinsky_coeff: 1.222 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. enstrophy_correction: 0.754 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.062 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.038 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.080399e+00\n",
      "  drag_scale: 9.478022e-01\n",
      "  eddy_diffusivity: 6.513051e+04\n",
      "  smagorinsky_coeff: 2.922368e-01\n",
      "  energy_correction: 5.036871e-04\n",
      "  enstrophy_correction: 9.932448e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.080399083979461\n",
      "  drag_scale: 0.9478021539741572\n",
      "  eddy_diffusivity: 65130.51046226019\n",
      "  smagorinsky_coeff: 0.2922368285264031\n",
      "  energy_correction: 0.0005036871180372198\n",
      "  enstrophy_correction: 9.93244790265582e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 336.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.113783\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.113783\u001b[0m (+45.0% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m25\u001b[0m/25\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.113783\u001b[0m \u001b[96m(discovered at iteration 25)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+45.0%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 26/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m25\u001b[0m/25\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 59.939 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 5.013 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. smagorinsky_coeff: 1.334 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. enstrophy_correction: 0.657 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.099 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.033 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.812457e+00\n",
      "  drag_scale: 6.336020e-01\n",
      "  eddy_diffusivity: 4.305262e+04\n",
      "  smagorinsky_coeff: 2.996220e-01\n",
      "  energy_correction: 1.575898e-03\n",
      "  enstrophy_correction: 1.515831e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.8124571155456215\n",
      "  drag_scale: 0.6336019634826842\n",
      "  eddy_diffusivity: 43052.61741254654\n",
      "  smagorinsky_coeff: 0.29962198267848833\n",
      "  energy_correction: 0.001575898423734375\n",
      "  enstrophy_correction: 1.5158307764452406e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 333.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.172901\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m26\u001b[0m/26\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.113783\u001b[0m \u001b[96m(discovered at iteration 25)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+45.0%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 27/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m26\u001b[0m/26\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 115.550 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 11.830 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.615 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. smagorinsky_coeff: 1.008 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.621 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.278 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.486046e+00\n",
      "  drag_scale: 5.063869e-01\n",
      "  eddy_diffusivity: 6.231108e+04\n",
      "  smagorinsky_coeff: 2.888963e-01\n",
      "  energy_correction: -1.460320e-05\n",
      "  enstrophy_correction: 5.620605e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.4860463165390674\n",
      "  drag_scale: 0.5063868723511874\n",
      "  eddy_diffusivity: 62311.076166799045\n",
      "  smagorinsky_coeff: 0.28889625840441613\n",
      "  energy_correction: -1.4603198005440354e-05\n",
      "  enstrophy_correction: 5.6206046760584145e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.121305\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m27\u001b[0m/27\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.113783\u001b[0m \u001b[96m(discovered at iteration 25)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+45.0%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 28/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m27\u001b[0m/27\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 66.209 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 6.647 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 0.798 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. enstrophy_correction: 0.729 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.483 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.169 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.486001e+00\n",
      "  drag_scale: 1.013501e+00\n",
      "  eddy_diffusivity: 8.146918e+04\n",
      "  smagorinsky_coeff: 2.937418e-01\n",
      "  energy_correction: -6.093275e-04\n",
      "  enstrophy_correction: 2.542623e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.4860006346879717\n",
      "  drag_scale: 1.0135012937687446\n",
      "  eddy_diffusivity: 81469.18269843765\n",
      "  smagorinsky_coeff: 0.29374179278154516\n",
      "  energy_correction: -0.0006093274517863251\n",
      "  enstrophy_correction: 2.5426230082655375e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 332.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.112137\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.112137\u001b[0m (+45.8% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m28\u001b[0m/28\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.112137\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+45.8%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 29/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m28\u001b[0m/28\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 70.388 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 8.020 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 0.846 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. smagorinsky_coeff: 0.674 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.570 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.159 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 8.613754e-01\n",
      "  drag_scale: 9.812951e-01\n",
      "  eddy_diffusivity: 7.369861e+04\n",
      "  smagorinsky_coeff: 2.902039e-01\n",
      "  energy_correction: 1.733352e-04\n",
      "  enstrophy_correction: 3.534034e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.8613754192074271\n",
      "  drag_scale: 0.9812950585580529\n",
      "  eddy_diffusivity: 73698.61430517772\n",
      "  smagorinsky_coeff: 0.290203913855968\n",
      "  energy_correction: 0.0001733351814089141\n",
      "  enstrophy_correction: 3.534034211850364e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 336.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.104961\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.104961\u001b[0m (+49.3% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m29\u001b[0m/29\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.104961\u001b[0m \u001b[96m(discovered at iteration 29)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+49.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 30/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m29\u001b[0m/29\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 83.720 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 11.937 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 0.898 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. smagorinsky_coeff: 0.825 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.364 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.107 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 9.815503e-01\n",
      "  drag_scale: 5.748186e-01\n",
      "  eddy_diffusivity: 6.768695e+04\n",
      "  smagorinsky_coeff: 2.338674e-01\n",
      "  energy_correction: -7.145477e-04\n",
      "  enstrophy_correction: 1.260900e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.9815502940530842\n",
      "  drag_scale: 0.5748185959634905\n",
      "  eddy_diffusivity: 67686.94766673083\n",
      "  smagorinsky_coeff: 0.23386735068666697\n",
      "  energy_correction: -0.0007145476957597929\n",
      "  enstrophy_correction: 1.2609001923475163e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 331.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.128748\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m30\u001b[0m/30\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.104961\u001b[0m \u001b[96m(discovered at iteration 29)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+49.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 31/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m30\u001b[0m/30\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 70.767 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 10.704 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.060 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. smagorinsky_coeff: 0.685 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.312 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.169 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.169971e+00\n",
      "  drag_scale: 1.019683e+00\n",
      "  eddy_diffusivity: 8.707923e+04\n",
      "  smagorinsky_coeff: 2.729278e-01\n",
      "  energy_correction: -1.134294e-04\n",
      "  enstrophy_correction: 1.970435e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1699710941490764\n",
      "  drag_scale: 1.019682840534148\n",
      "  eddy_diffusivity: 87079.23436063783\n",
      "  smagorinsky_coeff: 0.2729278219039197\n",
      "  energy_correction: -0.00011342942433887476\n",
      "  enstrophy_correction: 1.9704353058459044e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.102854\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.102854\u001b[0m (+50.3% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m31\u001b[0m/31\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 32/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m31\u001b[0m/31\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 53.610 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 8.872 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.272 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. smagorinsky_coeff: 0.442 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.322 (\u001b[96mmed\u001b[0m)\n",
      "    6. viscosity_scale: 0.106 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.195093e+00\n",
      "  drag_scale: 1.475626e+00\n",
      "  eddy_diffusivity: 4.573155e+04\n",
      "  smagorinsky_coeff: 2.891348e-01\n",
      "  energy_correction: -3.547298e-04\n",
      "  enstrophy_correction: 1.428032e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1950931926585595\n",
      "  drag_scale: 1.4756260190431467\n",
      "  eddy_diffusivity: 45731.54567490188\n",
      "  smagorinsky_coeff: 0.28913483446131427\n",
      "  energy_correction: -0.00035472978446551146\n",
      "  enstrophy_correction: 1.4280321687245809e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 338.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.106295\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m32\u001b[0m/32\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 33/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m32\u001b[0m/32\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 30.285 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 4.255 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.244 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. viscosity_scale: 0.600 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.171 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.161 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.927870e-01\n",
      "  drag_scale: 1.335594e+00\n",
      "  eddy_diffusivity: 6.300139e+04\n",
      "  smagorinsky_coeff: 2.281842e-01\n",
      "  energy_correction: -4.792693e-05\n",
      "  enstrophy_correction: 2.948464e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5927869595786266\n",
      "  drag_scale: 1.335593552245502\n",
      "  eddy_diffusivity: 63001.39472812825\n",
      "  smagorinsky_coeff: 0.22818415110052112\n",
      "  energy_correction: -4.7926927403603783e-05\n",
      "  enstrophy_correction: 2.948463671775738e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 338.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.105528\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m33\u001b[0m/33\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 34/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m33\u001b[0m/33\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 28.020 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 4.206 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.688 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.267 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.080 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.062 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.000446e+00\n",
      "  drag_scale: 9.480168e-01\n",
      "  eddy_diffusivity: 4.436844e+04\n",
      "  smagorinsky_coeff: 2.775558e-01\n",
      "  energy_correction: 1.009351e-04\n",
      "  enstrophy_correction: 1.665572e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.0004456101141725\n",
      "  drag_scale: 0.9480167563445291\n",
      "  eddy_diffusivity: 44368.43931348813\n",
      "  smagorinsky_coeff: 0.2775558481073996\n",
      "  energy_correction: 0.00010093508071425811\n",
      "  enstrophy_correction: 1.6655722381727902e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 340.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.110578\u001b[0m\n",
      "  → Trust region shrunk to 0.25\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m34\u001b[0m/34\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 35/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m34\u001b[0m/34\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 30.455 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 3.805 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.440 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.366 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.257 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.133 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.094038e+00\n",
      "  drag_scale: 1.327338e+00\n",
      "  eddy_diffusivity: 8.309359e+04\n",
      "  smagorinsky_coeff: 2.669057e-01\n",
      "  energy_correction: -1.050516e-03\n",
      "  enstrophy_correction: 5.775676e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.0940377072129073\n",
      "  drag_scale: 1.327338003076541\n",
      "  eddy_diffusivity: 83093.5904394918\n",
      "  smagorinsky_coeff: 0.26690567818877287\n",
      "  energy_correction: -0.0010505162204526904\n",
      "  enstrophy_correction: 5.775675568977226e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.129812\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m35\u001b[0m/35\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m4/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 36/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m35\u001b[0m/35\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 23.824 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 3.436 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.626 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.363 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.033 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.029 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.119690e+00\n",
      "  drag_scale: 1.199653e+00\n",
      "  eddy_diffusivity: 7.652003e+04\n",
      "  smagorinsky_coeff: 2.358820e-01\n",
      "  energy_correction: -3.928672e-04\n",
      "  enstrophy_correction: 3.150365e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1196900717085292\n",
      "  drag_scale: 1.1996525400258933\n",
      "  eddy_diffusivity: 76520.03212149926\n",
      "  smagorinsky_coeff: 0.23588202956453042\n",
      "  energy_correction: -0.0003928671744326071\n",
      "  enstrophy_correction: 3.15036453784533e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.105545\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m36\u001b[0m/36\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m5/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 37/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m36\u001b[0m/36\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 22.009 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 3.021 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.848 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.363 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.026 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.024 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.515695e-01\n",
      "  drag_scale: 1.188365e+00\n",
      "  eddy_diffusivity: 9.894969e+04\n",
      "  smagorinsky_coeff: 2.380282e-01\n",
      "  energy_correction: 2.028682e-04\n",
      "  enstrophy_correction: 5.495374e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7515694611448548\n",
      "  drag_scale: 1.188365493949553\n",
      "  eddy_diffusivity: 98949.68957076341\n",
      "  smagorinsky_coeff: 0.23802816321168424\n",
      "  energy_correction: 0.0002028682420043195\n",
      "  enstrophy_correction: 5.495374327141122e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.105375\u001b[0m\n",
      "  → Trust region shrunk to 0.12\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m37\u001b[0m/37\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m6/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 38/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m37\u001b[0m/37\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 22.819 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 2.896 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.898 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.359 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.024 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.014 (low)\n",
      "  Trust region: \u001b[96m0.12\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.039469e+00\n",
      "  drag_scale: 8.674048e-01\n",
      "  eddy_diffusivity: 9.467739e+04\n",
      "  smagorinsky_coeff: 2.680160e-01\n",
      "  energy_correction: -3.101667e-04\n",
      "  enstrophy_correction: 1.647837e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.0394690822915353\n",
      "  drag_scale: 0.8674047886699845\n",
      "  eddy_diffusivity: 94677.38820609183\n",
      "  smagorinsky_coeff: 0.2680160142859312\n",
      "  energy_correction: -0.0003101666529198351\n",
      "  enstrophy_correction: 1.6478374709239174e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.107555\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m38\u001b[0m/38\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m7/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 39/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m38\u001b[0m/38\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 19.434 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 2.512 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 2.085 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.313 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.020 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.011 (low)\n",
      "  Trust region: \u001b[96m0.12\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 9.881920e-01\n",
      "  drag_scale: 8.719437e-01\n",
      "  eddy_diffusivity: 9.997087e+04\n",
      "  smagorinsky_coeff: 2.841070e-01\n",
      "  energy_correction: 8.971336e-04\n",
      "  enstrophy_correction: 1.801158e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.988191981344885\n",
      "  drag_scale: 0.8719437104328456\n",
      "  eddy_diffusivity: 99970.87251159808\n",
      "  smagorinsky_coeff: 0.2841070477256752\n",
      "  energy_correction: 0.0008971335642282904\n",
      "  enstrophy_correction: 1.8011576152564448e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 337.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.131383\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m39\u001b[0m/39\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102854\u001b[0m \u001b[96m(discovered at iteration 31)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.3%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m8/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 40/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m39\u001b[0m/39\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 25.379 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. drag_scale: 3.356 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. enstrophy_correction: 1.613 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. eddy_diffusivity: 0.387 (\u001b[96mmed\u001b[0m)\n",
      "    5. viscosity_scale: 0.060 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.013 (low)\n",
      "  Trust region: \u001b[96m0.12\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.424829e+00\n",
      "  drag_scale: 1.140379e+00\n",
      "  eddy_diffusivity: 9.492156e+04\n",
      "  smagorinsky_coeff: 2.895712e-01\n",
      "  energy_correction: -2.516649e-05\n",
      "  enstrophy_correction: 1.935362e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.424829139580515\n",
      "  drag_scale: 1.1403791825872298\n",
      "  eddy_diffusivity: 94921.55563078646\n",
      "  smagorinsky_coeff: 0.28957118109467156\n",
      "  energy_correction: -2.5166489019609606e-05\n",
      "  enstrophy_correction: 1.935361881463363e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 328.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.102669\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.102669\u001b[0m (+50.4% vs baseline @ FAST (30d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m40\u001b[0m/40\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102669\u001b[0m \u001b[96m(discovered at iteration 40)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 41/80\u001b[0m\n",
      "======================================================================\n",
      "\u001b[91m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[91m⚠ FIDELITY TRANSITION: FAST (30d) → FULL (180d)\u001b[0m\n",
      "\u001b[91m======================================================================\u001b[0m\n",
      "\u001b[96m→ Re-evaluating BASELINE at FULL (180d) fidelity...\u001b[0m\n",
      "\u001b[93m  ⚠ Clipped eddy_diffusivity: 5.000000e-03 → 1.000000e+03 (bounds: [1.000000e+03, 1.000000e+05])\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.000000e-01\n",
      "  drag_scale: 5.000000e-01\n",
      "  eddy_diffusivity: 1.000000e+03\n",
      "  smagorinsky_coeff: 1.500000e-02\n",
      "  energy_correction: -2.000000e-03\n",
      "  enstrophy_correction: 3.000000e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5\n",
      "  drag_scale: 0.5\n",
      "  eddy_diffusivity: 1000.0\n",
      "  smagorinsky_coeff: 0.015\n",
      "  energy_correction: -0.002\n",
      "  enstrophy_correction: 3e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 329.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.628715\u001b[0m\n",
      "\u001b[96m→ Baseline at FULL (180d): 0.628715\u001b[0m\n",
      "\u001b[93m\n",
      "→ Re-evaluating BEST PARAMETERS at FULL (180d) fidelity...\u001b[0m\n",
      "\u001b[93m   Old best loss (FAST (30d)): 0.102669\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.424829e+00\n",
      "  drag_scale: 1.140379e+00\n",
      "  eddy_diffusivity: 9.492156e+04\n",
      "  smagorinsky_coeff: 2.895712e-01\n",
      "  energy_correction: -2.516649e-05\n",
      "  enstrophy_correction: 1.935362e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.424829139580515\n",
      "  drag_scale: 1.1403791825872298\n",
      "  eddy_diffusivity: 94921.55563078646\n",
      "  smagorinsky_coeff: 0.28957118109467156\n",
      "  energy_correction: -2.5166489019609606e-05\n",
      "  enstrophy_correction: 1.935361881463363e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 329.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.213380\u001b[0m\n",
      "\u001b[93m   New best loss (FULL (180d)): 0.213380\u001b[0m\n",
      "\u001b[91m   ⚠ Loss INCREASED by 107.8% at higher fidelity\u001b[0m\n",
      "\u001b[96m   → Improvement vs FULL (180d) baseline: +66.1%\u001b[0m\n",
      "\u001b[91m======================================================================\n",
      "\u001b[0m\n",
      "Valid samples: \u001b[96m40\u001b[0m/40\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 18.788\n",
      "    2. drag_scale: 2.535\n",
      "    3. enstrophy_correction: 1.851\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.297571e+00\n",
      "  drag_scale: 1.160642e+00\n",
      "  eddy_diffusivity: 9.579370e+04\n",
      "  smagorinsky_coeff: 2.870108e-01\n",
      "  energy_correction: -2.022630e-04\n",
      "  enstrophy_correction: 2.147225e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.2975709294374413\n",
      "  drag_scale: 1.1606419226602256\n",
      "  eddy_diffusivity: 95793.69621330536\n",
      "  smagorinsky_coeff: 0.2870108207269112\n",
      "  energy_correction: -0.000202262978413607\n",
      "  enstrophy_correction: 2.1472248516206526e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.235446\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m41\u001b[0m/41\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.213380\u001b[0m \u001b[96m(discovered at iteration 40)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+66.1%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 42/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m41\u001b[0m/41\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 52.265\n",
      "    2. enstrophy_correction: 28.975\n",
      "    3. drag_scale: 1.027\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.186499e+00\n",
      "  drag_scale: 1.080772e+00\n",
      "  eddy_diffusivity: 9.458852e+04\n",
      "  smagorinsky_coeff: 2.932957e-01\n",
      "  energy_correction: -3.022536e-05\n",
      "  enstrophy_correction: 1.862459e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1864985239603316\n",
      "  drag_scale: 1.0807723029972407\n",
      "  eddy_diffusivity: 94588.5248852224\n",
      "  smagorinsky_coeff: 0.29329574733412034\n",
      "  energy_correction: -3.0225357886002127e-05\n",
      "  enstrophy_correction: 1.8624592727141515e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 341.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.176356\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.176356\u001b[0m (+71.9% vs baseline @ FULL (180d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m42\u001b[0m/42\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.176356\u001b[0m \u001b[96m(discovered at iteration 42)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+71.9%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 43/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m42\u001b[0m/42\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 66.727\n",
      "    2. enstrophy_correction: 33.145\n",
      "    3. drag_scale: 1.961\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 9.481679e-01\n",
      "  drag_scale: 1.021165e+00\n",
      "  eddy_diffusivity: 9.453413e+04\n",
      "  smagorinsky_coeff: 2.941515e-01\n",
      "  energy_correction: -3.528423e-05\n",
      "  enstrophy_correction: 1.792303e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.9481679083401482\n",
      "  drag_scale: 1.0211654234072514\n",
      "  eddy_diffusivity: 94534.1333925298\n",
      "  smagorinsky_coeff: 0.294151519914261\n",
      "  energy_correction: -3.528422675239465e-05\n",
      "  enstrophy_correction: 1.792302812069878e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.134755\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.134755\u001b[0m (+78.6% vs baseline @ FULL (180d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m43\u001b[0m/43\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134755\u001b[0m \u001b[96m(discovered at iteration 43)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 44/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m43\u001b[0m/43\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 67.341\n",
      "    2. enstrophy_correction: 34.081\n",
      "    3. drag_scale: 1.917\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.452523e+04\n",
      "  smagorinsky_coeff: 2.943481e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199649\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 94525.23481490769\n",
      "  smagorinsky_coeff: 0.29434814595386904\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556408913e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m44\u001b[0m/44\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134755\u001b[0m \u001b[96m(discovered at iteration 43)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 45/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m44\u001b[0m/44\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 62.176\n",
      "    2. enstrophy_correction: 35.760\n",
      "    3. drag_scale: 1.166\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.452523e+04\n",
      "  smagorinsky_coeff: 2.943481e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199649\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 94525.23481490769\n",
      "  smagorinsky_coeff: 0.29434814595386904\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556408913e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 327.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m45\u001b[0m/45\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134755\u001b[0m \u001b[96m(discovered at iteration 43)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 46/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m45\u001b[0m/45\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 231.097\n",
      "    2. enstrophy_correction: 36.060\n",
      "    3. drag_scale: 16.839\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.452523e+04\n",
      "  smagorinsky_coeff: 2.943481e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199649\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 94525.23481490769\n",
      "  smagorinsky_coeff: 0.29434814595386904\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556408913e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "  → Trust region shrunk to 0.06\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m46\u001b[0m/46\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134755\u001b[0m \u001b[96m(discovered at iteration 43)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 47/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m46\u001b[0m/46\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 231.949\n",
      "    2. enstrophy_correction: 35.377\n",
      "    3. drag_scale: 16.297\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 8.290026e-01\n",
      "  drag_scale: 9.913620e-01\n",
      "  eddy_diffusivity: 9.677793e+04\n",
      "  smagorinsky_coeff: 2.965022e-01\n",
      "  energy_correction: -3.781366e-05\n",
      "  enstrophy_correction: 1.758222e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.8290026005300565\n",
      "  drag_scale: 0.9913619836122567\n",
      "  eddy_diffusivity: 96777.9317057153\n",
      "  smagorinsky_coeff: 0.29650218683354096\n",
      "  energy_correction: -3.781366118559004e-05\n",
      "  enstrophy_correction: 1.7582219071180272e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 327.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.129293\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.129293\u001b[0m (+79.4% vs baseline @ FULL (180d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m47\u001b[0m/47\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 48/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m47\u001b[0m/47\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 138.961\n",
      "    2. enstrophy_correction: 37.217\n",
      "    3. drag_scale: 7.761\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.715018e+04\n",
      "  smagorinsky_coeff: 2.970423e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199648\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 97150.1833117873\n",
      "  smagorinsky_coeff: 0.2970422863149939\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556507043e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m48\u001b[0m/48\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 49/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m48\u001b[0m/48\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 127.307\n",
      "    2. enstrophy_correction: 40.393\n",
      "    3. drag_scale: 6.952\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.715018e+04\n",
      "  smagorinsky_coeff: 2.970423e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199648\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 97150.1833117873\n",
      "  smagorinsky_coeff: 0.2970422863149939\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556507043e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m49\u001b[0m/49\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 50/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m49\u001b[0m/49\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 70.569\n",
      "    2. enstrophy_correction: 40.759\n",
      "    3. drag_scale: 1.292\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.098373e-01\n",
      "  drag_scale: 9.615585e-01\n",
      "  eddy_diffusivity: 9.715018e+04\n",
      "  smagorinsky_coeff: 2.970423e-01\n",
      "  energy_correction: -4.034310e-05\n",
      "  enstrophy_correction: 1.724789e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7098372927199648\n",
      "  drag_scale: 0.961558543817262\n",
      "  eddy_diffusivity: 97150.1833117873\n",
      "  smagorinsky_coeff: 0.2970422863149939\n",
      "  energy_correction: -4.034309561878717e-05\n",
      "  enstrophy_correction: 1.7247890556507043e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142995\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m50\u001b[0m/50\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 51/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m50\u001b[0m/50\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 124.604\n",
      "    2. enstrophy_correction: 42.813\n",
      "    3. drag_scale: 6.366\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.336704e-01\n",
      "  drag_scale: 9.675192e-01\n",
      "  eddy_diffusivity: 9.760888e+04\n",
      "  smagorinsky_coeff: 2.974731e-01\n",
      "  energy_correction: -3.983721e-05\n",
      "  enstrophy_correction: 1.731424e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7336703542819831\n",
      "  drag_scale: 0.967519231776261\n",
      "  eddy_diffusivity: 97608.88205486523\n",
      "  smagorinsky_coeff: 0.2974730944909283\n",
      "  energy_correction: -3.983720873214705e-05\n",
      "  enstrophy_correction: 1.7314243765661335e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.139702\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m51\u001b[0m/51\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m4/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 52/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m51\u001b[0m/51\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 71.373\n",
      "    2. enstrophy_correction: 39.146\n",
      "    3. drag_scale: 1.390\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.203406e-01\n",
      "  drag_scale: 9.531850e-01\n",
      "  eddy_diffusivity: 9.398348e+04\n",
      "  smagorinsky_coeff: 2.893504e-01\n",
      "  energy_correction: 6.141764e-05\n",
      "  enstrophy_correction: 1.447844e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.720340614728604\n",
      "  drag_scale: 0.9531849858635189\n",
      "  eddy_diffusivity: 93983.47913461545\n",
      "  smagorinsky_coeff: 0.289350436902433\n",
      "  energy_correction: 6.1417637139188e-05\n",
      "  enstrophy_correction: 1.4478441233918063e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.150235\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m52\u001b[0m/52\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m5/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 53/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m52\u001b[0m/52\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 75.925\n",
      "    2. enstrophy_correction: 45.085\n",
      "    3. drag_scale: 1.309\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.336704e-01\n",
      "  drag_scale: 9.675192e-01\n",
      "  eddy_diffusivity: 9.760888e+04\n",
      "  smagorinsky_coeff: 2.974731e-01\n",
      "  energy_correction: -3.983721e-05\n",
      "  enstrophy_correction: 1.731424e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7336703542819831\n",
      "  drag_scale: 0.967519231776261\n",
      "  eddy_diffusivity: 97608.88205486523\n",
      "  smagorinsky_coeff: 0.2974730944909283\n",
      "  energy_correction: -3.983720873214705e-05\n",
      "  enstrophy_correction: 1.7314243765661335e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.139702\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m53\u001b[0m/53\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m6/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 54/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m53\u001b[0m/53\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 124.205\n",
      "    2. enstrophy_correction: 46.140\n",
      "    3. drag_scale: 5.937\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.336704e-01\n",
      "  drag_scale: 9.675192e-01\n",
      "  eddy_diffusivity: 9.760888e+04\n",
      "  smagorinsky_coeff: 2.974731e-01\n",
      "  energy_correction: -3.983721e-05\n",
      "  enstrophy_correction: 1.731424e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7336703542819831\n",
      "  drag_scale: 0.967519231776261\n",
      "  eddy_diffusivity: 97608.88205486523\n",
      "  smagorinsky_coeff: 0.2974730944909283\n",
      "  energy_correction: -3.983720873214705e-05\n",
      "  enstrophy_correction: 1.7314243765661335e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 324.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.139702\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m54\u001b[0m/54\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m7/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 55/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m54\u001b[0m/54\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 123.745\n",
      "    2. enstrophy_correction: 46.542\n",
      "    3. drag_scale: 5.831\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.336704e-01\n",
      "  drag_scale: 9.675192e-01\n",
      "  eddy_diffusivity: 9.760888e+04\n",
      "  smagorinsky_coeff: 2.974731e-01\n",
      "  energy_correction: -3.983721e-05\n",
      "  enstrophy_correction: 1.731424e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7336703542819831\n",
      "  drag_scale: 0.967519231776261\n",
      "  eddy_diffusivity: 97608.88205486523\n",
      "  smagorinsky_coeff: 0.2974730944909283\n",
      "  energy_correction: -3.983720873214705e-05\n",
      "  enstrophy_correction: 1.7314243765661335e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.139702\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m55\u001b[0m/55\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m8/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 56/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m55\u001b[0m/55\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 312.828\n",
      "    2. viscosity_scale: 16.832\n",
      "    3. enstrophy_correction: 8.472\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.407880e-01\n",
      "  drag_scale: 1.004494e+00\n",
      "  eddy_diffusivity: 9.063492e+04\n",
      "  smagorinsky_coeff: 2.957934e-01\n",
      "  energy_correction: 4.506167e-04\n",
      "  enstrophy_correction: 2.029115e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7407880106378122\n",
      "  drag_scale: 1.0044942662821932\n",
      "  eddy_diffusivity: 90634.9163934785\n",
      "  smagorinsky_coeff: 0.2957934081478371\n",
      "  energy_correction: 0.0004506166555039576\n",
      "  enstrophy_correction: 2.0291148456502833e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 327.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.200113\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m56\u001b[0m/56\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m9/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 57/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m56\u001b[0m/56\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 332.313\n",
      "    2. viscosity_scale: 19.087\n",
      "    3. enstrophy_correction: 3.204\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.736090e-01\n",
      "  drag_scale: 9.610700e-01\n",
      "  eddy_diffusivity: 8.904313e+04\n",
      "  smagorinsky_coeff: 2.958937e-01\n",
      "  energy_correction: -4.775701e-04\n",
      "  enstrophy_correction: 1.767594e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7736090091446886\n",
      "  drag_scale: 0.9610700020160889\n",
      "  eddy_diffusivity: 89043.13428745323\n",
      "  smagorinsky_coeff: 0.29589367475702766\n",
      "  energy_correction: -0.00047757007442812346\n",
      "  enstrophy_correction: 1.7675941063580282e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 327.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.160078\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m57\u001b[0m/57\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m10/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 58/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m57\u001b[0m/57\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 25.657\n",
      "    2. enstrophy_correction: 11.677\n",
      "    3. viscosity_scale: 11.039\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 9.155134e-01\n",
      "  drag_scale: 9.311870e-01\n",
      "  eddy_diffusivity: 8.671756e+04\n",
      "  smagorinsky_coeff: 2.910065e-01\n",
      "  energy_correction: 3.298069e-04\n",
      "  enstrophy_correction: 2.140791e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.9155134237994946\n",
      "  drag_scale: 0.931186960019539\n",
      "  eddy_diffusivity: 86717.56266896037\n",
      "  smagorinsky_coeff: 0.2910064664096866\n",
      "  energy_correction: 0.0003298068724810841\n",
      "  enstrophy_correction: 2.1407907043208745e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:28<00:00, 301.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.190320\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m58\u001b[0m/58\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m11/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 59/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m58\u001b[0m/58\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 326.807\n",
      "    2. viscosity_scale: 18.326\n",
      "    3. enstrophy_correction: 8.110\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.171554e-01\n",
      "  drag_scale: 9.466739e-01\n",
      "  eddy_diffusivity: 8.911928e+04\n",
      "  smagorinsky_coeff: 2.981085e-01\n",
      "  energy_correction: -2.246306e-04\n",
      "  enstrophy_correction: 1.416131e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7171553534201853\n",
      "  drag_scale: 0.9466738558109491\n",
      "  eddy_diffusivity: 89119.28108102691\n",
      "  smagorinsky_coeff: 0.2981084520735618\n",
      "  energy_correction: -0.00022463060906596603\n",
      "  enstrophy_correction: 1.4161305287004298e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 335.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.150489\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m59\u001b[0m/59\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m12/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 60/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m59\u001b[0m/59\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. enstrophy_correction: 162.723\n",
      "    2. energy_correction: 98.478\n",
      "    3. viscosity_scale: 2.528\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 8.621701e-01\n",
      "  drag_scale: 9.368821e-01\n",
      "  eddy_diffusivity: 9.483245e+04\n",
      "  smagorinsky_coeff: 2.934750e-01\n",
      "  energy_correction: -1.738730e-04\n",
      "  enstrophy_correction: 1.547185e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.8621700722863305\n",
      "  drag_scale: 0.9368820563908646\n",
      "  eddy_diffusivity: 94832.44825947742\n",
      "  smagorinsky_coeff: 0.29347496626966374\n",
      "  energy_correction: -0.0001738730456552779\n",
      "  enstrophy_correction: 1.5471847476146364e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 334.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.155355\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m60\u001b[0m/60\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m13/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 61/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m60\u001b[0m/60\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 94.694\n",
      "    2. enstrophy_correction: 58.328\n",
      "    3. drag_scale: 1.384\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.336704e-01\n",
      "  drag_scale: 9.675192e-01\n",
      "  eddy_diffusivity: 9.760888e+04\n",
      "  smagorinsky_coeff: 2.974731e-01\n",
      "  energy_correction: -3.983721e-05\n",
      "  enstrophy_correction: 1.731424e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7336703542819831\n",
      "  drag_scale: 0.967519231776261\n",
      "  eddy_diffusivity: 97608.88205486523\n",
      "  smagorinsky_coeff: 0.2974730944909283\n",
      "  energy_correction: -3.983720873214705e-05\n",
      "  enstrophy_correction: 1.7314243765661335e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 329.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.139702\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m61\u001b[0m/61\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m14/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 62/80\u001b[0m\n",
      "======================================================================\n",
      "\u001b[91m\n",
      "⚠ STAGNATION: 15 iterations w/o improvement\u001b[0m\n",
      "\u001b[93m→ Triggering exploration restart\u001b[0m\n",
      "  → Trust region RESET to 0.80\n",
      "\u001b[93m  → Random sample will be added next\u001b[0m\n",
      "\u001b[92m  ✓ Restart complete\u001b[0m\n",
      "Valid samples: \u001b[96m61\u001b[0m/61\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 10.689\n",
      "    2. viscosity_scale: 2.141\n",
      "    3. enstrophy_correction: 1.204\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.849009e+00\n",
      "  drag_scale: 7.174922e-01\n",
      "  eddy_diffusivity: 1.720989e+04\n",
      "  smagorinsky_coeff: 2.316670e-01\n",
      "  energy_correction: -3.163381e-03\n",
      "  enstrophy_correction: 2.814043e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.8490094485464554\n",
      "  drag_scale: 0.7174922256463392\n",
      "  eddy_diffusivity: 17209.885165987907\n",
      "  smagorinsky_coeff: 0.23166699040988503\n",
      "  energy_correction: -0.0031633814395579697\n",
      "  enstrophy_correction: 2.8140434176976762e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.800252\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m62\u001b[0m/62\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 63/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m62\u001b[0m/62\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 311.723\n",
      "    2. viscosity_scale: 15.647\n",
      "    3. drag_scale: 1.971\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.492000e+00\n",
      "  drag_scale: 1.990662e+00\n",
      "  eddy_diffusivity: 6.366303e+04\n",
      "  smagorinsky_coeff: 2.103423e-01\n",
      "  energy_correction: -6.514061e-03\n",
      "  enstrophy_correction: 6.997060e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.4920000956122097\n",
      "  drag_scale: 1.9906616927628367\n",
      "  eddy_diffusivity: 63663.025440179204\n",
      "  smagorinsky_coeff: 0.21034234551900394\n",
      "  energy_correction: -0.0065140612511795145\n",
      "  enstrophy_correction: 6.997059767887326e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 331.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m1.939944\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m63\u001b[0m/63\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 64/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m63\u001b[0m/63\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 337.630\n",
      "    2. viscosity_scale: 17.638\n",
      "    3. drag_scale: 1.951\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.482749e+00\n",
      "  drag_scale: 8.336094e-01\n",
      "  eddy_diffusivity: 2.725407e+04\n",
      "  smagorinsky_coeff: 2.813328e-01\n",
      "  energy_correction: 4.965151e-03\n",
      "  enstrophy_correction: 1.128921e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.4827493358718564\n",
      "  drag_scale: 0.8336094122889534\n",
      "  eddy_diffusivity: 27254.071924747175\n",
      "  smagorinsky_coeff: 0.28133281916533237\n",
      "  energy_correction: 0.0049651507466278045\n",
      "  enstrophy_correction: 1.128921294023832e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m1.034195\u001b[0m\n",
      "  → Trust region shrunk to 0.40\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m64\u001b[0m/64\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 65/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m64\u001b[0m/64\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 305.697\n",
      "    2. viscosity_scale: 17.074\n",
      "    3. drag_scale: 1.765\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.278738e+00\n",
      "  drag_scale: 6.445749e-01\n",
      "  eddy_diffusivity: 4.085205e+04\n",
      "  smagorinsky_coeff: 2.648658e-01\n",
      "  energy_correction: -1.600598e-03\n",
      "  enstrophy_correction: 1.820296e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.2787384195728253\n",
      "  drag_scale: 0.6445749097846505\n",
      "  eddy_diffusivity: 40852.05363289471\n",
      "  smagorinsky_coeff: 0.26486580154899936\n",
      "  energy_correction: -0.0016005975503717799\n",
      "  enstrophy_correction: 1.820295731489889e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 341.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.547341\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m65\u001b[0m/65\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 66/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m65\u001b[0m/65\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 348.867\n",
      "    2. viscosity_scale: 18.101\n",
      "    3. drag_scale: 1.950\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.209641e-01\n",
      "  drag_scale: 6.929032e-01\n",
      "  eddy_diffusivity: 6.701781e+04\n",
      "  smagorinsky_coeff: 2.385129e-01\n",
      "  energy_correction: 7.560367e-04\n",
      "  enstrophy_correction: 3.717566e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5209641308039384\n",
      "  drag_scale: 0.6929031980737332\n",
      "  eddy_diffusivity: 67017.81269871545\n",
      "  smagorinsky_coeff: 0.23851287000073226\n",
      "  energy_correction: 0.0007560367254126343\n",
      "  enstrophy_correction: 3.717565703439588e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:28<00:00, 306.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.314086\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m66\u001b[0m/66\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m4/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 67/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m66\u001b[0m/66\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 347.308\n",
      "    2. viscosity_scale: 18.132\n",
      "    3. drag_scale: 1.949\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.067309e+00\n",
      "  drag_scale: 7.217622e-01\n",
      "  eddy_diffusivity: 5.161602e+04\n",
      "  smagorinsky_coeff: 2.904021e-01\n",
      "  energy_correction: 2.463669e-03\n",
      "  enstrophy_correction: 1.089096e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.067308602232328\n",
      "  drag_scale: 0.7217621827247025\n",
      "  eddy_diffusivity: 51616.01568634537\n",
      "  smagorinsky_coeff: 0.29040205546484804\n",
      "  energy_correction: 0.0024636685427211064\n",
      "  enstrophy_correction: 1.0890956892807602e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:27<00:00, 311.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.671338\u001b[0m\n",
      "  → Trust region shrunk to 0.20\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m67\u001b[0m/67\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m5/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 68/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m67\u001b[0m/67\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 343.691\n",
      "    2. viscosity_scale: 17.989\n",
      "    3. drag_scale: 1.950\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 6.626957e-01\n",
      "  drag_scale: 7.731253e-01\n",
      "  eddy_diffusivity: 7.762978e+04\n",
      "  smagorinsky_coeff: 2.709695e-01\n",
      "  energy_correction: -3.666456e-04\n",
      "  enstrophy_correction: 3.348557e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.6626957351781735\n",
      "  drag_scale: 0.773125337331258\n",
      "  eddy_diffusivity: 77629.77586719826\n",
      "  smagorinsky_coeff: 0.27096950222832705\n",
      "  energy_correction: -0.00036664561102360375\n",
      "  enstrophy_correction: 3.3485572754364993e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.264127\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m68\u001b[0m/68\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m6/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 69/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m68\u001b[0m/68\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 5.244\n",
      "    2. viscosity_scale: 2.809\n",
      "    3. drag_scale: 1.523\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.129040e+00\n",
      "  drag_scale: 1.175059e+00\n",
      "  eddy_diffusivity: 8.327332e+04\n",
      "  smagorinsky_coeff: 2.673828e-01\n",
      "  energy_correction: 1.228929e-03\n",
      "  enstrophy_correction: 7.970607e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.1290403218043275\n",
      "  drag_scale: 1.1750588504493222\n",
      "  eddy_diffusivity: 83273.31707814279\n",
      "  smagorinsky_coeff: 0.26738284816083907\n",
      "  energy_correction: 0.001228929225211093\n",
      "  enstrophy_correction: 7.970606794560517e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 328.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.482596\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m69\u001b[0m/69\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m7/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 70/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m69\u001b[0m/69\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 425.912\n",
      "    2. viscosity_scale: 23.899\n",
      "    3. drag_scale: 1.940\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.062456e+00\n",
      "  drag_scale: 9.945866e-01\n",
      "  eddy_diffusivity: 8.723830e+04\n",
      "  smagorinsky_coeff: 2.707995e-01\n",
      "  energy_correction: -1.966155e-03\n",
      "  enstrophy_correction: 1.537038e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.062456085617883\n",
      "  drag_scale: 0.994586603334955\n",
      "  eddy_diffusivity: 87238.29700916269\n",
      "  smagorinsky_coeff: 0.2707994979247609\n",
      "  energy_correction: -0.0019661546056345767\n",
      "  enstrophy_correction: 1.5370377770369685e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.455486\u001b[0m\n",
      "  → Trust region shrunk to 0.10\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m70\u001b[0m/70\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m8/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 71/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m70\u001b[0m/70\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 472.664\n",
      "    2. viscosity_scale: 30.660\n",
      "    3. drag_scale: 1.927\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.182154e-01\n",
      "  drag_scale: 9.307780e-01\n",
      "  eddy_diffusivity: 8.135100e+04\n",
      "  smagorinsky_coeff: 2.930934e-01\n",
      "  energy_correction: -9.173265e-04\n",
      "  enstrophy_correction: 1.777016e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7182154177593206\n",
      "  drag_scale: 0.9307780204199212\n",
      "  eddy_diffusivity: 81351.00198723844\n",
      "  smagorinsky_coeff: 0.2930933508329754\n",
      "  energy_correction: -0.0009173264876706569\n",
      "  enstrophy_correction: 1.7770162640819242e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 328.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.265319\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m71\u001b[0m/71\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m9/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 72/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m71\u001b[0m/71\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 4.216\n",
      "    2. viscosity_scale: 2.702\n",
      "    3. drag_scale: 1.613\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.025045e+00\n",
      "  drag_scale: 1.116245e+00\n",
      "  eddy_diffusivity: 9.386167e+04\n",
      "  smagorinsky_coeff: 2.865709e-01\n",
      "  energy_correction: -8.473446e-04\n",
      "  enstrophy_correction: 1.458356e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.0250448495166562\n",
      "  drag_scale: 1.1162445924528475\n",
      "  eddy_diffusivity: 93861.6651737311\n",
      "  smagorinsky_coeff: 0.28657085094051826\n",
      "  energy_correction: -0.00084734460993483\n",
      "  enstrophy_correction: 1.4583563682860256e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 326.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.277799\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m72\u001b[0m/72\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m10/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 73/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m72\u001b[0m/72\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 4.105\n",
      "    2. viscosity_scale: 1.865\n",
      "    3. drag_scale: 1.586\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 6.319505e-01\n",
      "  drag_scale: 1.079007e+00\n",
      "  eddy_diffusivity: 9.660432e+04\n",
      "  smagorinsky_coeff: 2.904857e-01\n",
      "  energy_correction: 2.447106e-04\n",
      "  enstrophy_correction: 1.744125e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.6319504532962791\n",
      "  drag_scale: 1.0790068983100507\n",
      "  eddy_diffusivity: 96604.32264571791\n",
      "  smagorinsky_coeff: 0.29048566556858835\n",
      "  energy_correction: 0.00024471060786424026\n",
      "  enstrophy_correction: 1.7441246988961806e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 328.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.192910\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m73\u001b[0m/73\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m11/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 74/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m73\u001b[0m/73\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 4.180\n",
      "    2. viscosity_scale: 1.955\n",
      "    3. drag_scale: 1.588\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 9.270237e-01\n",
      "  drag_scale: 1.053803e+00\n",
      "  eddy_diffusivity: 9.650086e+04\n",
      "  smagorinsky_coeff: 2.920157e-01\n",
      "  energy_correction: -4.425791e-04\n",
      "  enstrophy_correction: 1.601285e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.9270237250233564\n",
      "  drag_scale: 1.053803288032552\n",
      "  eddy_diffusivity: 96500.85958554088\n",
      "  smagorinsky_coeff: 0.2920157441849121\n",
      "  energy_correction: -0.00044257913556021086\n",
      "  enstrophy_correction: 1.6012851448509023e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.150455\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m74\u001b[0m/74\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m12/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 75/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m74\u001b[0m/74\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 4.178\n",
      "    2. viscosity_scale: 2.136\n",
      "    3. drag_scale: 1.595\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 7.709390e-01\n",
      "  drag_scale: 1.039819e+00\n",
      "  eddy_diffusivity: 9.215394e+04\n",
      "  smagorinsky_coeff: 2.896823e-01\n",
      "  energy_correction: -3.372003e-04\n",
      "  enstrophy_correction: 1.557715e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.7709390224017183\n",
      "  drag_scale: 1.0398186342830291\n",
      "  eddy_diffusivity: 92153.94345486289\n",
      "  smagorinsky_coeff: 0.28968227874373675\n",
      "  energy_correction: -0.0003372003490939076\n",
      "  enstrophy_correction: 1.5577146376258785e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 329.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.142348\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m75\u001b[0m/75\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m13/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 76/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m75\u001b[0m/75\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 4.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 4.106\n",
      "    2. viscosity_scale: 1.948\n",
      "    3. drag_scale: 1.584\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 8.897819e-01\n",
      "  drag_scale: 1.039411e+00\n",
      "  eddy_diffusivity: 8.872834e+04\n",
      "  smagorinsky_coeff: 2.897208e-01\n",
      "  energy_correction: -1.424469e-04\n",
      "  enstrophy_correction: 1.605222e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.8897818622920508\n",
      "  drag_scale: 1.0394105466095227\n",
      "  eddy_diffusivity: 88728.34317097576\n",
      "  smagorinsky_coeff: 0.2897207547119172\n",
      "  energy_correction: -0.00014244694025333446\n",
      "  enstrophy_correction: 1.6052216576914455e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 327.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.148716\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m76\u001b[0m/76\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[93m14/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 77/80\u001b[0m\n",
      "======================================================================\n",
      "\u001b[91m\n",
      "⚠ STAGNATION: 15 iterations w/o improvement\u001b[0m\n",
      "\u001b[93m→ Triggering exploration restart\u001b[0m\n",
      "  → Trust region RESET to 0.80\n",
      "\u001b[93m  → Random sample will be added next\u001b[0m\n",
      "\u001b[92m  ✓ Restart complete\u001b[0m\n",
      "Valid samples: \u001b[96m76\u001b[0m/76\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 7.385\n",
      "    2. drag_scale: 2.218\n",
      "    3. viscosity_scale: 1.433\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.139609e+00\n",
      "  drag_scale: 1.818943e+00\n",
      "  eddy_diffusivity: 2.195523e+04\n",
      "  smagorinsky_coeff: 1.845712e-01\n",
      "  energy_correction: -1.711946e-03\n",
      "  enstrophy_correction: 7.245771e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.1396088840409515\n",
      "  drag_scale: 1.8189433935766968\n",
      "  eddy_diffusivity: 21955.22751513476\n",
      "  smagorinsky_coeff: 0.18457120566919227\n",
      "  energy_correction: -0.001711946126269499\n",
      "  enstrophy_correction: 7.245771008546046e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 328.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m1.383993\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m77\u001b[0m/77\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 78/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m77\u001b[0m/77\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 27.239\n",
      "    2. drag_scale: 10.195\n",
      "    3. viscosity_scale: 1.474\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.903464e+00\n",
      "  drag_scale: 7.772625e-01\n",
      "  eddy_diffusivity: 1.608833e+04\n",
      "  smagorinsky_coeff: 2.507928e-01\n",
      "  energy_correction: -6.689818e-03\n",
      "  enstrophy_correction: 2.461225e-08\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.9034644093118698\n",
      "  drag_scale: 0.7772625328691571\n",
      "  eddy_diffusivity: 16088.327604277247\n",
      "  smagorinsky_coeff: 0.2507927604690288\n",
      "  energy_correction: -0.006689818392088553\n",
      "  enstrophy_correction: 2.461224666194789e-08\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 325.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m1.164088\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m78\u001b[0m/78\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 79/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m78\u001b[0m/78\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 5.825\n",
      "    2. smagorinsky_coeff: 2.498\n",
      "    3. viscosity_scale: 1.269\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.363162e-01\n",
      "  drag_scale: 7.901952e-01\n",
      "  eddy_diffusivity: 4.553536e+04\n",
      "  smagorinsky_coeff: 1.804128e-01\n",
      "  energy_correction: 1.549887e-03\n",
      "  enstrophy_correction: 1.669553e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5363161875981285\n",
      "  drag_scale: 0.7901952070787819\n",
      "  eddy_diffusivity: 45535.3626411127\n",
      "  smagorinsky_coeff: 0.1804127935416457\n",
      "  energy_correction: 0.0015498871120108587\n",
      "  enstrophy_correction: 1.6695532787653471e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 337.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.435952\u001b[0m\n",
      "  → Trust region shrunk to 0.40\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m79\u001b[0m/79\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 80/80\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m79\u001b[0m/79\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 6.120\n",
      "    2. smagorinsky_coeff: 2.341\n",
      "    3. viscosity_scale: 1.277\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 1.649916e+00\n",
      "  drag_scale: 1.490896e+00\n",
      "  eddy_diffusivity: 7.947503e+04\n",
      "  smagorinsky_coeff: 2.539015e-01\n",
      "  energy_correction: -3.275937e-03\n",
      "  enstrophy_correction: 8.322113e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 1.6499155976390103\n",
      "  drag_scale: 1.4908964750816551\n",
      "  eddy_diffusivity: 79475.0283216847\n",
      "  smagorinsky_coeff: 0.25390149147415497\n",
      "  energy_correction: -0.0032759374561825514\n",
      "  enstrophy_correction: 8.322112623118634e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 335.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m1.269184\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m80\u001b[0m/80\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.129293\u001b[0m \u001b[96m(discovered at iteration 47)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.4%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING FINAL VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Total iterations: 80\n",
      "  Valid: \u001b[96m80\u001b[0m\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "\n",
      "Baselines by fidelity:\n",
      "  FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "\n",
      "\u001b[1mFinal Comparison at FULL (180d) Fidelity:\u001b[0m\n",
      "  Baseline (default): \u001b[96m0.628715\u001b[0m\n",
      "  Best loss: \u001b[92m0.129293\u001b[0m \u001b[92m[+79.4% improvement]\u001b[0m\n",
      "  Best parameters discovered at: iteration 47\n",
      "\u001b[96m    (during 180-day full precision phase)\u001b[0m\n",
      "\n",
      "\u001b[1mBest parameters:\u001b[0m\n",
      "  viscosity_scale: \u001b[96m8.290026e-01\u001b[0m (default: 5.000000e-01, +65.8%)\n",
      "  drag_scale: \u001b[96m9.913620e-01\u001b[0m (default: 5.000000e-01, +98.3%)\n",
      "  eddy_diffusivity: \u001b[96m9.677793e+04\u001b[0m (default: 5.000000e-03, +1935558534.1%)\n",
      "  smagorinsky_coeff: \u001b[96m2.965022e-01\u001b[0m (default: 1.500000e-02, +1876.7%)\n",
      "  energy_correction: \u001b[96m-3.781366e-05\u001b[0m (default: -2.000000e-03, -98.1%)\n",
      "  enstrophy_correction: \u001b[96m1.758222e-09\u001b[0m (default: 3.000000e-09, -41.4%)\n",
      "\n",
      "✓ Saved: enhanced_gp_optimal_params.pkl\n",
      "✓ Saved: enhanced_gp_optimal_config.txt\n",
      "\n",
      "======================================================================\n",
      "NOTE: 2-LEVEL MULTI-FIDELITY WITH ADAPTIVE BASELINES\n",
      "======================================================================\n",
      "The optimizer uses a simple 2-level fidelity strategy:\n",
      "  Phase 1 (iterations 0-40):  30-day runs (~6x faster)\n",
      "    - Compares entire simulation (days 0-30)\n",
      "    - Baseline tracked at 30-day fidelity\n",
      "  Phase 2 (iterations 40+):   180-day runs (full precision)\n",
      "    - Compares last 30 days (equilibrated state)\n",
      "    - Baseline tracked at 180-day fidelity\n",
      "\n",
      "This ensures:\n",
      "  ✓ Fast exploration in early iterations\n",
      "  ✓ Fair apples-to-apples comparisons at each fidelity\n",
      "  ✓ Final results use full 180-day simulations\n",
      "\n",
      "Seed robustness:\n",
      "  ✓ Random seed used: 42\n",
      "  ✓ Multiple complementary seeds used internally\n",
      "  ✓ Small perturbations added to reduce grid artifacts\n",
      "  ℹ Different seeds may find best at different iterations\n",
      "    but final performance should be similar (~5-10% variation)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING FINAL COMPARISON SIMULATIONS\n",
      "======================================================================\n",
      "\n",
      "✓ Using cached default results at FULL fidelity\n",
      "\n",
      "Running optimized parameters simulation (full 180 days)...\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.8290026005300565\n",
      "  drag_scale: 0.9913619836122567\n",
      "  eddy_diffusivity: 96777.9317057153\n",
      "  smagorinsky_coeff: 0.29650218683354096\n",
      "  energy_correction: -3.781366118559004e-05\n",
      "  enstrophy_correction: 1.7582219071180272e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 336.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  ✓ Optimized simulation complete\n",
      "\n",
      "======================================================================\n",
      "GENERATING 3-WAY COMPARISON\n",
      "======================================================================\n",
      "✓ Saved 3-way comparison: three_way_comparison.png\n",
      "\n",
      "======================================================================\n",
      "COMPARISON SUMMARY (All using last 30 days)\n",
      "======================================================================\n",
      "High-Res (Reference):\n",
      "  Resolution: 512x256\n",
      "  Time window: last 30 days (equilibrated state)\n",
      "\n",
      "Low-Res DEFAULT:\n",
      "  Resolution: 64x32\n",
      "  PV Loss: 0.726491\n",
      "  Streamfn Loss: 0.482050\n",
      "  Total Loss: 0.628715\n",
      "\n",
      "Low-Res OPTIMIZED:\n",
      "  Resolution: 64x32\n",
      "  PV Loss: 0.176751\n",
      "  Streamfn Loss: 0.058104\n",
      "  Total Loss: 0.129293\n",
      "\n",
      "\u001b[93m\u001b[1m★ IMPROVEMENT: 79.4%\u001b[0m\n",
      "======================================================================\n",
      "\n",
      "✓ Saved: optimization_analysis.png\n",
      "✓ Saved: parameter_sensitivity.png\n",
      "✓ Saved: computational_efficiency.png\n",
      "✓ Saved: three_way_comparison.png\n",
      "\n",
      "======================================================================\n",
      "VISUALIZATION GUIDE\n",
      "======================================================================\n",
      "1. optimization_analysis.png\n",
      "   → Loss evolution, parameter trajectories, trust region\n",
      "   → Shows HOW the optimization progressed\n",
      "\n",
      "2. parameter_sensitivity.png\n",
      "   → Correlation analysis, variance explained, ranges explored\n",
      "   → Shows WHICH parameters matter most\n",
      "   → Red = increasing parameter worsens loss\n",
      "   → Green = increasing parameter improves loss\n",
      "\n",
      "3. computational_efficiency.png\n",
      "   → Cost vs improvement, phase breakdown, sample efficiency\n",
      "   → Shows HOW EFFICIENTLY we found improvements\n",
      "\n",
      "4. three_way_comparison.png\n",
      "   → Spatial fields: high-res vs default vs optimized\n",
      "   → Shows FINAL RESULTS quality\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Robust GP Optimizer with Warm-Start & 3-Way Comparison\n",
    "\n",
    "NEW FEATURES:\n",
    "1. Warm-start from reference parameters (baseline-aware)\n",
    "2. Multi-fidelity optimization (30d → 180d with separate tracking)\n",
    "3. Thompson sampling exploration\n",
    "4. 3-way comparison: high-res vs low-res default vs low-res optimized (contourf plots)\n",
    "5. Comprehensive visualization with improvement metrics\n",
    "6. Seed-robust initialization using multiple complementary random sequences\n",
    "7. Separate best-loss tracking per fidelity level (no confusing jumps!)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from scipy.stats import qmc, norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, ConstantKernel, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from qg_model import QGTwoLayerModel\n",
    "from scipy.ndimage import uniform_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.gaussian_process')\n",
    "warnings.filterwarnings('ignore', message='The optimal value found for dimension')\n",
    "\n",
    "class Colors:\n",
    "    \"\"\"Compact color printing\"\"\"\n",
    "    @staticmethod\n",
    "    def green(t): return f\"\\033[92m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def cyan(t): return f\"\\033[96m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def yellow(t): return f\"\\033[93m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def red(t): return f\"\\033[91m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def bold(t): return f\"\\033[1m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def star(t): return f\"\\033[93m\\033[1m★ {t}\\033[0m\"\n",
    "\n",
    "# Parameter configuration with REFERENCE BASELINE\n",
    "PARAM_BOUNDS = {\n",
    "    'viscosity_scale': {'bounds': (0.5, 5.0), 'type': 'linear'},\n",
    "    'drag_scale': {'bounds': (0.5, 3.0), 'type': 'linear'},\n",
    "    'eddy_diffusivity': {'bounds': (1e3, 1e5), 'type': 'log'},\n",
    "    'smagorinsky_coeff': {'bounds': (0.0, 0.3), 'type': 'linear'},\n",
    "    'energy_correction': {'bounds': (-0.01, 0.01), 'type': 'linear'},\n",
    "    'enstrophy_correction': {'bounds': (0.0, 1e-6), 'type': 'log'},\n",
    "}\n",
    "\n",
    "# REFERENCE/DEFAULT PARAMETERS (known baseline)\n",
    "# Note: If defaults are outside bounds, they will be clipped automatically\n",
    "DEFAULT_PARAMS = {\n",
    "    'viscosity_scale': 0.5,\n",
    "    'drag_scale': 0.5,\n",
    "    'eddy_diffusivity': 0.005,  # User-provided default (will be clipped to bounds if needed)\n",
    "    'smagorinsky_coeff': 0.015,\n",
    "    'energy_correction': -0.002,\n",
    "    'enstrophy_correction': 3e-9,\n",
    "}\n",
    "\n",
    "PARAM_NAMES = list(PARAM_BOUNDS.keys())\n",
    "N_PARAMS = len(PARAM_NAMES)\n",
    "\n",
    "# Input warping for log-scale parameters\n",
    "def warp_parameters(params_array):\n",
    "    \"\"\"Transform to warped space: log params → log space, linear → [0,1]\"\"\"\n",
    "    warped = np.zeros(N_PARAMS)\n",
    "    for i, name in enumerate(PARAM_NAMES):\n",
    "        val, info = params_array[i], PARAM_BOUNDS[name]\n",
    "        lower, upper = info['bounds']\n",
    "        if info['type'] == 'log':\n",
    "            log_lower, log_upper = np.log10(lower) if lower > 0 else -10, np.log10(upper)\n",
    "            warped[i] = (np.log10(val + 1e-20) - log_lower) / (log_upper - log_lower)\n",
    "        else:\n",
    "            warped[i] = (val - lower) / (upper - lower)\n",
    "    return warped\n",
    "\n",
    "def unwarp_parameters(warped_array):\n",
    "    \"\"\"Transform from warped space back to original space\"\"\"\n",
    "    params = np.zeros(N_PARAMS)\n",
    "    for i, name in enumerate(PARAM_NAMES):\n",
    "        info = PARAM_BOUNDS[name]\n",
    "        lower, upper = info['bounds']\n",
    "        if info['type'] == 'log':\n",
    "            log_lower, log_upper = np.log10(lower) if lower > 0 else -10, np.log10(upper)\n",
    "            params[i] = 10 ** (warped_array[i] * (log_upper - log_lower) + log_lower)\n",
    "        else:\n",
    "            params[i] = warped_array[i] * (upper - lower) + lower\n",
    "        params[i] = np.clip(params[i], lower, upper)\n",
    "    return params\n",
    "\n",
    "def params_dict_to_array(params_dict):\n",
    "    \"\"\"Convert parameter dictionary to array, clipping to bounds\"\"\"\n",
    "    params = []\n",
    "    for name in PARAM_NAMES:\n",
    "        val = params_dict[name]\n",
    "        lower, upper = PARAM_BOUNDS[name]['bounds']\n",
    "        clipped_val = np.clip(val, lower, upper)\n",
    "        if clipped_val != val:\n",
    "            print(Colors.yellow(f\"  ⚠ Clipped {name}: {val:.6e} → {clipped_val:.6e} (bounds: [{lower:.6e}, {upper:.6e}])\"))\n",
    "        params.append(clipped_val)\n",
    "    return np.array(params)\n",
    "\n",
    "def params_array_to_dict(params_array):\n",
    "    \"\"\"Convert parameter array to dictionary\"\"\"\n",
    "    return {PARAM_NAMES[i]: float(params_array[i]) for i in range(N_PARAMS)}\n",
    "\n",
    "# ============================================================================\n",
    "# SMART INITIALIZATION WITH WARM-START\n",
    "# ============================================================================\n",
    "\n",
    "def generate_smart_initial_samples(n_samples, include_default=True, base_seed=42):\n",
    "    \"\"\"\n",
    "    Combine default params + Latin Hypercube + Sobol for warm-start\n",
    "    Uses multiple complementary seeds for better diversity and robustness\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Total number of samples\n",
    "        include_default: If True, first sample is DEFAULT_PARAMS\n",
    "        base_seed: Base random seed (will generate complementary seeds from this)\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # WARM-START: Include default parameters as first sample\n",
    "    if include_default:\n",
    "        default_array = params_dict_to_array(DEFAULT_PARAMS)\n",
    "        samples.append(default_array)\n",
    "        n_samples -= 1\n",
    "        print(Colors.cyan(\"  ✓ Including reference parameters as warm-start\"))\n",
    "    \n",
    "    # Generate space-filling samples for remaining\n",
    "    # Use MULTIPLE seeds for robustness - reduces sensitivity to single seed choice\n",
    "    n_lhs = n_samples // 2\n",
    "    n_sobol = n_samples - n_lhs\n",
    "    \n",
    "    # LHS with primary seed\n",
    "    lhs_sampler = qmc.LatinHypercube(d=N_PARAMS, seed=base_seed)\n",
    "    lhs_samples = lhs_sampler.random(n=n_lhs)\n",
    "    \n",
    "    # Sobol with complementary seed (offset by 1000)\n",
    "    # This ensures different quasi-random sequences\n",
    "    sobol_sampler = qmc.Sobol(d=N_PARAMS, seed=base_seed + 1000, scramble=True)\n",
    "    sobol_samples = sobol_sampler.random(n=n_sobol)\n",
    "    \n",
    "    # Combine samples\n",
    "    unit_samples = np.vstack([lhs_samples, sobol_samples])\n",
    "    \n",
    "    # Add small random perturbations to avoid exact grid points\n",
    "    # This helps exploration and reduces sensitivity to specific seed values\n",
    "    np.random.seed(base_seed + 2000)\n",
    "    perturbations = np.random.normal(0, 0.02, size=unit_samples.shape)\n",
    "    unit_samples = np.clip(unit_samples + perturbations, 0, 1)\n",
    "    \n",
    "    for unit_sample in unit_samples:\n",
    "        samples.append(unwarp_parameters(unit_sample))\n",
    "    \n",
    "    print(Colors.cyan(f\"  ✓ Generated {len(samples)} diverse initial samples (base_seed={base_seed})\"))\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "# ============================================================================\n",
    "# ENSEMBLE GP\n",
    "# ============================================================================\n",
    "\n",
    "class EnsembleGP:\n",
    "    \"\"\"Ensemble of Gaussian Processes with different kernels\"\"\"\n",
    "    \n",
    "    def __init__(self, n_models=8):\n",
    "        self.models = []\n",
    "        self.model_weights = []\n",
    "        \n",
    "        kernels = [\n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=1.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[0.5]*N_PARAMS, length_scale_bounds=(1e-3, 1e2), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[2.0]*N_PARAMS, length_scale_bounds=(1e-2, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[0.3]*N_PARAMS, length_scale_bounds=(1e-3, 1e2), nu=1.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[0.7]*N_PARAMS, length_scale_bounds=(1e-3, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.5]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "        ]\n",
    "        \n",
    "        for kernel in kernels[:n_models]:\n",
    "            self.models.append(GaussianProcessRegressor(\n",
    "                kernel=kernel,\n",
    "                alpha=1e-6,\n",
    "                normalize_y=True,\n",
    "                n_restarts_optimizer=15,\n",
    "                random_state=None\n",
    "            ))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit all models and compute weights based on marginal likelihood\"\"\"\n",
    "        self.model_weights = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            try:\n",
    "                model.fit(X, y)\n",
    "                # Weight by log marginal likelihood\n",
    "                log_ml = model.log_marginal_likelihood()\n",
    "                self.model_weights.append(np.exp(log_ml))\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Model {i} fitting failed: {e}\")\n",
    "                self.model_weights.append(0.0)\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(self.model_weights)\n",
    "        if total_weight > 0:\n",
    "            self.model_weights = [w / total_weight for w in self.model_weights]\n",
    "        else:\n",
    "            self.model_weights = [1.0 / len(self.models)] * len(self.models)\n",
    "    \n",
    "    def predict(self, X, return_std=True):\n",
    "        \"\"\"Weighted ensemble prediction\"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        if return_std:\n",
    "            predictions = []\n",
    "            uncertainties = []\n",
    "            weights = []\n",
    "            \n",
    "            for i, model in enumerate(self.models):\n",
    "                if self.model_weights[i] > 0:\n",
    "                    try:\n",
    "                        mu, sigma = model.predict(X, return_std=True)\n",
    "                        predictions.append(mu)\n",
    "                        uncertainties.append(sigma)\n",
    "                        weights.append(self.model_weights[i])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            if len(predictions) == 0:\n",
    "                return np.zeros(len(X)), np.ones(len(X))\n",
    "            \n",
    "            # Weighted mean and maximum uncertainty\n",
    "            weights = np.array(weights)\n",
    "            mean = np.average(predictions, axis=0, weights=weights)\n",
    "            std = np.max(uncertainties, axis=0)\n",
    "            \n",
    "            return mean, std\n",
    "        else:\n",
    "            predictions = []\n",
    "            weights = []\n",
    "            for i, model in enumerate(self.models):\n",
    "                if self.model_weights[i] > 0:\n",
    "                    try:\n",
    "                        predictions.append(model.predict(X))\n",
    "                        weights.append(self.model_weights[i])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            return np.average(predictions, axis=0, weights=weights) if predictions else np.zeros(len(X))\n",
    "    \n",
    "    def get_parameter_importance(self):\n",
    "        \"\"\"Extract parameter importance from length scales\"\"\"\n",
    "        importance_scores = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.model_weights[i] > 0:\n",
    "                try:\n",
    "                    kernel = model.kernel_\n",
    "                    # Try to extract length scales from different kernel structures\n",
    "                    length_scales = None\n",
    "                    \n",
    "                    # For composite kernels (ConstantKernel * Matern/RBF + WhiteKernel)\n",
    "                    if hasattr(kernel, 'k1') and hasattr(kernel.k1, 'k2'):\n",
    "                        length_scales = kernel.k1.k2.length_scale\n",
    "                    elif hasattr(kernel, 'k2'):\n",
    "                        length_scales = kernel.k2.length_scale\n",
    "                    elif hasattr(kernel, 'length_scale'):\n",
    "                        length_scales = kernel.length_scale\n",
    "                    \n",
    "                    if length_scales is not None and hasattr(length_scales, '__len__'):\n",
    "                        # Inverse of length scale = importance (smaller length scale = more sensitive)\n",
    "                        # Normalize by median to get relative importance\n",
    "                        ls_array = np.array(length_scales)\n",
    "                        importance = 1.0 / (ls_array + 1e-10)\n",
    "                        # Normalize so median = 1.0\n",
    "                        importance = importance / (np.median(importance) + 1e-10)\n",
    "                        importance_scores.append(importance)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        if importance_scores and len(importance_scores) > 0:\n",
    "            # Weighted average importance\n",
    "            weights = [w for w in self.model_weights if w > 0][:len(importance_scores)]\n",
    "            weighted_importance = np.average(importance_scores, axis=0, weights=weights)\n",
    "            return weighted_importance\n",
    "        else:\n",
    "            # Fallback: return ones (equal importance)\n",
    "            return np.ones(N_PARAMS)\n",
    "\n",
    "# Trust region with reset capability\n",
    "class TrustRegion:\n",
    "    def __init__(self):\n",
    "        self.trust_radius, self.best_center = 0.5, None\n",
    "        self.success_count, self.fail_count = 0, 0\n",
    "        self.min_radius, self.max_radius = 0.05, 1.0\n",
    "        self.radius_history = []\n",
    "    \n",
    "    def get_trust_region_bounds(self):\n",
    "        if self.best_center is None:\n",
    "            return [(0, 1)] * N_PARAMS\n",
    "        bounds = []\n",
    "        for i in range(N_PARAMS):\n",
    "            center, half_width = self.best_center[i], self.trust_radius / 2\n",
    "            bounds.append((max(0.0, center - half_width), min(1.0, center + half_width)))\n",
    "        return bounds\n",
    "    \n",
    "    def update(self, new_best_found, new_center=None):\n",
    "        if new_best_found:\n",
    "            self.success_count += 1\n",
    "            self.fail_count = 0\n",
    "            if new_center is not None:\n",
    "                self.best_center = new_center\n",
    "            if self.success_count >= 3:\n",
    "                self.trust_radius = min(self.max_radius, self.trust_radius * 1.5)\n",
    "                self.success_count = 0\n",
    "                print(f\"  → Trust region expanded to {self.trust_radius:.2f}\")\n",
    "        else:\n",
    "            self.fail_count += 1\n",
    "            self.success_count = 0\n",
    "            if self.fail_count >= 3:\n",
    "                self.trust_radius = max(self.min_radius, self.trust_radius * 0.5)\n",
    "                self.fail_count = 0\n",
    "                print(f\"  → Trust region shrunk to {self.trust_radius:.2f}\")\n",
    "        \n",
    "        self.radius_history.append(self.trust_radius)\n",
    "    \n",
    "    def reset_for_exploration(self):\n",
    "        self.trust_radius = 0.8\n",
    "        self.success_count, self.fail_count = 0, 0\n",
    "        self.radius_history.append(self.trust_radius)\n",
    "        print(f\"  → Trust region RESET to {self.trust_radius:.2f}\")\n",
    "\n",
    "# NEW: Thompson Sampling for exploration\n",
    "def thompson_sampling(gp, bounds, n_samples=1):\n",
    "    \"\"\"Sample from GP posterior for exploration\"\"\"\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        # Sample a function from GP posterior\n",
    "        X_grid = np.random.uniform([b[0] for b in bounds], [b[1] for b in bounds], size=(500, N_PARAMS))\n",
    "        mu, sigma = gp.predict(X_grid, return_std=True)\n",
    "        \n",
    "        # Sample from posterior at each point\n",
    "        posterior_samples = np.random.normal(mu, sigma)\n",
    "        \n",
    "        # Find minimum of sampled function\n",
    "        best_idx = np.argmin(posterior_samples)\n",
    "        samples.append(X_grid[best_idx])\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "# Hybrid acquisition with LOCAL PENALIZATION\n",
    "def hybrid_acquisition_with_penalization(X, gp, best_y, X_samples, xi=0.01, kappa=2.0, weight_ei=0.6, penalization_weight=0.3):\n",
    "    \"\"\"Hybrid EI+UCB with local penalization\"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    # Expected Improvement\n",
    "    with np.errstate(divide='warn', invalid='warn'):\n",
    "        imp = best_y - mu - xi\n",
    "        Z = imp / (sigma + 1e-9)\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    # Upper Confidence Bound\n",
    "    ucb = -(mu - kappa * sigma)\n",
    "    \n",
    "    # Normalize\n",
    "    ei_norm = (ei - ei.min()) / (ei.max() - ei.min() + 1e-9)\n",
    "    ucb_norm = (ucb - ucb.min()) / (ucb.max() - ucb.min() + 1e-9)\n",
    "    \n",
    "    # Base acquisition\n",
    "    acq = weight_ei * ei_norm + (1 - weight_ei) * ucb_norm\n",
    "    \n",
    "    # Local penalization\n",
    "    if len(X_samples) > 0 and penalization_weight > 0:\n",
    "        X_samples_warped = np.array([warp_parameters(x) for x in X_samples])\n",
    "        min_distances = np.min([np.linalg.norm(X - x_sample, axis=1) for x_sample in X_samples_warped], axis=0)\n",
    "        penalty = np.exp(-10 * min_distances)\n",
    "        acq = acq * (1 - penalization_weight * penalty)\n",
    "    \n",
    "    return acq\n",
    "\n",
    "# Acquisition optimizer with multi-start\n",
    "def optimize_acquisition_multistart(acquisition_fn, bounds, n_starts=20, n_random=500):\n",
    "    \"\"\"Multi-start optimization of acquisition function\"\"\"\n",
    "    best_acq, best_x = -np.inf, None\n",
    "    \n",
    "    # Random sampling\n",
    "    random_samples = np.random.uniform([b[0] for b in bounds], [b[1] for b in bounds], size=(n_random, N_PARAMS))\n",
    "    acq_random = acquisition_fn(random_samples)\n",
    "    best_random_idx = np.argmax(acq_random)\n",
    "    if acq_random[best_random_idx] > best_acq:\n",
    "        best_acq, best_x = acq_random[best_random_idx], random_samples[best_random_idx]\n",
    "    \n",
    "    # Gradient-based optimization\n",
    "    for _ in range(n_starts):\n",
    "        x0 = np.array([np.random.uniform(b[0], b[1]) for b in bounds])\n",
    "        result = minimize(lambda x: -acquisition_fn(x.reshape(1, -1))[0], x0, method='L-BFGS-B', bounds=bounds)\n",
    "        if result.success and -result.fun > best_acq:\n",
    "            best_acq, best_x = -result.fun, result.x\n",
    "    \n",
    "    return best_x\n",
    "\n",
    "# NEW: Simplified 2-level multi-fidelity (30 days → 180 days)\n",
    "def get_adaptive_sim_days(iteration, base_days=180):\n",
    "    \"\"\"\n",
    "    Two-level fidelity strategy:\n",
    "    - Iterations 0-40: Fast 30-day runs (6x faster exploration)\n",
    "    - Iterations 40+:  Full 180-day runs (final precision)\n",
    "    \n",
    "    Returns: (sim_days, description)\n",
    "    \"\"\"\n",
    "    if iteration < 40:\n",
    "        return 30, \"FAST (30d)\"  # Fast exploration\n",
    "    else:\n",
    "        return base_days, \"FULL (180d)\"  # Full precision\n",
    "\n",
    "# Simulation runner\n",
    "def run_lowres_with_params(params_array, config_base, highres_results, sim_days=180, iteration=0):\n",
    "    from main_comparison import run_simulation\n",
    "    \n",
    "    # Adaptive fidelity\n",
    "    adaptive_days, fidelity_desc = get_adaptive_sim_days(iteration, sim_days)\n",
    "    \n",
    "    config = config_base.copy()\n",
    "    config['subgrid_params'] = {PARAM_NAMES[i]: float(params_array[i]) for i in range(N_PARAMS)}\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing parameters - Fidelity: {Colors.cyan(fidelity_desc)}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for param_name, val in config['subgrid_params'].items():\n",
    "        print(f\"  {param_name}: {val:.6e}\")\n",
    "    \n",
    "    try:\n",
    "        results = run_simulation(config, sim_days=adaptive_days, save_interval_hours=12)\n",
    "        # Adaptive loss computation will automatically use appropriate time window\n",
    "        loss, detailed = compute_loss(results, highres_results, return_fields=True, adaptive_window=True)\n",
    "        if not np.isfinite(loss):\n",
    "            print(Colors.yellow(f\"  ⚠ Loss not finite: {loss}\"))\n",
    "            return np.nan, None, None\n",
    "        print(f\"  Loss: {Colors.green(f'{loss:.6f}')}\")\n",
    "        return loss, results, detailed\n",
    "    except Exception as e:\n",
    "        print(Colors.yellow(f\"  ⚠ Simulation failed: {e}\"))\n",
    "        return np.nan, None, None\n",
    "\n",
    "# Loss computation with adaptive time window\n",
    "def compute_loss(lowres_results, highres_results, n_days_avg=30, return_fields=False, adaptive_window=True):\n",
    "    \"\"\"\n",
    "    Compute loss with adaptive time window based on simulation length\n",
    "    \n",
    "    Args:\n",
    "        adaptive_window: If True, adjust time window based on lowres simulation length\n",
    "                        - For 30-day runs: use entire simulation (days 0-30)\n",
    "                        - For 180-day runs: use last 30 days (days 150-180, equilibrated)\n",
    "    \"\"\"\n",
    "    nx_hr, ny_hr = highres_results['config']['nx'], highres_results['config']['ny']\n",
    "    nx_lr, ny_lr = lowres_results['config']['nx'], lowres_results['config']['ny']\n",
    "    coarsen_factor_x, coarsen_factor_y = nx_hr // nx_lr, ny_hr // ny_lr\n",
    "    \n",
    "    times_hr, times_lr = highres_results['times'], lowres_results['times']\n",
    "    \n",
    "    # Adaptive time window based on simulation length\n",
    "    if adaptive_window:\n",
    "        lr_duration = times_lr[-1] - times_lr[0]\n",
    "        \n",
    "        if lr_duration <= 40:  # 30-day runs\n",
    "            # Use entire simulation\n",
    "            time_start, time_end = times_lr[0], times_lr[-1]\n",
    "            print(f\"  → Using entire simulation (days 0-{time_end - time_start:.0f}) for loss\")\n",
    "        else:  # Full 180-day runs\n",
    "            # Use last 30 days for equilibrated state\n",
    "            time_start, time_end = times_lr[-1] - n_days_avg, times_lr[-1]\n",
    "            print(f\"  → Using last {n_days_avg} days for loss (equilibrated state)\")\n",
    "        \n",
    "        # Get matching time window from high-res\n",
    "        if lr_duration <= 40:\n",
    "            # For short runs, match the same absolute time window\n",
    "            indices_hr = np.where((times_hr >= time_start) & (times_hr <= time_end))[0]\n",
    "        else:\n",
    "            # For full runs, use last 30 days of high-res too\n",
    "            indices_hr = np.where(times_hr >= times_hr[-1] - n_days_avg)[0]\n",
    "        \n",
    "        indices_lr = np.where((times_lr >= time_start) & (times_lr <= time_end))[0]\n",
    "    else:\n",
    "        # Original behavior: use last n_days_avg\n",
    "        indices_hr = np.where(times_hr >= times_hr[-1] - n_days_avg)[0]\n",
    "        indices_lr = np.where(times_lr >= times_lr[-1] - n_days_avg)[0]\n",
    "    \n",
    "    q1_hr_avg = np.mean([highres_results['q1_history'][i] for i in indices_hr], axis=0)\n",
    "    q2_hr_avg = np.mean([highres_results['q2_history'][i] for i in indices_hr], axis=0)\n",
    "    q1_lr_avg = np.mean([lowres_results['q1_history'][i] for i in indices_lr], axis=0)\n",
    "    q2_lr_avg = np.mean([lowres_results['q2_history'][i] for i in indices_lr], axis=0)\n",
    "    \n",
    "    model_hr, model_lr = highres_results['model'], lowres_results['model']\n",
    "    psi1_hr_avg, psi2_hr_avg = model_hr.q_to_psi(q1_hr_avg, q2_hr_avg)\n",
    "    psi1_lr_avg, psi2_lr_avg = model_lr.q_to_psi(q1_lr_avg, q2_lr_avg)\n",
    "    \n",
    "    H1, H2, H_total = model_hr.H1, model_hr.H2, model_hr.H1 + model_hr.H2\n",
    "    q_bt_hr = (H1 * q1_hr_avg + H2 * q2_hr_avg) / H_total\n",
    "    psi_bt_hr = (H1 * psi1_hr_avg + H2 * psi2_hr_avg) / H_total\n",
    "    q_bt_lr = (H1 * q1_lr_avg + H2 * q2_lr_avg) / H_total\n",
    "    psi_bt_lr = (H1 * psi1_lr_avg + H2 * psi2_lr_avg) / H_total\n",
    "    \n",
    "    def coarsen(field, fx, fy):\n",
    "        return uniform_filter(field, size=(fy, fx), mode='wrap')[::fy, ::fx]\n",
    "    \n",
    "    q_bt_hr_coarse = coarsen(q_bt_hr, coarsen_factor_x, coarsen_factor_y)\n",
    "    psi_bt_hr_coarse = coarsen(psi_bt_hr, coarsen_factor_x, coarsen_factor_y)\n",
    "    \n",
    "    nrmse = lambda pred, target: np.sqrt(np.mean((pred - target)**2)) / (np.std(target) + 1e-20)\n",
    "    loss_q_bt, loss_psi_bt = nrmse(q_bt_lr, q_bt_hr_coarse), nrmse(psi_bt_lr, psi_bt_hr_coarse)\n",
    "    weight_pv, weight_psi = 0.6, 0.4\n",
    "    total_loss = weight_pv * loss_q_bt + weight_psi * loss_psi_bt\n",
    "    \n",
    "    if return_fields:\n",
    "        return total_loss, {'q_bt_hr_coarse': q_bt_hr_coarse, 'psi_bt_hr_coarse': psi_bt_hr_coarse,\n",
    "                           'q_bt_lr': q_bt_lr, 'psi_bt_lr': psi_bt_lr, 'loss_q_bt': loss_q_bt,\n",
    "                           'loss_psi_bt': loss_psi_bt, 'total_loss': total_loss}\n",
    "    return total_loss\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION SUITE\n",
    "# ============================================================================\n",
    "\n",
    "class OptimizationVisualizer:\n",
    "    \"\"\"Comprehensive visualization of optimization progress\"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.dpi'] = 100\n",
    "        plt.rcParams['savefig.dpi'] = 300\n",
    "    \n",
    "    def plot_comprehensive_analysis(self, save_path='optimization_analysis.png'):\n",
    "        \"\"\"Create comprehensive multi-panel analysis\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Loss evolution\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        self._plot_loss_evolution(ax1)\n",
    "        \n",
    "        # 2. Parameter evolution\n",
    "        ax2 = fig.add_subplot(gs[1, :2])\n",
    "        self._plot_parameter_evolution(ax2)\n",
    "        \n",
    "        # 3. Parameter importance\n",
    "        ax3 = fig.add_subplot(gs[2, :2])\n",
    "        self._plot_parameter_importance(ax3)\n",
    "        \n",
    "        # 4. Trust region evolution\n",
    "        ax4 = fig.add_subplot(gs[0, 2])\n",
    "        self._plot_trust_region(ax4)\n",
    "        \n",
    "        # 5. Convergence diagnostics\n",
    "        ax5 = fig.add_subplot(gs[1, 2])\n",
    "        self._plot_convergence_diagnostics(ax5)\n",
    "        \n",
    "        # 6. Best parameters bar chart\n",
    "        ax6 = fig.add_subplot(gs[2, 2])\n",
    "        self._plot_best_parameters(ax6)\n",
    "        \n",
    "        plt.suptitle('Bayesian Optimization - Comprehensive Analysis', \n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"\\n✓ Saved comprehensive analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_loss_evolution(self, ax):\n",
    "        \"\"\"Plot loss vs iterations with best loss tracking and fidelity phases\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        iterations = np.arange(len(y_samples))\n",
    "        \n",
    "        # Plot all losses\n",
    "        ax.scatter(iterations[valid_mask], y_samples[valid_mask], \n",
    "                  alpha=0.6, s=50, c='steelblue', label='Valid evaluations', zorder=3)\n",
    "        ax.scatter(iterations[~valid_mask], np.ones(np.sum(~valid_mask)) * np.nanmax(y_samples) * 1.1, \n",
    "                  alpha=0.4, s=30, c='red', marker='x', label='Failed evaluations', zorder=2)\n",
    "        \n",
    "        # Plot best loss trajectory - SEPARATE FOR EACH FIDELITY\n",
    "        best_trajectory_30d = []\n",
    "        best_trajectory_180d = []\n",
    "        current_best_30d = np.inf\n",
    "        current_best_180d = np.inf\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            sim_days, _ = get_adaptive_sim_days(i)\n",
    "            \n",
    "            if sim_days <= 40:  # 30-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_30d:\n",
    "                    current_best_30d = loss\n",
    "                best_trajectory_30d.append(current_best_30d if current_best_30d != np.inf else np.nan)\n",
    "                best_trajectory_180d.append(np.nan)\n",
    "            else:  # 180-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_180d:\n",
    "                    current_best_180d = loss\n",
    "                best_trajectory_30d.append(np.nan)\n",
    "                best_trajectory_180d.append(current_best_180d if current_best_180d != np.inf else np.nan)\n",
    "        \n",
    "        # Plot 30-day best loss\n",
    "        valid_30d = [(i, best_trajectory_30d[i]) for i in range(len(best_trajectory_30d)) if np.isfinite(best_trajectory_30d[i])]\n",
    "        if valid_30d:\n",
    "            indices_30d, values_30d = zip(*valid_30d)\n",
    "            ax.plot(indices_30d, values_30d, 'limegreen', linewidth=2.5, \n",
    "                   label='Best loss (30d)', zorder=4, marker='o', markersize=5)\n",
    "        \n",
    "        # Plot 180-day best loss\n",
    "        valid_180d = [(i, best_trajectory_180d[i]) for i in range(len(best_trajectory_180d)) if np.isfinite(best_trajectory_180d[i])]\n",
    "        if valid_180d:\n",
    "            indices_180d, values_180d = zip(*valid_180d)\n",
    "            ax.plot(indices_180d, values_180d, 'darkgreen', linewidth=3, \n",
    "                   label='Best loss (180d)', zorder=4, marker='*', markersize=8)\n",
    "        \n",
    "        # Highlight different fidelity phases with colored backgrounds\n",
    "        n_initial = self.optimizer.n_initial_samples\n",
    "        ax.axvspan(0, n_initial-1, alpha=0.1, color='orange', label='Initial sampling')\n",
    "        \n",
    "        # 2-level multi-fidelity phases\n",
    "        fidelity_transition = 40\n",
    "        \n",
    "        if len(iterations) > n_initial:\n",
    "            # 30-day runs (fast exploration)\n",
    "            ax.axvspan(n_initial, min(fidelity_transition, len(iterations)-1), \n",
    "                      alpha=0.10, color='lightblue', label='30d runs (fast)')\n",
    "        \n",
    "        if len(iterations) > fidelity_transition:\n",
    "            # 180-day runs (full precision)\n",
    "            ax.axvspan(fidelity_transition, len(iterations)-1, \n",
    "                      alpha=0.10, color='lightcoral', label='180d runs (full)')\n",
    "        \n",
    "        # Mark fidelity transition with vertical line\n",
    "        if len(iterations) > fidelity_transition:\n",
    "            ax.axvline(fidelity_transition, color='red', linestyle='--', linewidth=2, \n",
    "                      alpha=0.7, label='Fidelity jump')\n",
    "        \n",
    "        # Mark best iteration\n",
    "        ax.scatter([self.optimizer.best_iteration], [self.optimizer.best_loss],\n",
    "                  s=200, c='gold', marker='*', edgecolors='red', linewidth=2,\n",
    "                  label=f'Best (iter {self.optimizer.best_iteration+1})', zorder=5)\n",
    "        \n",
    "        # If best was found in 30d phase, add annotation\n",
    "        if self.optimizer.best_params_original_iteration is not None and self.optimizer.best_params_original_iteration < 40:\n",
    "            # Check if we have 180d baseline (meaning re-evaluation happened)\n",
    "            has_full_baseline = 'FULL (180d)' in self.optimizer.baseline_loss_by_fidelity\n",
    "            if has_full_baseline:\n",
    "                annotation_text = f'Found at iter {self.optimizer.best_params_original_iteration+1}\\n(30d phase)\\nRe-eval at 180d'\n",
    "            else:\n",
    "                annotation_text = f'Found at iter {self.optimizer.best_params_original_iteration+1}\\n(30d phase)'\n",
    "            \n",
    "            ax.annotate(annotation_text, \n",
    "                       xy=(self.optimizer.best_params_original_iteration, self.optimizer.best_loss),\n",
    "                       xytext=(self.optimizer.best_params_original_iteration + 10, self.optimizer.best_loss * 1.2),\n",
    "                       arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                       fontsize=7, color='red', fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Loss Evolution (2-Level Multi-Fidelity: 30d → 180d)\\nSeparate tracking per fidelity', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=7, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add improvement info with all baselines\n",
    "        if self.optimizer.baseline_loss_by_fidelity:\n",
    "            info_lines = []\n",
    "            \n",
    "            # Final improvement (use FULL baseline if available)\n",
    "            final_baseline = self.optimizer.baseline_loss_by_fidelity.get('FULL (180d)')\n",
    "            if final_baseline:\n",
    "                improvement = (final_baseline - self.optimizer.best_loss) / final_baseline * 100\n",
    "                info_lines.append(f'Final improvement: {improvement:+.1f}%')\n",
    "            \n",
    "            # Show all baselines\n",
    "            info_lines.append('Baselines:')\n",
    "            for fid, base in sorted(self.optimizer.baseline_loss_by_fidelity.items()):\n",
    "                info_lines.append(f'  {fid}: {base:.4f}')\n",
    "            \n",
    "            info_text = '\\n'.join(info_lines)\n",
    "            ax.text(0.02, 0.98, info_text, \n",
    "                   transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
    "    \n",
    "    def _plot_parameter_evolution(self, ax):\n",
    "        \"\"\"Plot how parameters evolved over iterations\"\"\"\n",
    "        X_samples = np.array(self.optimizer.X_samples)\n",
    "        n_iters = len(X_samples)\n",
    "        \n",
    "        # Normalize parameters to [0, 1] for visualization\n",
    "        X_normalized = np.array([warp_parameters(x) for x in X_samples])\n",
    "        \n",
    "        for i, param_name in enumerate(PARAM_NAMES):\n",
    "            ax.plot(range(n_iters), X_normalized[:, i], \n",
    "                   marker='o', markersize=4, alpha=0.7, linewidth=1.5, \n",
    "                   label=param_name)\n",
    "        \n",
    "        # Highlight initial samples phase\n",
    "        n_initial = self.optimizer.n_initial_samples\n",
    "        ax.axvspan(0, n_initial-1, alpha=0.1, color='orange')\n",
    "        \n",
    "        # Mark best iteration\n",
    "        ax.axvline(self.optimizer.best_iteration, color='red', linestyle='--', \n",
    "                  linewidth=2, alpha=0.7, label='Best found')\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Normalized Parameter Value', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Parameter Evolution', fontsize=13, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    def _plot_parameter_importance(self, ax):\n",
    "        \"\"\"Plot parameter sensitivity over time\"\"\"\n",
    "        if not hasattr(self.optimizer, 'importance_history') or not self.optimizer.importance_history:\n",
    "            ax.text(0.5, 0.5, 'Parameter importance\\nnot tracked\\n(Need more iterations)', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title('Parameter Importance Over Time', fontsize=13, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        importance_array = np.array(self.optimizer.importance_history)\n",
    "        \n",
    "        # Check if all values are constant (indicating a problem)\n",
    "        if importance_array.shape[0] < 2 or np.allclose(importance_array[0], importance_array[-1]):\n",
    "            # Fall back to correlation-based importance from current samples\n",
    "            ax.text(0.5, 0.7, 'GP-based importance unavailable', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=11, style='italic')\n",
    "            ax.text(0.5, 0.5, 'Using correlation-based\\nimportance instead', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.text(0.5, 0.3, '(See parameter_sensitivity.png\\nfor detailed analysis)', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=9, style='italic')\n",
    "            ax.set_title('Parameter Importance Over Time', fontsize=13, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        # Plot importance evolution\n",
    "        iterations = np.arange(len(importance_array)) + self.optimizer.n_initial_samples\n",
    "        \n",
    "        for i, param_name in enumerate(PARAM_NAMES):\n",
    "            ax.plot(iterations, importance_array[:, i], \n",
    "                   marker='o', markersize=3, alpha=0.7, linewidth=1.5,\n",
    "                   label=param_name)\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Importance Score (1/length_scale)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Parameter Importance Over Time\\n(Higher = More Sensitive)', fontsize=13, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add interpretation note\n",
    "        ax.text(0.98, 0.02, 'Note: Based on GP length scales\\nSmaller length scale → Higher importance', \n",
    "               transform=ax.transAxes, fontsize=7, ha='right', va='bottom',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    def _plot_trust_region(self, ax):\n",
    "        \"\"\"Plot trust region radius evolution\"\"\"\n",
    "        if not self.optimizer.trust_region.radius_history:\n",
    "            ax.text(0.5, 0.5, 'Trust region\\nhistory empty', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.set_title('Trust Region Evolution', fontsize=11, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        radius_history = self.optimizer.trust_region.radius_history\n",
    "        ax.plot(radius_history, marker='o', markersize=4, linewidth=2, color='purple')\n",
    "        ax.axhline(self.optimizer.trust_region.min_radius, color='red', \n",
    "                  linestyle='--', alpha=0.5, label='Min radius')\n",
    "        ax.axhline(self.optimizer.trust_region.max_radius, color='green', \n",
    "                  linestyle='--', alpha=0.5, label='Max radius')\n",
    "        \n",
    "        ax.set_xlabel('Update Step', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Trust Radius', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Trust Region Evolution', fontsize=11, fontweight='bold')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_convergence_diagnostics(self, ax):\n",
    "        \"\"\"Plot convergence metrics\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        # Moving average of improvement\n",
    "        window = 5\n",
    "        improvements = []\n",
    "        for i in range(window, len(y_samples)):\n",
    "            if valid_mask[i]:\n",
    "                recent_best = np.nanmin(y_samples[max(0, i-window):i])\n",
    "                current = y_samples[i]\n",
    "                improvements.append(max(0, recent_best - current))\n",
    "            else:\n",
    "                improvements.append(0)\n",
    "        \n",
    "        iterations = np.arange(window, len(y_samples))\n",
    "        ax.bar(iterations, improvements, alpha=0.6, color='teal')\n",
    "        ax.set_xlabel('Iteration', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Recent Improvement', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Convergence Diagnostics', fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    def _plot_best_parameters(self, ax):\n",
    "        \"\"\"Bar chart of best parameters\"\"\"\n",
    "        if self.optimizer.best_params is None:\n",
    "            ax.text(0.5, 0.5, 'No best\\nparameters yet', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.set_title('Best Parameters', fontsize=11, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        best_normalized = warp_parameters(self.optimizer.best_params)\n",
    "        \n",
    "        colors = plt.cm.viridis(best_normalized)\n",
    "        bars = ax.barh(PARAM_NAMES, best_normalized, color=colors, alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Normalized Value', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Best Parameters (Normalized)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add actual values as text\n",
    "        for i, (bar, name) in enumerate(zip(bars, PARAM_NAMES)):\n",
    "            actual_val = self.optimizer.best_params[i]\n",
    "            ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{actual_val:.2e}', va='center', fontsize=7)\n",
    "    \n",
    "    def plot_parameter_sensitivity_heatmap(self, save_path='parameter_sensitivity.png'):\n",
    "        \"\"\"Create comprehensive parameter sensitivity analysis\"\"\"\n",
    "        X_samples = np.array(self.optimizer.X_samples)\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        if np.sum(valid_mask) < 5:\n",
    "            print(\"Not enough valid samples for sensitivity analysis\")\n",
    "            return\n",
    "        \n",
    "        X_valid = X_samples[valid_mask]\n",
    "        y_valid = y_samples[valid_mask]\n",
    "        \n",
    "        # Normalize parameters\n",
    "        X_normalized = np.array([warp_parameters(x) for x in X_valid])\n",
    "        \n",
    "        # Create comprehensive figure\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.35, wspace=0.35)\n",
    "        \n",
    "        # ========== Panel 1: Parameter-Loss Correlations ==========\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        correlations = []\n",
    "        for i in range(N_PARAMS):\n",
    "            corr = np.corrcoef(X_normalized[:, i], y_valid)[0, 1]\n",
    "            correlations.append(corr)\n",
    "        \n",
    "        colors = ['crimson' if c > 0 else 'forestgreen' for c in correlations]\n",
    "        bars = ax1.barh(PARAM_NAMES, correlations, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax1.axvline(0, color='black', linewidth=2)\n",
    "        ax1.set_xlabel('Correlation with Loss', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Parameter Sensitivity: Correlation with Loss\\n' + \n",
    "                     'RED = Increasing parameter WORSENS performance | GREEN = Increasing parameter IMPROVES performance',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, corr in zip(bars, correlations):\n",
    "            width = bar.get_width()\n",
    "            label = f'{corr:+.3f}'\n",
    "            ax1.text(width + (0.02 if width > 0 else -0.02), \n",
    "                    bar.get_y() + bar.get_height()/2, label,\n",
    "                    va='center', ha='left' if width > 0 else 'right',\n",
    "                    fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 2: Variance Explained ==========\n",
    "        ax2 = fig.add_subplot(gs[0, 2])\n",
    "        \n",
    "        # Simple variance explained: R² from linear fit\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        var_explained = []\n",
    "        for i in range(N_PARAMS):\n",
    "            X_param = X_normalized[:, i].reshape(-1, 1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_param, y_valid)\n",
    "            r2 = model.score(X_param, y_valid)\n",
    "            var_explained.append(max(0, r2))  # Clip negative R²\n",
    "        \n",
    "        colors_var = plt.cm.RdYlGn_r(np.array(var_explained) / max(var_explained))\n",
    "        ax2.barh(PARAM_NAMES, var_explained, color=colors_var, alpha=0.8, edgecolor='black')\n",
    "        ax2.set_xlabel('Variance Explained (R²)', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Parameter Importance\\n(Higher = More Influential)', fontsize=11, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (val, name) in enumerate(zip(var_explained, PARAM_NAMES)):\n",
    "            ax2.text(val + 0.01, i, f'{val:.3f}', va='center', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 3: Parameter Ranges Explored ==========\n",
    "        ax3 = fig.add_subplot(gs[1, :2])\n",
    "        \n",
    "        # Box plots showing explored ranges\n",
    "        positions = np.arange(N_PARAMS)\n",
    "        bp = ax3.boxplot([X_normalized[:, i] for i in range(N_PARAMS)],\n",
    "                         positions=positions, vert=False, patch_artist=True,\n",
    "                         widths=0.6, showfliers=True)\n",
    "        \n",
    "        for patch, corr in zip(bp['boxes'], correlations):\n",
    "            color = 'lightcoral' if corr > 0 else 'lightgreen'\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "        \n",
    "        ax3.set_yticks(positions)\n",
    "        ax3.set_yticklabels(PARAM_NAMES)\n",
    "        ax3.set_xlabel('Normalized Parameter Value [0=min, 1=max]', fontsize=12, fontweight='bold')\n",
    "        ax3.set_title('Parameter Space Exploration\\n(Box = 25th-75th percentile, Whiskers = min-max, Dots = outliers)',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='x')\n",
    "        ax3.set_xlim(-0.05, 1.05)\n",
    "        \n",
    "        # Mark best parameters\n",
    "        if self.optimizer.best_params is not None:\n",
    "            best_normalized = warp_parameters(self.optimizer.best_params)\n",
    "            ax3.scatter(best_normalized, positions, s=200, c='gold', marker='*', \n",
    "                       edgecolors='red', linewidth=2, zorder=10, label='Best Found')\n",
    "            ax3.legend(fontsize=10, loc='upper right')\n",
    "        \n",
    "        # ========== Panel 4: Loss vs Top 2 Parameters (Scatter) ==========\n",
    "        abs_corr = np.abs(correlations)\n",
    "        top_2_indices = np.argsort(abs_corr)[-2:]\n",
    "        \n",
    "        ax4 = fig.add_subplot(gs[1, 2])\n",
    "        param_idx_1, param_idx_2 = top_2_indices[1], top_2_indices[0]\n",
    "        \n",
    "        scatter = ax4.scatter(X_normalized[:, param_idx_1], X_normalized[:, param_idx_2],\n",
    "                            c=y_valid, cmap='viridis_r', s=80, alpha=0.6,\n",
    "                            edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Mark best point\n",
    "        if self.optimizer.best_params is not None:\n",
    "            best_norm = warp_parameters(self.optimizer.best_params)\n",
    "            ax4.scatter(best_norm[param_idx_1], best_norm[param_idx_2],\n",
    "                       s=300, c='gold', marker='*', edgecolors='red', linewidth=2.5,\n",
    "                       zorder=10, label='Best')\n",
    "        \n",
    "        ax4.set_xlabel(f'{PARAM_NAMES[param_idx_1]}', fontsize=11, fontweight='bold')\n",
    "        ax4.set_ylabel(f'{PARAM_NAMES[param_idx_2]}', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title(f'Top 2 Most Influential Parameters\\n(Lower loss = Better)', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.legend(fontsize=9)\n",
    "        \n",
    "        cbar = plt.colorbar(scatter, ax=ax4)\n",
    "        cbar.set_label('Loss', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 5: Parameter Value Distributions ==========\n",
    "        ax5 = fig.add_subplot(gs[2, :2])\n",
    "        \n",
    "        # Show distribution of sampled values for top 3 parameters\n",
    "        top_3_indices = np.argsort(abs_corr)[-3:]\n",
    "        colors_dist = ['red', 'orange', 'green']\n",
    "        \n",
    "        for idx_rank, param_idx in enumerate(top_3_indices[::-1]):\n",
    "            values = X_normalized[:, param_idx]\n",
    "            ax5.hist(values, bins=15, alpha=0.5, color=colors_dist[idx_rank], \n",
    "                    label=PARAM_NAMES[param_idx], edgecolor='black', linewidth=1)\n",
    "        \n",
    "        ax5.set_xlabel('Normalized Parameter Value', fontsize=12, fontweight='bold')\n",
    "        ax5.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "        ax5.set_title('Sampling Distribution of Top 3 Most Influential Parameters',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax5.legend(fontsize=10)\n",
    "        ax5.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # ========== Panel 6: Parameter Importance Summary ==========\n",
    "        ax6 = fig.add_subplot(gs[2, 2])\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # Create summary text\n",
    "        summary_lines = [\n",
    "            \"INTERPRETATION GUIDE:\",\n",
    "            \"\",\n",
    "            \"Correlation:\",\n",
    "            \"  • Positive = increasing parameter worsens loss\",\n",
    "            \"  • Negative = increasing parameter improves loss\",\n",
    "            \"  • Magnitude = strength of relationship\",\n",
    "            \"\",\n",
    "            \"Variance Explained (R²):\",\n",
    "            \"  • How much loss variation this parameter explains\",\n",
    "            \"  • Higher = more important to tune carefully\",\n",
    "            \"\",\n",
    "            \"Top 3 Most Important Parameters:\",\n",
    "        ]\n",
    "        \n",
    "        top_3_with_corr = [(PARAM_NAMES[i], correlations[i], var_explained[i]) \n",
    "                           for i in np.argsort(abs_corr)[-3:][::-1]]\n",
    "        \n",
    "        for rank, (name, corr, var_exp) in enumerate(top_3_with_corr, 1):\n",
    "            direction = \"↑ worsens\" if corr > 0 else \"↓ improves\"\n",
    "            summary_lines.append(f\"  {rank}. {name}\")\n",
    "            summary_lines.append(f\"     Corr: {corr:+.3f} ({direction})\")\n",
    "            summary_lines.append(f\"     R²: {var_exp:.3f}\")\n",
    "        \n",
    "        summary_text = '\\n'.join(summary_lines)\n",
    "        ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,\n",
    "                fontsize=10, verticalalignment='top', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Comprehensive Parameter Sensitivity Analysis', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Saved sensitivity analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_computational_efficiency(self, save_path='computational_efficiency.png'):\n",
    "        \"\"\"Analyze computational cost vs improvement\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        if np.sum(valid_mask) < 5:\n",
    "            print(\"Not enough valid samples for efficiency analysis\")\n",
    "            return\n",
    "        \n",
    "        # Estimate computational cost (30-day = 1 unit, 180-day = 6 units)\n",
    "        cumulative_cost = []\n",
    "        cost_per_iteration = []\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(len(y_samples)):\n",
    "            sim_days, _ = get_adaptive_sim_days(i)\n",
    "            cost = sim_days / 30.0  # Normalize to 30-day cost\n",
    "            cost_per_iteration.append(cost)\n",
    "            total_cost += cost\n",
    "            cumulative_cost.append(total_cost)\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # ========== Panel 1: Cumulative Cost vs Improvement ==========\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        \n",
    "        # Best loss trajectory - split by fidelity\n",
    "        best_trajectory_30d = []\n",
    "        best_trajectory_180d = []\n",
    "        current_best_30d = np.inf\n",
    "        current_best_180d = np.inf\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            sim_days, _ = get_adaptive_sim_days(i)\n",
    "            \n",
    "            if sim_days <= 40:  # 30-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_30d:\n",
    "                    current_best_30d = loss\n",
    "                best_trajectory_30d.append(current_best_30d if current_best_30d != np.inf else np.nan)\n",
    "                best_trajectory_180d.append(np.nan)  # Not applicable yet\n",
    "            else:  # 180-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_180d:\n",
    "                    current_best_180d = loss\n",
    "                best_trajectory_30d.append(np.nan)  # 30-day phase is over\n",
    "                best_trajectory_180d.append(current_best_180d if current_best_180d != np.inf else np.nan)\n",
    "        \n",
    "        ax1_twin = ax1.twinx()\n",
    "        \n",
    "        # Plot cumulative cost\n",
    "        color_cost = 'steelblue'\n",
    "        line1 = ax1.plot(range(len(cumulative_cost)), cumulative_cost, \n",
    "                color=color_cost, linewidth=2.5, label='Cumulative Cost', marker='o', markersize=4)\n",
    "        ax1.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Cumulative Computational Cost (30-day equiv.)', \n",
    "                      fontsize=11, fontweight='bold', color=color_cost)\n",
    "        ax1.tick_params(axis='y', labelcolor=color_cost)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot best loss for 30-day fidelity\n",
    "        color_loss_30d = 'limegreen'\n",
    "        valid_indices_30d = [i for i, loss in enumerate(best_trajectory_30d) if np.isfinite(loss)]\n",
    "        valid_trajectory_30d = [best_trajectory_30d[i] for i in valid_indices_30d]\n",
    "        line2 = ax1_twin.plot(valid_indices_30d, valid_trajectory_30d, \n",
    "                     color=color_loss_30d, linewidth=2.5, label='Best Loss (30d)', \n",
    "                     marker='o', markersize=6, linestyle='-', alpha=0.8)\n",
    "        \n",
    "        # Plot best loss for 180-day fidelity\n",
    "        color_loss_180d = 'darkgreen'\n",
    "        valid_indices_180d = [i for i, loss in enumerate(best_trajectory_180d) if np.isfinite(loss)]\n",
    "        valid_trajectory_180d = [best_trajectory_180d[i] for i in valid_indices_180d]\n",
    "        line3 = ax1_twin.plot(valid_indices_180d, valid_trajectory_180d, \n",
    "                     color=color_loss_180d, linewidth=3, label='Best Loss (180d)', \n",
    "                     marker='*', markersize=8, linestyle='-')\n",
    "        \n",
    "        ax1_twin.set_ylabel('Best Loss', fontsize=11, fontweight='bold', color='darkgreen')\n",
    "        ax1_twin.tick_params(axis='y', labelcolor='darkgreen')\n",
    "        \n",
    "        # Mark fidelity transition\n",
    "        line4 = ax1.axvline(40, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Fidelity Jump')\n",
    "        \n",
    "        # Add annotation explaining the jump\n",
    "        if len(valid_indices_30d) > 0 and len(valid_indices_180d) > 0:\n",
    "            last_30d_loss = valid_trajectory_30d[-1]\n",
    "            first_180d_loss = valid_trajectory_180d[0]\n",
    "            if np.isfinite(last_30d_loss) and np.isfinite(first_180d_loss):\n",
    "                jump_pct = (first_180d_loss - last_30d_loss) / last_30d_loss * 100\n",
    "                ax1_twin.annotate(f'Re-eval: {jump_pct:+.1f}%',\n",
    "                                 xy=(40, first_180d_loss), xytext=(45, first_180d_loss * 1.1),\n",
    "                                 arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                                 fontsize=8, color='red', fontweight='bold',\n",
    "                                 bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "        \n",
    "        ax1.set_title('Computational Efficiency: Cost vs Improvement Over Time\\n(Separate best loss tracking for each fidelity)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Combine legends from both axes\n",
    "        lines = line1 + line2 + line3 + [line4]\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax1.legend(lines, labels, loc='upper left', fontsize=9)\n",
    "        \n",
    "        # ========== Panel 2: Improvement per Cost Unit ==========\n",
    "        ax2 = fig.add_subplot(gs[0, 2])\n",
    "        \n",
    "        # Calculate improvement per cost for each iteration\n",
    "        if self.optimizer.baseline_loss:\n",
    "            improvements = []\n",
    "            for i, loss in enumerate(y_samples):\n",
    "                if np.isfinite(loss):\n",
    "                    improvement = max(0, self.optimizer.baseline_loss - loss)\n",
    "                    improvements.append(improvement / cost_per_iteration[i])\n",
    "                else:\n",
    "                    improvements.append(0)\n",
    "            \n",
    "            # Moving average\n",
    "            window = 5\n",
    "            smooth_improvements = []\n",
    "            for i in range(len(improvements)):\n",
    "                start = max(0, i - window + 1)\n",
    "                smooth_improvements.append(np.mean(improvements[start:i+1]))\n",
    "            \n",
    "            ax2.plot(range(len(smooth_improvements)), smooth_improvements, \n",
    "                    color='purple', linewidth=2.5, label='Smoothed')\n",
    "            ax2.scatter(range(len(improvements)), improvements, \n",
    "                       alpha=0.4, s=30, c='gray', label='Raw')\n",
    "            \n",
    "            ax2.set_xlabel('Iteration', fontsize=11, fontweight='bold')\n",
    "            ax2.set_ylabel('Improvement per Cost Unit', fontsize=10, fontweight='bold')\n",
    "            ax2.set_title('Sample Efficiency\\n(Higher = Better)', fontsize=11, fontweight='bold')\n",
    "            ax2.legend(fontsize=9)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ========== Panel 3: Cost Breakdown by Phase ==========\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        \n",
    "        # Calculate costs by phase\n",
    "        phase_names = ['Initial\\nSampling', 'Fast\\nExploration\\n(30d)', 'Full\\nPrecision\\n(180d)']\n",
    "        phase_costs = [0, 0, 0]\n",
    "        phase_iters = [0, 0, 0]\n",
    "        \n",
    "        n_init = self.optimizer.n_initial_samples\n",
    "        for i, cost in enumerate(cost_per_iteration):\n",
    "            if i < n_init:\n",
    "                phase_costs[0] += cost\n",
    "                phase_iters[0] += 1\n",
    "            elif i < 40:\n",
    "                phase_costs[1] += cost\n",
    "                phase_iters[1] += 1\n",
    "            else:\n",
    "                phase_costs[2] += cost\n",
    "                phase_iters[2] += 1\n",
    "        \n",
    "        colors_phase = ['orange', 'lightblue', 'lightcoral']\n",
    "        bars = ax3.bar(phase_names, phase_costs, color=colors_phase, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax3.set_ylabel('Total Computational Cost', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Cost Breakdown by Phase', fontsize=11, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add iteration counts and percentages\n",
    "        for bar, cost, n_iter in zip(bars, phase_costs, phase_iters):\n",
    "            height = bar.get_height()\n",
    "            pct = cost / sum(phase_costs) * 100\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{cost:.1f}\\n({n_iter} iters)\\n{pct:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 4: Improvements Found by Phase ==========\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        \n",
    "        # Count new bests found in each phase\n",
    "        best_found_phase = [0, 0, 0]\n",
    "        current_best = np.inf\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            if np.isfinite(loss) and loss < current_best:\n",
    "                current_best = loss\n",
    "                if i < n_init:\n",
    "                    best_found_phase[0] += 1\n",
    "                elif i < 40:\n",
    "                    best_found_phase[1] += 1\n",
    "                else:\n",
    "                    best_found_phase[2] += 1\n",
    "        \n",
    "        bars2 = ax4.bar(phase_names, best_found_phase, color=colors_phase, alpha=0.7, \n",
    "                       edgecolor='black', linewidth=2)\n",
    "        ax4.set_ylabel('Number of Improvements Found', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title('Improvements Discovered by Phase', fontsize=11, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, count in zip(bars2, best_found_phase):\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{int(count)}', ha='center', va='bottom', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 5: Efficiency Summary ==========\n",
    "        ax5 = fig.add_subplot(gs[1, 2])\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        total_simulations = len(y_samples)\n",
    "        total_cost_units = cumulative_cost[-1] if cumulative_cost else 0\n",
    "        avg_cost_per_iter = total_cost_units / total_simulations if total_simulations > 0 else 0\n",
    "        \n",
    "        if self.optimizer.baseline_loss:\n",
    "            total_improvement = self.optimizer.baseline_loss - self.optimizer.best_loss\n",
    "            improvement_pct = total_improvement / self.optimizer.baseline_loss * 100\n",
    "            cost_per_pct_improvement = total_cost_units / improvement_pct if improvement_pct > 0 else np.inf\n",
    "        else:\n",
    "            total_improvement = 0\n",
    "            improvement_pct = 0\n",
    "            cost_per_pct_improvement = np.inf\n",
    "        \n",
    "        # Phase efficiency\n",
    "        phase_efficiency = []\n",
    "        for i in range(3):\n",
    "            if phase_costs[i] > 0 and best_found_phase[i] > 0:\n",
    "                eff = best_found_phase[i] / phase_costs[i]\n",
    "                phase_efficiency.append(eff)\n",
    "            else:\n",
    "                phase_efficiency.append(0)\n",
    "        \n",
    "        summary_lines = [\n",
    "            \"COMPUTATIONAL EFFICIENCY SUMMARY\",\n",
    "            \"=\" * 35,\n",
    "            \"\",\n",
    "            f\"Total Iterations: {total_simulations}\",\n",
    "            f\"Total Cost: {total_cost_units:.1f} units\",\n",
    "            f\"  (1 unit = one 30-day simulation)\",\n",
    "            f\"Avg Cost/Iter: {avg_cost_per_iter:.2f} units\",\n",
    "            \"\",\n",
    "            f\"Total Improvement: {improvement_pct:.1f}%\",\n",
    "            f\"Cost per 1% Improvement: {cost_per_pct_improvement:.2f} units\",\n",
    "            \"\",\n",
    "            \"Phase Efficiency (improvements/cost):\",\n",
    "            f\"  Initial: {phase_efficiency[0]:.3f}\",\n",
    "            f\"  Fast (30d): {phase_efficiency[1]:.3f}\",\n",
    "            f\"  Full (180d): {phase_efficiency[2]:.3f}\",\n",
    "            \"\",\n",
    "            \"INTERPRETATION:\",\n",
    "            \"• Higher efficiency = more improvements\",\n",
    "            \"  per computational cost\",\n",
    "            \"• Fast phase should have high efficiency\",\n",
    "            \"• Full phase validates with precision\",\n",
    "        ]\n",
    "        \n",
    "        summary_text = '\\n'.join(summary_lines)\n",
    "        ax5.text(0.05, 0.95, summary_text, transform=ax5.transAxes,\n",
    "                fontsize=9, verticalalignment='top', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Computational Efficiency Analysis', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Saved efficiency analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def create_all_plots(self):\n",
    "        \"\"\"Generate all visualization plots\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING VISUALIZATION SUITE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self.plot_comprehensive_analysis()\n",
    "        self.plot_parameter_sensitivity_heatmap()\n",
    "        self.plot_computational_efficiency()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"✓ All visualizations complete!\")\n",
    "        print(\"  - optimization_analysis.png: Loss curves, parameters, trust region\")\n",
    "        print(\"  - parameter_sensitivity.png: Which parameters matter most\")\n",
    "        print(\"  - computational_efficiency.png: Cost vs improvement analysis\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 3-WAY COMPARISON VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_three_way_comparison(highres_results, lowres_default_results, lowres_optimized_results, \n",
    "                                 save_path='three_way_comparison.png'):\n",
    "    \"\"\"\n",
    "    Compare high-res vs low-res default vs low-res optimized\n",
    "    Shows spatial fields and quantitative metrics using contourf\n",
    "    NOTE: Uses last 30 days for all (assumes all are 180-day runs)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING 3-WAY COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Compute losses with FIXED window (last 30 days) for fair comparison\n",
    "    loss_default, fields_default = compute_loss(lowres_default_results, highres_results, \n",
    "                                                n_days_avg=30, return_fields=True, adaptive_window=False)\n",
    "    loss_optimized, fields_optimized = compute_loss(lowres_optimized_results, highres_results, \n",
    "                                                    n_days_avg=30, return_fields=True, adaptive_window=False)\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement_pct = (loss_default - loss_optimized) / loss_default * 100\n",
    "    \n",
    "    # Helper function for consistent contourf plotting\n",
    "    def add_contourf(ax, data, levels, cmap, title=None):\n",
    "        cf = ax.contourf(data, levels=levels, cmap=cmap, extend='both', origin='lower')\n",
    "        ax.set_title(title or \"\", fontsize=11, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        return cf\n",
    "    \n",
    "    # Create figure/grid\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "    gs = gridspec.GridSpec(4, 3, figure=fig, hspace=0.35, wspace=0.25)\n",
    "    \n",
    "    # ========== Row 1: Potential Vorticity Fields (contourf) ==========\n",
    "    q_ref = fields_default['q_bt_hr_coarse']\n",
    "    qmin, qmax = float(np.nanmin(q_ref)), float(np.nanmax(q_ref))\n",
    "    q_levels = np.linspace(qmin, qmax, 31)  # shared discrete levels -> consistent color meaning\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    cf1 = add_contourf(ax1, q_ref, q_levels, 'RdBu_r',\n",
    "                       'High-Res (Ground Truth)\\nPotential Vorticity')\n",
    "    plt.colorbar(cf1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    cf2 = add_contourf(ax2, fields_default['q_bt_lr'], q_levels, 'RdBu_r',\n",
    "                       f'Low-Res DEFAULT\\nLoss: {loss_default:.4f}')\n",
    "    ax2.title.set_color('red')\n",
    "    plt.colorbar(cf2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    cf3 = add_contourf(ax3, fields_optimized['q_bt_lr'], q_levels, 'RdBu_r',\n",
    "                       f'Low-Res OPTIMIZED\\nLoss: {loss_optimized:.4f}')\n",
    "    ax3.title.set_color('green')\n",
    "    plt.colorbar(cf3, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # ========== Row 2: PV Error Maps (contourf) ==========\n",
    "    error_default = np.abs(fields_default['q_bt_lr'] - fields_default['q_bt_hr_coarse'])\n",
    "    error_optimized = np.abs(fields_optimized['q_bt_lr'] - fields_optimized['q_bt_hr_coarse'])\n",
    "    errmax = float(max(np.nanmax(error_default), np.nanmax(error_optimized)))\n",
    "    err_levels = np.linspace(0.0, errmax, 31)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.text(0.5, 0.5, 'Reference\\n(zero error)', ha='center', va='center',\n",
    "             transform=ax4.transAxes, fontsize=14, fontweight='bold', color='green')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    cf5 = add_contourf(ax5, error_default, err_levels, 'magma',\n",
    "                       f'DEFAULT Error (PV)\\nNRMSE: {fields_default[\"loss_q_bt\"]:.4f}')\n",
    "    plt.colorbar(cf5, ax=ax5, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    cf6 = add_contourf(ax6, error_optimized, err_levels, 'magma',\n",
    "                       f'OPTIMIZED Error (PV)\\nNRMSE: {fields_optimized[\"loss_q_bt\"]:.4f}')\n",
    "    plt.colorbar(cf6, ax=ax6, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # ========== Row 3: Streamfunction Fields (contourf, fixed cmap + range) ==========\n",
    "    psi_ref = fields_default['psi_bt_hr_coarse']\n",
    "    # symmetric about zero for a proper diverging map\n",
    "    psi_absmax = float(np.nanmax(np.abs(psi_ref)))\n",
    "    psi_levels = np.linspace(-psi_absmax, psi_absmax, 41)  # same levels across panels\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[2, 0])\n",
    "    cf7 = add_contourf(ax7, psi_ref, psi_levels, 'RdBu_r', 'High-Res\\nStreamfunction')\n",
    "    plt.colorbar(cf7, ax=ax7, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[2, 1])\n",
    "    cf8 = add_contourf(ax8, fields_default['psi_bt_lr'], psi_levels, 'RdBu_r', 'Low-Res DEFAULT')\n",
    "    ax8.title.set_color('red')\n",
    "    plt.colorbar(cf8, ax=ax8, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    ax9 = fig.add_subplot(gs[2, 2])\n",
    "    cf9 = add_contourf(ax9, fields_optimized['psi_bt_lr'], psi_levels, 'RdBu_r', 'Low-Res OPTIMIZED')\n",
    "    ax9.title.set_color('green')\n",
    "    plt.colorbar(cf9, ax=ax9, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # ========== Row 4: Metrics Comparison ==========\n",
    "    ax10 = fig.add_subplot(gs[3, :])\n",
    "    \n",
    "    metrics = {\n",
    "        'Configuration': ['High-Res (Reference)', 'Low-Res DEFAULT', 'Low-Res OPTIMIZED'],\n",
    "        'PV Loss': [0.0, fields_default['loss_q_bt'], fields_optimized['loss_q_bt']],\n",
    "        'Streamfn Loss': [0.0, fields_default['loss_psi_bt'], fields_optimized['loss_psi_bt']],\n",
    "        'Total Loss': [0.0, loss_default, loss_optimized],\n",
    "    }\n",
    "    \n",
    "    x = np.arange(3)\n",
    "    width = 0.25\n",
    "    bars1 = ax10.bar(x - width, metrics['PV Loss'], width, label='PV Loss', color='steelblue', alpha=0.8)\n",
    "    bars2 = ax10.bar(x, metrics['Streamfn Loss'], width, label='Streamfn Loss', color='orange', alpha=0.8)\n",
    "    bars3 = ax10.bar(x + width, metrics['Total Loss'], width, label='Total Loss', color='green', alpha=0.8)\n",
    "    \n",
    "    ax10.set_ylabel('Loss (NRMSE)', fontsize=12, fontweight='bold')\n",
    "    ax10.set_xticks(x)\n",
    "    ax10.set_xticklabels(metrics['Configuration'], fontsize=11)\n",
    "    ax10.legend(fontsize=10, loc='upper left')\n",
    "    ax10.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax10.text(0.98, 0.98, f'IMPROVEMENT: {improvement_pct:.1f}%\\n({loss_default:.4f} → {loss_optimized:.4f})',\n",
    "              transform=ax10.transAxes, fontsize=12, fontweight='bold',\n",
    "              va='top', ha='right', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            h = bar.get_height()\n",
    "            if h > 0:\n",
    "                ax10.text(bar.get_x() + bar.get_width()/2., h, f'{h:.4f}',\n",
    "                          ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('3-Way Comparison: High-Res vs Low-Res Default vs Low-Res Optimized',\n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    print(f\"✓ Saved 3-way comparison: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARISON SUMMARY (All using last 30 days)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"High-Res (Reference):\")\n",
    "    print(f\"  Resolution: {highres_results['config']['nx']}x{highres_results['config']['ny']}\")\n",
    "    print(f\"  Time window: last 30 days (equilibrated state)\")\n",
    "    print(f\"\\nLow-Res DEFAULT:\")\n",
    "    print(f\"  Resolution: {lowres_default_results['config']['nx']}x{lowres_default_results['config']['ny']}\")\n",
    "    print(f\"  PV Loss: {fields_default['loss_q_bt']:.6f}\")\n",
    "    print(f\"  Streamfn Loss: {fields_default['loss_psi_bt']:.6f}\")\n",
    "    print(f\"  Total Loss: {loss_default:.6f}\")\n",
    "    print(f\"\\nLow-Res OPTIMIZED:\")\n",
    "    print(f\"  Resolution: {lowres_optimized_results['config']['nx']}x{lowres_optimized_results['config']['ny']}\")\n",
    "    print(f\"  PV Loss: {fields_optimized['loss_q_bt']:.6f}\")\n",
    "    print(f\"  Streamfn Loss: {fields_optimized['loss_psi_bt']:.6f}\")\n",
    "    print(f\"  Total Loss: {loss_optimized:.6f}\")\n",
    "    print(f\"\\n{Colors.star(f'IMPROVEMENT: {improvement_pct:.1f}%')}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Enhanced GP Optimizer with visualization and warm-start\n",
    "class EnhancedGPOptimizer:\n",
    "    \"\"\"Enhanced GP with visualization, warm-start, and 3-way comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, n_initial_samples=15, random_seed=42):\n",
    "        self.n_initial_samples = n_initial_samples\n",
    "        self.random_seed = random_seed  # Store for reproducibility\n",
    "        self.X_samples, self.y_samples, self.detailed_outputs = [], [], []\n",
    "        self.best_loss, self.best_params, self.best_iteration = np.inf, None, -1\n",
    "        self.iteration, self.iterations_without_improvement = 0, 0\n",
    "        self.stagnation_threshold = 15\n",
    "        self.gp = EnsembleGP(n_models=8)\n",
    "        self.trust_region = TrustRegion()\n",
    "        self.importance_history = []\n",
    "        self.use_thompson_sampling_prob = 0.1\n",
    "        self.baseline_loss = None  # Track default params loss at FINAL fidelity\n",
    "        self.baseline_loss_by_fidelity = {}  # Track baseline for each fidelity level\n",
    "        self.default_results = None  # Store default results for comparison\n",
    "        self.current_fidelity = None  # Track current fidelity level\n",
    "        self.best_params_original_iteration = None  # Track when best params were first discovered\n",
    "        \n",
    "        # Set numpy random seed for reproducibility\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    def optimize(self, config_base, highres_results, max_iterations=100):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ENHANCED GP: WARM-START + 2-LEVEL MULTI-FIDELITY + VISUALIZATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Features:\")\n",
    "        print(\"  ✓ Warm-start from reference parameters\")\n",
    "        print(\"  ✓ 8-model weighted ensemble\")\n",
    "        print(\"  ✓ Local penalization (space coverage)\")\n",
    "        print(\"  ✓ 2-level multi-fidelity strategy:\")\n",
    "        print(\"    • Iterations 0-40:  30-day runs (fast exploration, ~6x speedup)\")\n",
    "        print(\"    • Iterations 40+:   180-day runs (full precision)\")\n",
    "        print(\"  ✓ Adaptive time windows for fair comparison:\")\n",
    "        print(\"    • 30-day runs: compare entire simulation (days 0-30)\")\n",
    "        print(\"    • 180-day runs: compare last 30 days (equilibrated)\")\n",
    "        print(\"  ✓ Fidelity-aware baseline tracking\")\n",
    "        print(\"  ✓ Thompson sampling (10% exploration)\")\n",
    "        print(\"  ✓ Anti-stagnation (auto-restart)\")\n",
    "        print(\"  ✓ 3-way comparison visualization\")\n",
    "        print(f\"  Max iterations: {max_iterations}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Phase 1: Initial sampling with WARM-START\n",
    "        n_existing = len(self.X_samples)\n",
    "        if n_existing < self.n_initial_samples:\n",
    "            print(f\"\\n{'='*70}\\nPHASE 1: WARM-START INITIALIZATION (seed={self.random_seed})\\n{'='*70}\")\n",
    "            initial_samples = generate_smart_initial_samples(self.n_initial_samples, \n",
    "                                                            include_default=True,\n",
    "                                                            base_seed=self.random_seed)\n",
    "            \n",
    "            for i, params in enumerate(initial_samples[n_existing:]):\n",
    "                iter_num = i + n_existing\n",
    "                is_default = (iter_num == 0 and n_existing == 0)  # First sample is default\n",
    "                \n",
    "                print(f\"\\n[Initial {iter_num+1}/{self.n_initial_samples}]\" + \n",
    "                      (Colors.star(\" DEFAULT PARAMETERS\") if is_default else \"\"))\n",
    "                \n",
    "                loss, results, detailed = run_lowres_with_params(\n",
    "                    params, config_base, highres_results, iteration=iter_num\n",
    "                )\n",
    "                self.X_samples.append(params)\n",
    "                self.y_samples.append(loss)\n",
    "                self.detailed_outputs.append(detailed)\n",
    "                \n",
    "                # Track baseline from default params\n",
    "                if is_default and np.isfinite(loss):\n",
    "                    _, fidelity_desc = get_adaptive_sim_days(iter_num)\n",
    "                    self.current_fidelity = fidelity_desc\n",
    "                    self.baseline_loss = loss\n",
    "                    self.baseline_loss_by_fidelity[fidelity_desc] = loss\n",
    "                    self.default_results = results\n",
    "                    print(Colors.cyan(f\"  → Baseline loss at {fidelity_desc}: {loss:.6f}\"))\n",
    "                \n",
    "                if np.isfinite(loss) and loss < self.best_loss:\n",
    "                    self.best_loss, self.best_params = loss, params.copy()\n",
    "                    self.best_iteration, self.iterations_without_improvement = len(self.X_samples) - 1, 0\n",
    "                    self.best_params_original_iteration = iter_num  # Track discovery iteration\n",
    "                    if is_default:\n",
    "                        print(Colors.star(f\"BASELINE SET: {Colors.green(f'{loss:.6f}')}\"))\n",
    "                    else:\n",
    "                        # Compare to baseline at SAME fidelity\n",
    "                        _, fidelity_desc = get_adaptive_sim_days(iter_num)\n",
    "                        fidelity_baseline = self.baseline_loss_by_fidelity.get(fidelity_desc, self.baseline_loss)\n",
    "                        if fidelity_baseline:\n",
    "                            improvement = (fidelity_baseline - loss) / fidelity_baseline * 100\n",
    "                            print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')} ({improvement:+.1f}% vs baseline @ {fidelity_desc})\"))\n",
    "                        else:\n",
    "                            print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')}\"))\n",
    "                self.save_progress()\n",
    "        \n",
    "        # Phase 2: Bayesian optimization\n",
    "        print(f\"\\n{'='*70}\\nPHASE 2: BAYESIAN OPTIMIZATION\\n{'='*70}\")\n",
    "        \n",
    "        for iteration in range(len(self.X_samples), max_iterations):\n",
    "            self.iteration, self.iterations_without_improvement = iteration, self.iterations_without_improvement + 1\n",
    "            \n",
    "            print(f\"\\n{'='*70}\\n{Colors.cyan(f'ITERATION {iteration + 1}/{max_iterations}')}\\n{'='*70}\")\n",
    "            \n",
    "            # Check if fidelity level changed - if so, re-evaluate baseline AND best params\n",
    "            _, fidelity_desc = get_adaptive_sim_days(iteration)\n",
    "            if fidelity_desc != self.current_fidelity:\n",
    "                old_fidelity = self.current_fidelity\n",
    "                self.current_fidelity = fidelity_desc\n",
    "                print(Colors.red(f\"\\n{'='*70}\"))\n",
    "                print(Colors.red(f\"⚠ FIDELITY TRANSITION: {old_fidelity} → {fidelity_desc}\"))\n",
    "                print(Colors.red(f\"{'='*70}\"))\n",
    "                \n",
    "                # Re-evaluate baseline at new fidelity if not already done\n",
    "                if fidelity_desc not in self.baseline_loss_by_fidelity:\n",
    "                    print(Colors.cyan(f\"→ Re-evaluating BASELINE at {fidelity_desc} fidelity...\"))\n",
    "                    default_array = params_dict_to_array(DEFAULT_PARAMS)\n",
    "                    baseline_loss, baseline_results, _ = run_lowres_with_params(\n",
    "                        default_array, config_base, highres_results, iteration=iteration\n",
    "                    )\n",
    "                    if np.isfinite(baseline_loss):\n",
    "                        self.baseline_loss_by_fidelity[fidelity_desc] = baseline_loss\n",
    "                        self.baseline_loss = baseline_loss\n",
    "                        # Store the results if this is the final fidelity\n",
    "                        if fidelity_desc == 'FULL (180d)':\n",
    "                            self.default_results = baseline_results\n",
    "                        print(Colors.cyan(f\"→ Baseline at {fidelity_desc}: {baseline_loss:.6f}\"))\n",
    "                    else:\n",
    "                        print(Colors.red(f\"→ Baseline evaluation failed at {fidelity_desc}\"))\n",
    "                \n",
    "                # CRITICAL: Re-evaluate current best parameters at new fidelity!\n",
    "                if self.best_params is not None:\n",
    "                    print(Colors.yellow(f\"\\n→ Re-evaluating BEST PARAMETERS at {fidelity_desc} fidelity...\"))\n",
    "                    print(Colors.yellow(f\"   Old best loss ({old_fidelity}): {self.best_loss:.6f}\"))\n",
    "                    \n",
    "                    best_loss_new_fidelity, _, _ = run_lowres_with_params(\n",
    "                        self.best_params, config_base, highres_results, iteration=iteration\n",
    "                    )\n",
    "                    \n",
    "                    if np.isfinite(best_loss_new_fidelity):\n",
    "                        old_best = self.best_loss\n",
    "                        self.best_loss = best_loss_new_fidelity\n",
    "                        print(Colors.yellow(f\"   New best loss ({fidelity_desc}): {best_loss_new_fidelity:.6f}\"))\n",
    "                        \n",
    "                        # Calculate change\n",
    "                        change_pct = (best_loss_new_fidelity - old_best) / old_best * 100\n",
    "                        if change_pct > 0:\n",
    "                            print(Colors.red(f\"   ⚠ Loss INCREASED by {change_pct:.1f}% at higher fidelity\"))\n",
    "                        else:\n",
    "                            print(Colors.green(f\"   ✓ Loss decreased by {-change_pct:.1f}% at higher fidelity\"))\n",
    "                        \n",
    "                        # Compare to new baseline\n",
    "                        if fidelity_desc in self.baseline_loss_by_fidelity:\n",
    "                            improvement = (self.baseline_loss_by_fidelity[fidelity_desc] - best_loss_new_fidelity) / \\\n",
    "                                        self.baseline_loss_by_fidelity[fidelity_desc] * 100\n",
    "                            print(Colors.cyan(f\"   → Improvement vs {fidelity_desc} baseline: {improvement:+.1f}%\"))\n",
    "                    else:\n",
    "                        print(Colors.red(f\"   ✗ Re-evaluation failed, keeping old best loss\"))\n",
    "                \n",
    "                print(Colors.red(f\"{'='*70}\\n\"))\n",
    "            \n",
    "            # Stagnation check\n",
    "            if self.iterations_without_improvement >= self.stagnation_threshold:\n",
    "                print(Colors.red(f\"\\n⚠ STAGNATION: {self.iterations_without_improvement} iterations w/o improvement\"))\n",
    "                print(Colors.yellow(\"→ Triggering exploration restart\"))\n",
    "                self.trigger_exploration_restart()\n",
    "            \n",
    "            # Fit GP\n",
    "            X_warped = np.array([warp_parameters(x) for x in self.X_samples])\n",
    "            y_array = np.array(self.y_samples)\n",
    "            valid_mask = np.isfinite(y_array)\n",
    "            n_valid = np.sum(valid_mask)\n",
    "            \n",
    "            print(f\"Valid samples: {Colors.cyan(str(n_valid))}/{len(y_array)}\")\n",
    "            \n",
    "            kappa = self.get_adaptive_kappa()\n",
    "            if kappa > 2.0:\n",
    "                print(Colors.yellow(f\"  ℹ Increased exploration: kappa = {kappa:.1f}\"))\n",
    "            \n",
    "            # Thompson sampling with some probability\n",
    "            use_thompson = np.random.rand() < self.use_thompson_sampling_prob\n",
    "            \n",
    "            if n_valid < 5:\n",
    "                print(Colors.yellow(\"  ⚠ Too few valid samples, random exploration\"))\n",
    "                next_params = unwarp_parameters(np.random.uniform(0, 1, N_PARAMS))\n",
    "            elif use_thompson:\n",
    "                print(Colors.cyan(\"  → Using Thompson sampling for exploration\"))\n",
    "                X_valid, y_valid = X_warped[valid_mask], y_array[valid_mask]\n",
    "                self.gp.fit(X_valid, y_valid)\n",
    "                \n",
    "                # Track parameter importance even with Thompson sampling\n",
    "                importance = self.gp.get_parameter_importance()\n",
    "                self.importance_history.append(importance)\n",
    "                \n",
    "                # Print top 3 most important parameters\n",
    "                sorted_indices = np.argsort(importance)[::-1][:3]\n",
    "                print(\"  Top 3 important parameters:\")\n",
    "                for rank, idx in enumerate(sorted_indices, 1):\n",
    "                    print(f\"    {rank}. {PARAM_NAMES[idx]}: {importance[idx]:.3f}\")\n",
    "                \n",
    "                tr_bounds = self.trust_region.get_trust_region_bounds()\n",
    "                thompson_sample = thompson_sampling(self.gp, tr_bounds, n_samples=1)[0]\n",
    "                next_params = unwarp_parameters(thompson_sample)\n",
    "            else:\n",
    "                X_valid, y_valid = X_warped[valid_mask], y_array[valid_mask]\n",
    "                print(\"  Fitting 8-model ensemble GP...\")\n",
    "                self.gp.fit(X_valid, y_valid)\n",
    "                \n",
    "                # Track parameter importance\n",
    "                importance = self.gp.get_parameter_importance()\n",
    "                self.importance_history.append(importance)\n",
    "                \n",
    "                # Print parameter importance (show relative values)\n",
    "                print(\"  Parameter importance (relative):\")\n",
    "                sorted_indices = np.argsort(importance)[::-1]  # Sort descending\n",
    "                for rank, idx in enumerate(sorted_indices, 1):\n",
    "                    name = PARAM_NAMES[idx]\n",
    "                    imp_val = importance[idx]\n",
    "                    if rank <= 3:\n",
    "                        imp_str = f\"{Colors.green('HIGH')}\"\n",
    "                    elif rank <= 5:\n",
    "                        imp_str = f\"{Colors.cyan('med')}\"\n",
    "                    else:\n",
    "                        imp_str = \"low\"\n",
    "                    print(f\"    {rank}. {name}: {imp_val:.3f} ({imp_str})\")\n",
    "                \n",
    "                # Update trust region\n",
    "                if self.best_params is not None:\n",
    "                    self.trust_region.best_center = warp_parameters(self.best_params)\n",
    "                \n",
    "                tr_bounds = self.trust_region.get_trust_region_bounds()\n",
    "                print(f\"  Trust region: {Colors.cyan(f'{self.trust_region.trust_radius:.2f}')}\")\n",
    "                \n",
    "                # Optimize acquisition\n",
    "                print(f\"  Optimizing acquisition (kappa={kappa:.1f})...\")\n",
    "                best_y = np.min(y_valid)\n",
    "                acq_fn = lambda X: hybrid_acquisition_with_penalization(\n",
    "                    X, self.gp, best_y, self.X_samples, xi=0.01, kappa=kappa, penalization_weight=0.3\n",
    "                )\n",
    "                \n",
    "                next_params_warped = optimize_acquisition_multistart(acq_fn, tr_bounds, n_starts=20, n_random=1000)\n",
    "                acq_val = acq_fn(next_params_warped.reshape(1, -1))[0]\n",
    "                print(f\"  Selected point (acq={Colors.cyan(f'{acq_val:.4f}')})\")\n",
    "                next_params = unwarp_parameters(next_params_warped)\n",
    "            \n",
    "            # Evaluate with adaptive fidelity\n",
    "            loss, results, detailed = run_lowres_with_params(\n",
    "                next_params, config_base, highres_results, iteration=iteration\n",
    "            )\n",
    "            self.X_samples.append(next_params)\n",
    "            self.y_samples.append(loss)\n",
    "            self.detailed_outputs.append(detailed)\n",
    "            \n",
    "            # Update best\n",
    "            new_best = False\n",
    "            if np.isfinite(loss) and loss < self.best_loss:\n",
    "                self.best_loss, self.best_params = loss, next_params.copy()\n",
    "                self.best_iteration, self.iterations_without_improvement = iteration, 0\n",
    "                self.best_params_original_iteration = iteration  # Track discovery iteration\n",
    "                new_best = True\n",
    "                # Compare to baseline at CURRENT fidelity\n",
    "                fidelity_baseline = self.baseline_loss_by_fidelity.get(self.current_fidelity, self.baseline_loss)\n",
    "                if fidelity_baseline:\n",
    "                    improvement = (fidelity_baseline - loss) / fidelity_baseline * 100\n",
    "                    print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')} ({improvement:+.1f}% vs baseline @ {self.current_fidelity})\"))\n",
    "                else:\n",
    "                    print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')}\"))\n",
    "            \n",
    "            self.trust_region.update(new_best, warp_parameters(self.best_params) if new_best else None)\n",
    "            self.print_status()\n",
    "            self.save_progress()\n",
    "            \n",
    "            # Generate plots every 10 iterations\n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                print(\"\\n  Generating visualization...\")\n",
    "                visualizer = OptimizationVisualizer(self)\n",
    "                visualizer.create_all_plots()\n",
    "        \n",
    "        # Final visualization\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING FINAL VISUALIZATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        visualizer = OptimizationVisualizer(self)\n",
    "        visualizer.create_all_plots()\n",
    "        \n",
    "        return self.get_best_params()\n",
    "    \n",
    "    def get_adaptive_kappa(self):\n",
    "        \"\"\"Adaptive kappa: higher when stuck\"\"\"\n",
    "        if self.iterations_without_improvement < 6:\n",
    "            return 2.0\n",
    "        elif self.iterations_without_improvement < 10:\n",
    "            return 3.0\n",
    "        return 4.0\n",
    "    \n",
    "    def trigger_exploration_restart(self):\n",
    "        \"\"\"Reset trust region and add random sample\"\"\"\n",
    "        self.trust_region.reset_for_exploration()\n",
    "        print(Colors.yellow(\"  → Random sample will be added next\"))\n",
    "        self.iterations_without_improvement = 0\n",
    "        print(Colors.green(\"  ✓ Restart complete\"))\n",
    "    \n",
    "    def print_status(self):\n",
    "        \"\"\"Print status with fidelity-aware baseline comparison\"\"\"\n",
    "        n_valid = np.sum(np.isfinite(self.y_samples))\n",
    "        n_failed = len(self.y_samples) - n_valid\n",
    "        print(f\"\\n{Colors.bold('Status:')}\")\n",
    "        print(f\"  Valid: {Colors.cyan(str(n_valid))}/{len(self.y_samples)}\")\n",
    "        print(f\"  Failed: {Colors.yellow(str(n_failed))}\")\n",
    "        \n",
    "        # Show current fidelity\n",
    "        if self.current_fidelity:\n",
    "            print(f\"  Current fidelity: {Colors.cyan(self.current_fidelity)}\")\n",
    "        \n",
    "        # Show baselines for each fidelity\n",
    "        if self.baseline_loss_by_fidelity:\n",
    "            print(f\"  Baselines by fidelity:\")\n",
    "            for fidelity, baseline in sorted(self.baseline_loss_by_fidelity.items()):\n",
    "                print(f\"    {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "        \n",
    "        # Compare best to baseline at current fidelity\n",
    "        if self.best_params_original_iteration is not None:\n",
    "            print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{self.best_loss:.6f}')} \" +\n",
    "                  Colors.cyan(f'(discovered at iteration {self.best_params_original_iteration + 1})'))\n",
    "        else:\n",
    "            print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{self.best_loss:.6f}')} \" +\n",
    "                  Colors.cyan(f'(iteration {self.best_iteration + 1})'))\n",
    "        \n",
    "        if self.current_fidelity and self.current_fidelity in self.baseline_loss_by_fidelity:\n",
    "            fidelity_baseline = self.baseline_loss_by_fidelity[self.current_fidelity]\n",
    "            improvement = (fidelity_baseline - self.best_loss) / fidelity_baseline * 100\n",
    "            print(f\"    → vs {self.current_fidelity} baseline: {Colors.green(f'{improvement:+.1f}%')}\")\n",
    "        \n",
    "        stag_str = f\"{self.iterations_without_improvement}/{self.stagnation_threshold}\"\n",
    "        stag_str = Colors.yellow(stag_str) if self.iterations_without_improvement >= 10 else Colors.cyan(stag_str)\n",
    "        print(f\"  Iterations w/o improvement: {stag_str}\")\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"No valid parameters found!\")\n",
    "        return {PARAM_NAMES[i]: float(self.best_params[i]) for i in range(N_PARAMS)}\n",
    "    \n",
    "    def save_progress(self, filename='enhanced_gp_progress.pkl'):\n",
    "        data = {\n",
    "            'X_samples': self.X_samples, 'y_samples': self.y_samples, 'detailed_outputs': self.detailed_outputs,\n",
    "            'best_loss': self.best_loss, 'best_params': self.best_params, 'best_iteration': self.best_iteration,\n",
    "            'best_params_original_iteration': self.best_params_original_iteration,\n",
    "            'iteration': self.iteration, 'iterations_without_improvement': self.iterations_without_improvement,\n",
    "            'trust_region_state': {'radius': self.trust_region.trust_radius, 'center': self.trust_region.best_center,\n",
    "                                  'success_count': self.trust_region.success_count, 'fail_count': self.trust_region.fail_count},\n",
    "            'importance_history': self.importance_history,\n",
    "            'baseline_loss': self.baseline_loss,\n",
    "            'baseline_loss_by_fidelity': self.baseline_loss_by_fidelity,\n",
    "            'current_fidelity': self.current_fidelity,\n",
    "            'default_results': self.default_results,\n",
    "            'random_seed': self.random_seed\n",
    "        }\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"  ✓ Progress saved\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_progress(cls, filename='enhanced_gp_progress.pkl'):\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        optimizer = cls(random_seed=data.get('random_seed', 42))\n",
    "        optimizer.X_samples, optimizer.y_samples = data['X_samples'], data['y_samples']\n",
    "        optimizer.detailed_outputs = data['detailed_outputs']\n",
    "        optimizer.best_loss, optimizer.best_params = data['best_loss'], data['best_params']\n",
    "        optimizer.best_iteration, optimizer.iteration = data['best_iteration'], data['iteration']\n",
    "        optimizer.best_params_original_iteration = data.get('best_params_original_iteration', optimizer.best_iteration)\n",
    "        optimizer.iterations_without_improvement = data.get('iterations_without_improvement', 0)\n",
    "        optimizer.importance_history = data.get('importance_history', [])\n",
    "        optimizer.baseline_loss = data.get('baseline_loss', None)\n",
    "        optimizer.baseline_loss_by_fidelity = data.get('baseline_loss_by_fidelity', {})\n",
    "        optimizer.current_fidelity = data.get('current_fidelity', None)\n",
    "        optimizer.default_results = data.get('default_results', None)\n",
    "        \n",
    "        if 'trust_region_state' in data:\n",
    "            tr = data['trust_region_state']\n",
    "            optimizer.trust_region.trust_radius, optimizer.trust_region.best_center = tr['radius'], tr['center']\n",
    "            optimizer.trust_region.success_count, optimizer.trust_region.fail_count = tr['success_count'], tr['fail_count']\n",
    "        \n",
    "        print(f\"✓ Loaded checkpoint (seed={optimizer.random_seed}):\")\n",
    "        print(f\"  Iterations: {len(optimizer.X_samples)}\")\n",
    "        n_valid = np.sum(np.isfinite(optimizer.y_samples))\n",
    "        print(f\"  Valid: {Colors.cyan(str(n_valid))}/{len(optimizer.y_samples)}\")\n",
    "        \n",
    "        if optimizer.baseline_loss_by_fidelity:\n",
    "            print(f\"  Baselines by fidelity:\")\n",
    "            for fidelity, baseline in sorted(optimizer.baseline_loss_by_fidelity.items()):\n",
    "                print(f\"    {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "        \n",
    "        print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{optimizer.best_loss:.6f}')} \" +\n",
    "              Colors.cyan(f'(discovered at iteration {optimizer.best_params_original_iteration + 1})'))\n",
    "        \n",
    "        if optimizer.current_fidelity and optimizer.current_fidelity in optimizer.baseline_loss_by_fidelity:\n",
    "            fidelity_baseline = optimizer.baseline_loss_by_fidelity[optimizer.current_fidelity]\n",
    "            improvement = (fidelity_baseline - optimizer.best_loss) / fidelity_baseline * 100\n",
    "            print(f\"    → vs {optimizer.current_fidelity}: {Colors.green(f'{improvement:+.1f}%')}\")\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "# Main function with 3-way comparison\n",
    "def main(checkpoint_file='enhanced_gp_progress.pkl', max_iterations=100, random_seed=42):\n",
    "    \"\"\"\n",
    "    Main optimization routine with 3-way comparison\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_file: Path to checkpoint file for resuming\n",
    "        max_iterations: Maximum number of optimization iterations\n",
    "        random_seed: Random seed for reproducibility (affects initial sampling and exploration)\n",
    "    \"\"\"\n",
    "    if not os.path.exists('highres_results.pkl'):\n",
    "        print(\"\\n✗ Error: highres_results.pkl not found!\")\n",
    "        return\n",
    "    \n",
    "    with open('highres_results.pkl', 'rb') as f:\n",
    "        highres_results = pickle.load(f)\n",
    "    print(f\"\\n✓ Loaded high-res: {highres_results['config']['nx']}x{highres_results['config']['ny']}\")\n",
    "    \n",
    "    from main_comparison import config_lowres\n",
    "    config_base = config_lowres.copy()\n",
    "    \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"\\n✓ Checkpoint found\")\n",
    "        optimizer = EnhancedGPOptimizer.load_progress(checkpoint_file)\n",
    "    else:\n",
    "        print(f\"\\n✓ Starting new optimization (seed={random_seed})\")\n",
    "        optimizer = EnhancedGPOptimizer(n_initial_samples=18, random_seed=random_seed)\n",
    "    \n",
    "    best_params = optimizer.optimize(config_base, highres_results, max_iterations)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTIMIZATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_valid = np.sum(np.isfinite(optimizer.y_samples))\n",
    "    n_failed = len(optimizer.y_samples) - n_valid\n",
    "    print(f\"\\nTotal iterations: {len(optimizer.y_samples)}\")\n",
    "    print(f\"  Valid: {Colors.cyan(str(n_valid))}\")\n",
    "    print(f\"  Failed: {Colors.yellow(str(n_failed))}\")\n",
    "    \n",
    "    # Show all baselines\n",
    "    if optimizer.baseline_loss_by_fidelity:\n",
    "        print(f\"\\nBaselines by fidelity:\")\n",
    "        for fidelity, baseline in sorted(optimizer.baseline_loss_by_fidelity.items()):\n",
    "            print(f\"  {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "    \n",
    "    # Final comparison at FULL fidelity\n",
    "    final_baseline = optimizer.baseline_loss_by_fidelity.get('FULL (180d)', optimizer.baseline_loss)\n",
    "    if final_baseline:\n",
    "        improvement = (final_baseline - optimizer.best_loss) / final_baseline * 100\n",
    "        print(f\"\\n{Colors.bold('Final Comparison at FULL (180d) Fidelity:')}\")\n",
    "        print(f\"  Baseline (default): {Colors.cyan(f'{final_baseline:.6f}')}\")\n",
    "        print(f\"  Best loss: {Colors.green(f'{optimizer.best_loss:.6f}')} \" +\n",
    "              Colors.green(f'[{improvement:+.1f}% improvement]'))\n",
    "        \n",
    "        # Show discovery info\n",
    "        if optimizer.best_params_original_iteration is not None:\n",
    "            print(f\"  Best parameters discovered at: iteration {optimizer.best_params_original_iteration + 1}\")\n",
    "            if optimizer.best_params_original_iteration < 40:\n",
    "                print(Colors.yellow(f\"    (during 30-day fast exploration phase)\"))\n",
    "                print(Colors.cyan(f\"    Loss was re-evaluated at full 180-day fidelity\"))\n",
    "            else:\n",
    "                print(Colors.cyan(f\"    (during 180-day full precision phase)\"))\n",
    "    else:\n",
    "        print(f\"\\n{Colors.bold('Best loss:')} {Colors.green(f'{optimizer.best_loss:.6f}')}\")\n",
    "        print(Colors.yellow(\"  Note: No full-fidelity baseline available\"))\n",
    "    \n",
    "    print(f\"\\n{Colors.bold('Best parameters:')}\")\n",
    "    for name, val in best_params.items():\n",
    "        default_val = DEFAULT_PARAMS[name]\n",
    "        change = (val - default_val) / default_val * 100 if default_val != 0 else 0\n",
    "        print(f\"  {name}: {Colors.cyan(f'{val:.6e}')} (default: {default_val:.6e}, {change:+.1f}%)\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('enhanced_gp_optimal_params.pkl', 'wb') as f:\n",
    "        pickle.dump(best_params, f)\n",
    "    with open('enhanced_gp_optimal_config.txt', 'w') as f:\n",
    "        f.write(\"'subgrid_params': {\\n\")\n",
    "        for name, val in best_params.items():\n",
    "            f.write(f\"    '{name}': {val:.6e},\\n\")\n",
    "        f.write(\"}\\n\")\n",
    "    \n",
    "    print(\"\\n✓ Saved: enhanced_gp_optimal_params.pkl\")\n",
    "    print(\"✓ Saved: enhanced_gp_optimal_config.txt\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NOTE: 2-LEVEL MULTI-FIDELITY WITH ADAPTIVE BASELINES\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"The optimizer uses a simple 2-level fidelity strategy:\")\n",
    "    print(\"  Phase 1 (iterations 0-40):  30-day runs (~6x faster)\")\n",
    "    print(\"    - Compares entire simulation (days 0-30)\")\n",
    "    print(\"    - Baseline tracked at 30-day fidelity\")\n",
    "    print(\"  Phase 2 (iterations 40+):   180-day runs (full precision)\")\n",
    "    print(\"    - Compares last 30 days (equilibrated state)\")\n",
    "    print(\"    - Baseline tracked at 180-day fidelity\")\n",
    "    print(\"\\nThis ensures:\")\n",
    "    print(\"  ✓ Fast exploration in early iterations\")\n",
    "    print(\"  ✓ Fair apples-to-apples comparisons at each fidelity\")\n",
    "    print(\"  ✓ Final results use full 180-day simulations\")\n",
    "    print(\"\\nSeed robustness:\")\n",
    "    print(f\"  ✓ Random seed used: {optimizer.random_seed}\")\n",
    "    print(\"  ✓ Multiple complementary seeds used internally\")\n",
    "    print(\"  ✓ Small perturbations added to reduce grid artifacts\")\n",
    "    print(\"  ℹ Different seeds may find best at different iterations\")\n",
    "    print(\"    but final performance should be similar (~5-10% variation)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Run final simulation with optimized parameters for 3-way comparison\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RUNNING FINAL COMPARISON SIMULATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Ensure we have full-fidelity baseline (180 days)\n",
    "    if 'FULL (180d)' not in optimizer.baseline_loss_by_fidelity or optimizer.default_results is None:\n",
    "        print(\"\\nRunning default parameters at FULL fidelity (180 days)...\")\n",
    "        config_default = config_base.copy()\n",
    "        config_default['subgrid_params'] = DEFAULT_PARAMS\n",
    "        from main_comparison import run_simulation\n",
    "        optimizer.default_results = run_simulation(config_default, sim_days=180, save_interval_hours=12)\n",
    "        \n",
    "        # Compute baseline loss at full fidelity\n",
    "        baseline_loss_full, _ = compute_loss(optimizer.default_results, highres_results, \n",
    "                                             n_days_avg=30, return_fields=False, adaptive_window=False)\n",
    "        optimizer.baseline_loss_by_fidelity['FULL (180d)'] = baseline_loss_full\n",
    "        optimizer.baseline_loss = baseline_loss_full\n",
    "        print(f\"  ✓ Default simulation complete - Loss: {baseline_loss_full:.6f}\")\n",
    "    else:\n",
    "        print(\"\\n✓ Using cached default results at FULL fidelity\")\n",
    "    \n",
    "    # Run optimized parameters simulation (full 180 days for final comparison)\n",
    "    print(\"\\nRunning optimized parameters simulation (full 180 days)...\")\n",
    "    config_optimized = config_base.copy()\n",
    "    config_optimized['subgrid_params'] = best_params\n",
    "    from main_comparison import run_simulation\n",
    "    optimized_results = run_simulation(config_optimized, sim_days=180, save_interval_hours=12)\n",
    "    print(f\"  ✓ Optimized simulation complete\")\n",
    "    \n",
    "    # Create 3-way comparison\n",
    "    create_three_way_comparison(highres_results, optimizer.default_results, optimized_results)\n",
    "    \n",
    "    print(\"\\n✓ Saved: optimization_analysis.png\")\n",
    "    print(\"✓ Saved: parameter_sensitivity.png\")\n",
    "    print(\"✓ Saved: computational_efficiency.png\")\n",
    "    print(\"✓ Saved: three_way_comparison.png\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VISUALIZATION GUIDE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"1. optimization_analysis.png\")\n",
    "    print(\"   → Loss evolution, parameter trajectories, trust region\")\n",
    "    print(\"   → Shows HOW the optimization progressed\")\n",
    "    print(\"\")\n",
    "    print(\"2. parameter_sensitivity.png\")\n",
    "    print(\"   → Correlation analysis, variance explained, ranges explored\")\n",
    "    print(\"   → Shows WHICH parameters matter most\")\n",
    "    print(\"   → Red = increasing parameter worsens loss\")\n",
    "    print(\"   → Green = increasing parameter improves loss\")\n",
    "    print(\"\")\n",
    "    print(\"3. computational_efficiency.png\")\n",
    "    print(\"   → Cost vs improvement, phase breakdown, sample efficiency\")\n",
    "    print(\"   → Shows HOW EFFICIENTLY we found improvements\")\n",
    "    print(\"\")\n",
    "    print(\"4. three_way_comparison.png\")\n",
    "    print(\"   → Spatial fields: high-res vs default vs optimized\")\n",
    "    print(\"   → Shows FINAL RESULTS quality\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return optimizer, best_params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the random_seed parameter to test different initializations\n",
    "    # The optimizer uses multiple complementary seeds internally for robustness\n",
    "    optimizer, best_params = main(max_iterations=80, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0e5439-8e75-4f45-b762-53284e954c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded high-res: 512x256\n",
      "\n",
      "✓ Checkpoint found\n",
      "✓ Loaded checkpoint (seed=23):\n",
      "  Iterations: 30\n",
      "  Valid: \u001b[96m30\u001b[0m/30\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d): \u001b[92m+50.5%\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "ENHANCED GP: WARM-START + DYNAMIC 2-LEVEL MULTI-FIDELITY + VISUALIZATION\n",
      "======================================================================\n",
      "Features:\n",
      "  ✓ Warm-start from reference parameters\n",
      "  ✓ 8-model weighted ensemble\n",
      "  ✓ Local penalization (space coverage)\n",
      "  ✓ Dynamic 2-level multi-fidelity strategy (based on 6 params):\n",
      "    • Initial phase: 24 iterations at 30-day fidelity\n",
      "    • Fast phase: 12 iterations at 30-day fidelity\n",
      "    • Full phase: 12+ iterations at 180-day fidelity\n",
      "  ✓ Adaptive time windows for fair comparison:\n",
      "    • 30-day runs: compare entire simulation (days 0-30)\n",
      "    • 180-day runs: compare last 30 days (equilibrated)\n",
      "  ✓ Fidelity-aware baseline tracking\n",
      "  ✓ Thompson sampling (10% exploration)\n",
      "  ✓ Anti-stagnation (auto-restart)\n",
      "  ✓ 3-way comparison visualization\n",
      "  Max iterations: 50\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PHASE 2: BAYESIAN OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 31/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m30\u001b[0m/30\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 11.129 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.335 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.489 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.501 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.115 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.033 (low)\n",
      "  Trust region: \u001b[96m0.50\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 4.101741e+00\n",
      "  drag_scale: 6.716296e-01\n",
      "  eddy_diffusivity: 7.304919e+04\n",
      "  smagorinsky_coeff: 1.211816e-01\n",
      "  energy_correction: -8.213186e-05\n",
      "  enstrophy_correction: 2.096996e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 4.101741056741862\n",
      "  drag_scale: 0.6716296047714712\n",
      "  eddy_diffusivity: 73049.19428514091\n",
      "  smagorinsky_coeff: 0.12118160955508453\n",
      "  energy_correction: -8.213186385276974e-05\n",
      "  enstrophy_correction: 2.096995765338514e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 330.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.111881\u001b[0m\n",
      "  → Trust region shrunk to 0.25\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m31\u001b[0m/31\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 32/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m31\u001b[0m/31\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 10.144 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.524 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.601 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.399 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.019 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.019 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.203796e+00\n",
      "  drag_scale: 7.684946e-01\n",
      "  eddy_diffusivity: 3.992782e+04\n",
      "  smagorinsky_coeff: 1.979382e-01\n",
      "  energy_correction: -2.290644e-04\n",
      "  enstrophy_correction: 6.212215e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.20379643598204\n",
      "  drag_scale: 0.7684946466428342\n",
      "  eddy_diffusivity: 39927.81520174534\n",
      "  smagorinsky_coeff: 0.19793823309282751\n",
      "  energy_correction: -0.0002290644166504617\n",
      "  enstrophy_correction: 6.21221451717693e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 330.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.108828\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m32\u001b[0m/32\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m4/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 33/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m32\u001b[0m/32\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 10.440 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.526 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.619 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.372 (\u001b[96mmed\u001b[0m)\n",
      "    5. eddy_diffusivity: 0.027 (\u001b[96mmed\u001b[0m)\n",
      "    6. smagorinsky_coeff: 0.027 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=2.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.206823e+00\n",
      "  drag_scale: 8.428643e-01\n",
      "  eddy_diffusivity: 2.754158e+04\n",
      "  smagorinsky_coeff: 2.122382e-01\n",
      "  energy_correction: 4.903970e-04\n",
      "  enstrophy_correction: 5.468012e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.2068234387856833\n",
      "  drag_scale: 0.8428642641378801\n",
      "  eddy_diffusivity: 27541.57750802983\n",
      "  smagorinsky_coeff: 0.21223823785126442\n",
      "  energy_correction: 0.00049039702200189\n",
      "  enstrophy_correction: 5.468012367959851e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 328.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.114587\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m33\u001b[0m/33\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m5/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 34/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m33\u001b[0m/33\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 10.142 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.580 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.668 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.332 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.018 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.018 (low)\n",
      "  Trust region: \u001b[96m0.25\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.706533e+00\n",
      "  drag_scale: 7.743058e-01\n",
      "  eddy_diffusivity: 2.040905e+04\n",
      "  smagorinsky_coeff: 1.785315e-01\n",
      "  energy_correction: -8.649249e-04\n",
      "  enstrophy_correction: 5.394402e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.7065334779995927\n",
      "  drag_scale: 0.774305833322164\n",
      "  eddy_diffusivity: 20409.0488329021\n",
      "  smagorinsky_coeff: 0.17853152167736563\n",
      "  energy_correction: -0.0008649249275315806\n",
      "  enstrophy_correction: 5.394402373671481e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 305.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.127603\u001b[0m\n",
      "  → Trust region shrunk to 0.12\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m34\u001b[0m/34\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m6/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 35/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m34\u001b[0m/34\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 11.662 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.730 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.638 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.359 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.021 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.019 (low)\n",
      "  Trust region: \u001b[96m0.12\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.619825e+00\n",
      "  drag_scale: 1.203709e+00\n",
      "  eddy_diffusivity: 3.778812e+04\n",
      "  smagorinsky_coeff: 1.732419e-01\n",
      "  energy_correction: 3.392709e-04\n",
      "  enstrophy_correction: 1.786373e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.6198245701630003\n",
      "  drag_scale: 1.2037094760382716\n",
      "  eddy_diffusivity: 37788.11788430327\n",
      "  smagorinsky_coeff: 0.17324191870905578\n",
      "  energy_correction: 0.00033927090385957835\n",
      "  enstrophy_correction: 1.7863732059255601e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 323.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.109501\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m35\u001b[0m/35\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m7/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 36/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m35\u001b[0m/35\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "  Fitting 8-model ensemble GP...\n",
      "  Parameter importance (relative):\n",
      "    1. energy_correction: 12.214 (\u001b[92mHIGH\u001b[0m)\n",
      "    2. enstrophy_correction: 4.761 (\u001b[92mHIGH\u001b[0m)\n",
      "    3. viscosity_scale: 1.642 (\u001b[92mHIGH\u001b[0m)\n",
      "    4. drag_scale: 0.346 (\u001b[96mmed\u001b[0m)\n",
      "    5. smagorinsky_coeff: 0.030 (\u001b[96mmed\u001b[0m)\n",
      "    6. eddy_diffusivity: 0.018 (low)\n",
      "  Trust region: \u001b[96m0.12\u001b[0m\n",
      "  Optimizing acquisition (kappa=3.0)...\n",
      "  Selected point (acq=\u001b[96m0.0000\u001b[0m)\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.611698e+00\n",
      "  drag_scale: 1.175657e+00\n",
      "  eddy_diffusivity: 3.617494e+04\n",
      "  smagorinsky_coeff: 1.710100e-01\n",
      "  energy_correction: -2.207181e-05\n",
      "  enstrophy_correction: 8.781925e-10\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.611697818068567\n",
      "  drag_scale: 1.1756570076287343\n",
      "  eddy_diffusivity: 36174.94035421475\n",
      "  smagorinsky_coeff: 0.17100995980072264\n",
      "  energy_correction: -2.2071811344701736e-05\n",
      "  enstrophy_correction: 8.781925407785814e-10\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1440/1440 [00:04<00:00, 332.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using entire simulation (days 0-30) for loss\n",
      "  Loss: \u001b[92m0.103162\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m36\u001b[0m/36\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFAST (30d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.102483\u001b[0m \u001b[96m(discovered at iteration 28)\u001b[0m\n",
      "    → vs FAST (30d) baseline: \u001b[92m+50.5%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m8/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 37/50\u001b[0m\n",
      "======================================================================\n",
      "\u001b[91m\n",
      "======================================================================\u001b[0m\n",
      "\u001b[91m⚠ FIDELITY TRANSITION: FAST (30d) → FULL (180d)\u001b[0m\n",
      "\u001b[91m======================================================================\u001b[0m\n",
      "\u001b[96m→ Re-evaluating BASELINE at FULL (180d) fidelity...\u001b[0m\n",
      "\u001b[93m  ⚠ Clipped eddy_diffusivity: 5.000000e-03 → 1.000000e+03 (bounds: [1.000000e+03, 1.000000e+05])\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 5.000000e-01\n",
      "  drag_scale: 5.000000e-01\n",
      "  eddy_diffusivity: 1.000000e+03\n",
      "  smagorinsky_coeff: 1.500000e-02\n",
      "  energy_correction: -2.000000e-03\n",
      "  enstrophy_correction: 3.000000e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 0.5\n",
      "  drag_scale: 0.5\n",
      "  eddy_diffusivity: 1000.0\n",
      "  smagorinsky_coeff: 0.015\n",
      "  energy_correction: -0.002\n",
      "  enstrophy_correction: 3e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.628715\u001b[0m\n",
      "\u001b[96m→ Baseline at FULL (180d): 0.628715\u001b[0m\n",
      "\u001b[93m\n",
      "→ Re-evaluating BEST PARAMETERS at FULL (180d) fidelity...\u001b[0m\n",
      "\u001b[93m   Old best loss (FAST (30d)): 0.102483\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.340794e+00\n",
      "  drag_scale: 1.077530e+00\n",
      "  eddy_diffusivity: 2.861997e+04\n",
      "  smagorinsky_coeff: 1.750808e-01\n",
      "  energy_correction: -4.570863e-05\n",
      "  enstrophy_correction: 1.404013e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.340794423002603\n",
      "  drag_scale: 1.0775295703247196\n",
      "  eddy_diffusivity: 28619.971643516234\n",
      "  smagorinsky_coeff: 0.17508079721201122\n",
      "  energy_correction: -4.5708630846687595e-05\n",
      "  enstrophy_correction: 1.4040125390931079e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.176134\u001b[0m\n",
      "\u001b[93m   New best loss (FULL (180d)): 0.176134\u001b[0m\n",
      "\u001b[91m   ⚠ Loss INCREASED by 71.9% at higher fidelity\u001b[0m\n",
      "\u001b[96m   → Improvement vs FULL (180d) baseline: +72.0%\u001b[0m\n",
      "\u001b[91m======================================================================\n",
      "\u001b[0m\n",
      "Valid samples: \u001b[96m36\u001b[0m/36\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 12.123\n",
      "    2. enstrophy_correction: 4.667\n",
      "    3. viscosity_scale: 1.643\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.102464e+00\n",
      "  drag_scale: 1.017923e+00\n",
      "  eddy_diffusivity: 3.473401e+04\n",
      "  smagorinsky_coeff: 1.852146e-01\n",
      "  energy_correction: -5.076750e-05\n",
      "  enstrophy_correction: 1.351125e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.10246380738242\n",
      "  drag_scale: 1.0179226907347303\n",
      "  eddy_diffusivity: 34734.00907174493\n",
      "  smagorinsky_coeff: 0.1852146336933235\n",
      "  energy_correction: -5.0767499713080116e-05\n",
      "  enstrophy_correction: 1.3511251810275526e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.134823\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.134823\u001b[0m (+78.6% vs baseline @ FULL (180d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m37\u001b[0m/37\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134823\u001b[0m \u001b[96m(discovered at iteration 37)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 38/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m37\u001b[0m/37\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 11.824\n",
      "    2. enstrophy_correction: 5.086\n",
      "    3. viscosity_scale: 1.562\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.864133e+00\n",
      "  drag_scale: 9.583158e-01\n",
      "  eddy_diffusivity: 4.215418e+04\n",
      "  smagorinsky_coeff: 1.953485e-01\n",
      "  energy_correction: -5.582637e-05\n",
      "  enstrophy_correction: 1.300230e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.864133191762236\n",
      "  drag_scale: 0.958315811144741\n",
      "  eddy_diffusivity: 42154.17825088506\n",
      "  smagorinsky_coeff: 0.19534847017463575\n",
      "  energy_correction: -5.582636857947264e-05\n",
      "  enstrophy_correction: 1.3002300221523755e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.140730\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m38\u001b[0m/38\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134823\u001b[0m \u001b[96m(discovered at iteration 37)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 39/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m38\u001b[0m/38\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 12.519\n",
      "    2. enstrophy_correction: 5.489\n",
      "    3. viscosity_scale: 1.544\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.864133e+00\n",
      "  drag_scale: 9.583158e-01\n",
      "  eddy_diffusivity: 4.215418e+04\n",
      "  smagorinsky_coeff: 1.953485e-01\n",
      "  energy_correction: -5.582637e-05\n",
      "  enstrophy_correction: 1.300230e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.864133191762236\n",
      "  drag_scale: 0.958315811144741\n",
      "  eddy_diffusivity: 42154.17825088506\n",
      "  smagorinsky_coeff: 0.19534847017463575\n",
      "  energy_correction: -5.582636857947264e-05\n",
      "  enstrophy_correction: 1.3002300221523755e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.140730\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m39\u001b[0m/39\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134823\u001b[0m \u001b[96m(discovered at iteration 37)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 40/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m39\u001b[0m/39\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 13.422\n",
      "    2. enstrophy_correction: 5.781\n",
      "    3. viscosity_scale: 1.551\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.864133e+00\n",
      "  drag_scale: 9.583158e-01\n",
      "  eddy_diffusivity: 4.215418e+04\n",
      "  smagorinsky_coeff: 1.953485e-01\n",
      "  energy_correction: -5.582637e-05\n",
      "  enstrophy_correction: 1.300230e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.864133191762236\n",
      "  drag_scale: 0.958315811144741\n",
      "  eddy_diffusivity: 42154.17825088506\n",
      "  smagorinsky_coeff: 0.19534847017463575\n",
      "  energy_correction: -5.582636857947264e-05\n",
      "  enstrophy_correction: 1.3002300221523755e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 332.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.140730\u001b[0m\n",
      "  → Trust region shrunk to 0.06\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m40\u001b[0m/40\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.134823\u001b[0m \u001b[96m(discovered at iteration 37)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+78.6%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 41/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m40\u001b[0m/40\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 13.726\n",
      "    2. enstrophy_correction: 6.102\n",
      "    3. viscosity_scale: 1.603\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.983298e+00\n",
      "  drag_scale: 9.881193e-01\n",
      "  eddy_diffusivity: 3.826465e+04\n",
      "  smagorinsky_coeff: 1.902816e-01\n",
      "  energy_correction: -5.329693e-05\n",
      "  enstrophy_correction: 1.325433e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.983298499572328\n",
      "  drag_scale: 0.9881192509397356\n",
      "  eddy_diffusivity: 38264.652223405836\n",
      "  smagorinsky_coeff: 0.1902815519339796\n",
      "  energy_correction: -5.329693414627551e-05\n",
      "  enstrophy_correction: 1.325433334449937e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 343.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.127344\u001b[0m\n",
      "\u001b[93m\u001b[1m★ NEW BEST: \u001b[92m0.127344\u001b[0m (+79.7% vs baseline @ FULL (180d))\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m41\u001b[0m/41\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m0/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 42/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m41\u001b[0m/41\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 13.588\n",
      "    2. enstrophy_correction: 6.257\n",
      "    3. viscosity_scale: 1.632\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.864133e+00\n",
      "  drag_scale: 9.583158e-01\n",
      "  eddy_diffusivity: 4.215418e+04\n",
      "  smagorinsky_coeff: 1.953485e-01\n",
      "  energy_correction: -5.582637e-05\n",
      "  enstrophy_correction: 1.300230e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.864133191762236\n",
      "  drag_scale: 0.958315811144741\n",
      "  eddy_diffusivity: 42154.17825088515\n",
      "  smagorinsky_coeff: 0.19534847017463575\n",
      "  energy_correction: -5.582636857947264e-05\n",
      "  enstrophy_correction: 1.3002300221621875e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 339.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.140730\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m42\u001b[0m/42\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m1/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 43/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m42\u001b[0m/42\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 13.818\n",
      "    2. enstrophy_correction: 6.463\n",
      "    3. viscosity_scale: 1.728\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.864133e+00\n",
      "  drag_scale: 9.583158e-01\n",
      "  eddy_diffusivity: 4.215418e+04\n",
      "  smagorinsky_coeff: 1.953485e-01\n",
      "  energy_correction: -5.582637e-05\n",
      "  enstrophy_correction: 1.300230e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.864133191762236\n",
      "  drag_scale: 0.958315811144741\n",
      "  eddy_diffusivity: 42154.17825088515\n",
      "  smagorinsky_coeff: 0.19534847017463575\n",
      "  energy_correction: -5.582636857947264e-05\n",
      "  enstrophy_correction: 1.3002300221621875e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 341.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.140730\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m43\u001b[0m/43\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m2/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 44/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m43\u001b[0m/43\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 10.954\n",
      "    2. enstrophy_correction: 5.101\n",
      "    3. viscosity_scale: 1.655\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 3.020883e+00\n",
      "  drag_scale: 9.327809e-01\n",
      "  eddy_diffusivity: 3.372672e+04\n",
      "  smagorinsky_coeff: 1.892819e-01\n",
      "  energy_correction: -2.974819e-04\n",
      "  enstrophy_correction: 1.332638e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 3.0208831961265874\n",
      "  drag_scale: 0.9327809121465134\n",
      "  eddy_diffusivity: 33726.715192624775\n",
      "  smagorinsky_coeff: 0.1892819234530064\n",
      "  energy_correction: -0.00029748191683161805\n",
      "  enstrophy_correction: 1.3326383439229815e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 341.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.166344\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m44\u001b[0m/44\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m3/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 45/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m44\u001b[0m/44\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 15.586\n",
      "    2. enstrophy_correction: 7.087\n",
      "    3. viscosity_scale: 1.518\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.887966e+00\n",
      "  drag_scale: 9.642765e-01\n",
      "  eddy_diffusivity: 4.134586e+04\n",
      "  smagorinsky_coeff: 1.943351e-01\n",
      "  energy_correction: -5.532048e-05\n",
      "  enstrophy_correction: 1.305232e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8879662533242545\n",
      "  drag_scale: 0.9642764991037399\n",
      "  eddy_diffusivity: 41345.862518577276\n",
      "  smagorinsky_coeff: 0.19433508652650452\n",
      "  energy_correction: -5.532048169283252e-05\n",
      "  enstrophy_correction: 1.3052320503421882e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 340.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.137583\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m45\u001b[0m/45\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m4/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 46/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m45\u001b[0m/45\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 16.043\n",
      "    2. enstrophy_correction: 7.625\n",
      "    3. viscosity_scale: 1.646\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.887966e+00\n",
      "  drag_scale: 9.642765e-01\n",
      "  eddy_diffusivity: 4.134586e+04\n",
      "  smagorinsky_coeff: 1.943351e-01\n",
      "  energy_correction: -5.532048e-05\n",
      "  enstrophy_correction: 1.305232e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8879662533242545\n",
      "  drag_scale: 0.9642764991037399\n",
      "  eddy_diffusivity: 41345.862518577276\n",
      "  smagorinsky_coeff: 0.19433508652650452\n",
      "  energy_correction: -5.532048169283252e-05\n",
      "  enstrophy_correction: 1.3052320503421882e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 333.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.137583\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m46\u001b[0m/46\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m5/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 47/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m46\u001b[0m/46\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 13.780\n",
      "    2. viscosity_scale: 5.131\n",
      "    3. enstrophy_correction: 3.663\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.974659e+00\n",
      "  drag_scale: 9.535811e-01\n",
      "  eddy_diffusivity: 3.659818e+04\n",
      "  smagorinsky_coeff: 1.955142e-01\n",
      "  energy_correction: 2.593883e-04\n",
      "  enstrophy_correction: 1.248409e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.97465868298221\n",
      "  drag_scale: 0.9535810583307984\n",
      "  eddy_diffusivity: 36598.18098717588\n",
      "  smagorinsky_coeff: 0.1955142428591007\n",
      "  energy_correction: 0.00025938834134206154\n",
      "  enstrophy_correction: 1.2484091205559291e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 338.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.169086\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m47\u001b[0m/47\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m6/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 48/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m47\u001b[0m/47\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 16.030\n",
      "    2. enstrophy_correction: 7.569\n",
      "    3. viscosity_scale: 1.594\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.887966e+00\n",
      "  drag_scale: 9.642765e-01\n",
      "  eddy_diffusivity: 4.134586e+04\n",
      "  smagorinsky_coeff: 1.943351e-01\n",
      "  energy_correction: -5.532048e-05\n",
      "  enstrophy_correction: 1.305232e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8879662533242545\n",
      "  drag_scale: 0.9642764991037399\n",
      "  eddy_diffusivity: 41345.862518577276\n",
      "  smagorinsky_coeff: 0.19433508652650452\n",
      "  energy_correction: -5.532048169283252e-05\n",
      "  enstrophy_correction: 1.3052320503421882e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 337.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.137583\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m48\u001b[0m/48\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m7/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 49/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m48\u001b[0m/48\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 21.824\n",
      "    2. viscosity_scale: 6.108\n",
      "    3. enstrophy_correction: 3.670\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.887966e+00\n",
      "  drag_scale: 9.642765e-01\n",
      "  eddy_diffusivity: 4.134586e+04\n",
      "  smagorinsky_coeff: 1.943351e-01\n",
      "  energy_correction: -5.532048e-05\n",
      "  enstrophy_correction: 1.305232e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8879662533242545\n",
      "  drag_scale: 0.9642764991037399\n",
      "  eddy_diffusivity: 41345.862518577276\n",
      "  smagorinsky_coeff: 0.19433508652650452\n",
      "  energy_correction: -5.532048169283252e-05\n",
      "  enstrophy_correction: 1.3052320503421882e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 334.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.137583\u001b[0m\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m49\u001b[0m/49\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m8/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "======================================================================\n",
      "\u001b[96mITERATION 50/50\u001b[0m\n",
      "======================================================================\n",
      "Valid samples: \u001b[96m49\u001b[0m/49\n",
      "\u001b[93m  ℹ Increased exploration: kappa = 3.0\u001b[0m\n",
      "\u001b[96m  → Using Thompson sampling for exploration\u001b[0m\n",
      "  Top 3 important parameters:\n",
      "    1. energy_correction: 24.333\n",
      "    2. viscosity_scale: 7.930\n",
      "    3. enstrophy_correction: 2.015\n",
      "\n",
      "======================================================================\n",
      "Testing parameters - Fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "======================================================================\n",
      "  viscosity_scale: 2.887966e+00\n",
      "  drag_scale: 9.642765e-01\n",
      "  eddy_diffusivity: 4.134586e+04\n",
      "  smagorinsky_coeff: 1.943351e-01\n",
      "  energy_correction: -5.532048e-05\n",
      "  enstrophy_correction: 1.305232e-09\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.8879662533242545\n",
      "  drag_scale: 0.9642764991037399\n",
      "  eddy_diffusivity: 41345.862518577276\n",
      "  smagorinsky_coeff: 0.19433508652650452\n",
      "  energy_correction: -5.532048169283252e-05\n",
      "  enstrophy_correction: 1.3052320503421882e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:26<00:00, 328.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  → Using last 30 days for loss (equilibrated state)\n",
      "  Loss: \u001b[92m0.137583\u001b[0m\n",
      "  → Trust region shrunk to 0.05\n",
      "\n",
      "\u001b[1mStatus:\u001b[0m\n",
      "  Valid: \u001b[96m50\u001b[0m/50\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "  Current fidelity: \u001b[96mFULL (180d)\u001b[0m\n",
      "  Baselines by fidelity:\n",
      "    FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "    FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "  \u001b[1mBest loss:\u001b[0m \u001b[92m0.127344\u001b[0m \u001b[96m(discovered at iteration 41)\u001b[0m\n",
      "    → vs FULL (180d) baseline: \u001b[92m+79.7%\u001b[0m\n",
      "  Iterations w/o improvement: \u001b[96m9/15\u001b[0m\n",
      "  ✓ Progress saved\n",
      "\n",
      "  Generating visualization...\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING FINAL VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATION SUITE\n",
      "======================================================================\n",
      "\n",
      "✓ Saved comprehensive analysis: optimization_analysis.png\n",
      "✓ Saved sensitivity analysis: parameter_sensitivity.png\n",
      "✓ Saved efficiency analysis: computational_efficiency.png\n",
      "======================================================================\n",
      "✓ All visualizations complete!\n",
      "  - optimization_analysis.png: Loss curves, parameters, trust region\n",
      "  - parameter_sensitivity.png: Which parameters matter most\n",
      "  - computational_efficiency.png: Cost vs improvement analysis\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Total iterations: 50\n",
      "  Valid: \u001b[96m50\u001b[0m\n",
      "  Failed: \u001b[93m0\u001b[0m\n",
      "\n",
      "Baselines by fidelity:\n",
      "  FAST (30d): \u001b[96m0.206844\u001b[0m\n",
      "  FULL (180d): \u001b[96m0.628715\u001b[0m\n",
      "\n",
      "\u001b[1mFinal Comparison at FULL (180d) Fidelity:\u001b[0m\n",
      "  Baseline (default): \u001b[96m0.628715\u001b[0m\n",
      "  Best loss: \u001b[92m0.127344\u001b[0m \u001b[92m[+79.7% improvement]\u001b[0m\n",
      "  Best parameters discovered at: iteration 41\n",
      "\u001b[96m    (during 180-day full precision phase)\u001b[0m\n",
      "\n",
      "\u001b[1mBest parameters:\u001b[0m\n",
      "  viscosity_scale: \u001b[96m2.983298e+00\u001b[0m (default: 5.000000e-01, +496.7%)\n",
      "  drag_scale: \u001b[96m9.881193e-01\u001b[0m (default: 5.000000e-01, +97.6%)\n",
      "  eddy_diffusivity: \u001b[96m3.826465e+04\u001b[0m (default: 5.000000e-03, +765292944.5%)\n",
      "  smagorinsky_coeff: \u001b[96m1.902816e-01\u001b[0m (default: 1.500000e-02, +1168.5%)\n",
      "  energy_correction: \u001b[96m-5.329693e-05\u001b[0m (default: -2.000000e-03, -97.3%)\n",
      "  enstrophy_correction: \u001b[96m1.325433e-09\u001b[0m (default: 3.000000e-09, -55.8%)\n",
      "\n",
      "✓ Saved: enhanced_gp_optimal_params.pkl\n",
      "✓ Saved: enhanced_gp_optimal_config.txt\n",
      "\n",
      "======================================================================\n",
      "NOTE: DYNAMIC 2-LEVEL MULTI-FIDELITY WITH ADAPTIVE BASELINES\n",
      "======================================================================\n",
      "The optimizer uses a dynamic 2-level fidelity strategy (based on 6 params):\n",
      "  Initial phase (iterations 0-23):  30-day runs at low fidelity\n",
      "    - 24 samples for good initial coverage\n",
      "    - Compares entire simulation (days 0-30)\n",
      "    - Baseline tracked at 30-day fidelity\n",
      "  Fast phase (iterations 24-35):   30-day BO runs\n",
      "    - 12 iterations of fast exploration\n",
      "    - ~6x speedup vs full fidelity\n",
      "  Full phase (iterations 36+):   180-day BO runs\n",
      "    - 12+ iterations at full precision\n",
      "    - Compares last 30 days (equilibrated state)\n",
      "    - Baseline tracked at 180-day fidelity\n",
      "\n",
      "This ensures:\n",
      "  ✓ Good initial parameter space coverage\n",
      "  ✓ Fast exploration in early BO iterations\n",
      "  ✓ Fair apples-to-apples comparisons at each fidelity\n",
      "  ✓ Final results use full 180-day simulations\n",
      "\n",
      "Seed robustness:\n",
      "  ✓ Random seed used: 23\n",
      "  ✓ Multiple complementary seeds used internally\n",
      "  ✓ Small perturbations added to reduce grid artifacts\n",
      "  ℹ Different seeds may find best at different iterations\n",
      "    but final performance should be similar (~5-10% variation)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RUNNING FINAL COMPARISON SIMULATIONS\n",
      "======================================================================\n",
      "\n",
      "✓ Using cached default results at FULL fidelity\n",
      "\n",
      "Running optimized parameters simulation (full 180 days)...\n",
      "\n",
      "======================================================================\n",
      "Running LowRes_64x32 Simulation\n",
      "======================================================================\n",
      "Grid: 64 x 32\n",
      "Resolution: 31.2 km per grid point\n",
      "\n",
      "Subgrid Parameters:\n",
      "  viscosity_scale: 2.983298499572328\n",
      "  drag_scale: 0.9881192509397356\n",
      "  eddy_diffusivity: 38264.652223405836\n",
      "  smagorinsky_coeff: 0.1902815519339796\n",
      "  energy_correction: -5.329693414627551e-05\n",
      "  enstrophy_correction: 1.325433334449937e-09\n",
      "\n",
      "Initial Energy: 5.940e+02\n",
      "Initial Enstrophy: 8.404e-12\n",
      "\n",
      "Integrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8640/8640 [00:25<00:00, 337.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LowRes_64x32 Simulation Complete!\n",
      "======================================================================\n",
      "  ✓ Optimized simulation complete\n",
      "\n",
      "======================================================================\n",
      "GENERATING ENHANCED 3-WAY COMPARISON\n",
      "======================================================================\n",
      "✓ Saved enhanced 3-way comparison: three_way_comparison.png\n",
      "\n",
      "======================================================================\n",
      "COMPARISON SUMMARY (All using last 30 days)\n",
      "======================================================================\n",
      "High-Res (Reference):\n",
      "  Resolution: 512x256\n",
      "  Time window: last 30 days (equilibrated state)\n",
      "\n",
      "Low-Res DEFAULT:\n",
      "  Resolution: 64x32\n",
      "  PV Loss: 0.726491\n",
      "  Streamfn Loss: 0.482050\n",
      "  Total Loss: 0.628715\n",
      "\n",
      "Low-Res OPTIMIZED:\n",
      "  Resolution: 64x32\n",
      "  PV Loss: 0.174910 (+75.9%)\n",
      "  Streamfn Loss: 0.055995 (+88.4%)\n",
      "  Total Loss: 0.127344\n",
      "\n",
      "Spatial Improvement Statistics:\n",
      "  PV Error Reduction:\n",
      "    Mean: 0.000001\n",
      "    Median: 0.000000\n",
      "    % improved points: 84.2%\n",
      "  Streamfunction Error Reduction:\n",
      "    Mean: 14103.821286\n",
      "    Median: 11611.008305\n",
      "    % improved points: 93.2%\n",
      "\n",
      "\u001b[93m\u001b[1m★ TOTAL IMPROVEMENT: 79.7%\u001b[0m\n",
      "======================================================================\n",
      "\n",
      "✓ Saved: optimization_analysis.png\n",
      "✓ Saved: parameter_sensitivity.png\n",
      "✓ Saved: computational_efficiency.png\n",
      "✓ Saved: three_way_comparison.png\n",
      "\n",
      "======================================================================\n",
      "VISUALIZATION GUIDE\n",
      "======================================================================\n",
      "1. optimization_analysis.png\n",
      "   → Loss evolution, parameter trajectories, trust region\n",
      "   → Shows HOW the optimization progressed\n",
      "\n",
      "2. parameter_sensitivity.png\n",
      "   → Correlation analysis, variance explained, ranges explored\n",
      "   → Shows WHICH parameters matter most\n",
      "   → Red = increasing parameter worsens loss\n",
      "   → Green = increasing parameter improves loss\n",
      "\n",
      "3. computational_efficiency.png\n",
      "   → Cost vs improvement, phase breakdown, sample efficiency\n",
      "   → Shows HOW EFFICIENTLY we found improvements\n",
      "\n",
      "4. three_way_comparison.png\n",
      "   → Spatial fields: high-res vs default vs optimized\n",
      "   → Shows FINAL RESULTS quality\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Enhanced Robust GP Optimizer with Warm-Start & 3-Way Comparison\n",
    "\n",
    "NEW FEATURES:\n",
    "1. Warm-start from reference parameters (baseline-aware)\n",
    "2. Dynamic multi-fidelity optimization (30d → 180d with parameter-based thresholds)\n",
    "3. Thompson sampling exploration\n",
    "4. 3-way comparison: high-res vs low-res default vs low-res optimized (contourf plots)\n",
    "5. Comprehensive visualization with improvement metrics\n",
    "6. Seed-robust initialization using multiple complementary random sequences\n",
    "7. Separate best-loss tracking per fidelity level (no confusing jumps!)\n",
    "8. Dynamic sampling: 4*N_PARAMS initial, 2*N_PARAMS fast, 2*N_PARAMS full\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from scipy.stats import qmc, norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF, ConstantKernel, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from qg_model import QGTwoLayerModel\n",
    "from scipy.ndimage import uniform_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.gaussian_process')\n",
    "warnings.filterwarnings('ignore', message='The optimal value found for dimension')\n",
    "\n",
    "class Colors:\n",
    "    \"\"\"Compact color printing\"\"\"\n",
    "    @staticmethod\n",
    "    def green(t): return f\"\\033[92m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def cyan(t): return f\"\\033[96m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def yellow(t): return f\"\\033[93m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def red(t): return f\"\\033[91m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def bold(t): return f\"\\033[1m{t}\\033[0m\"\n",
    "    @staticmethod\n",
    "    def star(t): return f\"\\033[93m\\033[1m★ {t}\\033[0m\"\n",
    "\n",
    "# Parameter configuration with REFERENCE BASELINE\n",
    "PARAM_BOUNDS = {\n",
    "    'viscosity_scale': {'bounds': (0.5, 5.0), 'type': 'linear'},\n",
    "    'drag_scale': {'bounds': (0.5, 3.0), 'type': 'linear'},\n",
    "    'eddy_diffusivity': {'bounds': (1e3, 1e5), 'type': 'log'},\n",
    "    'smagorinsky_coeff': {'bounds': (0.0, 0.3), 'type': 'linear'},\n",
    "    'energy_correction': {'bounds': (-0.01, 0.01), 'type': 'linear'},\n",
    "    'enstrophy_correction': {'bounds': (0.0, 1e-6), 'type': 'log'},\n",
    "}\n",
    "\n",
    "# REFERENCE/DEFAULT PARAMETERS (known baseline)\n",
    "# Note: If defaults are outside bounds, they will be clipped automatically\n",
    "DEFAULT_PARAMS = {\n",
    "    'viscosity_scale': 0.5,\n",
    "    'drag_scale': 0.5,\n",
    "    'eddy_diffusivity': 0.005,  # User-provided default (will be clipped to bounds if needed)\n",
    "    'smagorinsky_coeff': 0.015,\n",
    "    'energy_correction': -0.002,\n",
    "    'enstrophy_correction': 3e-9,\n",
    "}\n",
    "\n",
    "PARAM_NAMES = list(PARAM_BOUNDS.keys())\n",
    "N_PARAMS = len(PARAM_NAMES)\n",
    "\n",
    "# Input warping for log-scale parameters\n",
    "def warp_parameters(params_array):\n",
    "    \"\"\"Transform to warped space: log params → log space, linear → [0,1]\"\"\"\n",
    "    warped = np.zeros(N_PARAMS)\n",
    "    for i, name in enumerate(PARAM_NAMES):\n",
    "        val, info = params_array[i], PARAM_BOUNDS[name]\n",
    "        lower, upper = info['bounds']\n",
    "        if info['type'] == 'log':\n",
    "            log_lower, log_upper = np.log10(lower) if lower > 0 else -10, np.log10(upper)\n",
    "            warped[i] = (np.log10(val + 1e-20) - log_lower) / (log_upper - log_lower)\n",
    "        else:\n",
    "            warped[i] = (val - lower) / (upper - lower)\n",
    "    return warped\n",
    "\n",
    "def unwarp_parameters(warped_array):\n",
    "    \"\"\"Transform from warped space back to original space\"\"\"\n",
    "    params = np.zeros(N_PARAMS)\n",
    "    for i, name in enumerate(PARAM_NAMES):\n",
    "        info = PARAM_BOUNDS[name]\n",
    "        lower, upper = info['bounds']\n",
    "        if info['type'] == 'log':\n",
    "            log_lower, log_upper = np.log10(lower) if lower > 0 else -10, np.log10(upper)\n",
    "            params[i] = 10 ** (warped_array[i] * (log_upper - log_lower) + log_lower)\n",
    "        else:\n",
    "            params[i] = warped_array[i] * (upper - lower) + lower\n",
    "        params[i] = np.clip(params[i], lower, upper)\n",
    "    return params\n",
    "\n",
    "def params_dict_to_array(params_dict):\n",
    "    \"\"\"Convert parameter dictionary to array, clipping to bounds\"\"\"\n",
    "    params = []\n",
    "    for name in PARAM_NAMES:\n",
    "        val = params_dict[name]\n",
    "        lower, upper = PARAM_BOUNDS[name]['bounds']\n",
    "        clipped_val = np.clip(val, lower, upper)\n",
    "        if clipped_val != val:\n",
    "            print(Colors.yellow(f\"  ⚠ Clipped {name}: {val:.6e} → {clipped_val:.6e} (bounds: [{lower:.6e}, {upper:.6e}])\"))\n",
    "        params.append(clipped_val)\n",
    "    return np.array(params)\n",
    "\n",
    "def params_array_to_dict(params_array):\n",
    "    \"\"\"Convert parameter array to dictionary\"\"\"\n",
    "    return {PARAM_NAMES[i]: float(params_array[i]) for i in range(N_PARAMS)}\n",
    "\n",
    "# ============================================================================\n",
    "# SMART INITIALIZATION WITH WARM-START\n",
    "# ============================================================================\n",
    "\n",
    "def generate_smart_initial_samples(n_samples, include_default=True, base_seed=42):\n",
    "    \"\"\"\n",
    "    Combine default params + Latin Hypercube + Sobol for warm-start\n",
    "    Uses multiple complementary seeds for better diversity and robustness\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Total number of samples\n",
    "        include_default: If True, first sample is DEFAULT_PARAMS\n",
    "        base_seed: Base random seed (will generate complementary seeds from this)\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # WARM-START: Include default parameters as first sample\n",
    "    if include_default:\n",
    "        default_array = params_dict_to_array(DEFAULT_PARAMS)\n",
    "        samples.append(default_array)\n",
    "        n_samples -= 1\n",
    "        print(Colors.cyan(\"  ✓ Including reference parameters as warm-start\"))\n",
    "    \n",
    "    # Generate space-filling samples for remaining\n",
    "    # Use MULTIPLE seeds for robustness - reduces sensitivity to single seed choice\n",
    "    n_lhs = n_samples // 2\n",
    "    n_sobol = n_samples - n_lhs\n",
    "    \n",
    "    # LHS with primary seed\n",
    "    lhs_sampler = qmc.LatinHypercube(d=N_PARAMS, seed=base_seed)\n",
    "    lhs_samples = lhs_sampler.random(n=n_lhs)\n",
    "    \n",
    "    # Sobol with complementary seed (offset by 1000)\n",
    "    # This ensures different quasi-random sequences\n",
    "    sobol_sampler = qmc.Sobol(d=N_PARAMS, seed=base_seed + 1000, scramble=True)\n",
    "    sobol_samples = sobol_sampler.random(n=n_sobol)\n",
    "    \n",
    "    # Combine samples\n",
    "    unit_samples = np.vstack([lhs_samples, sobol_samples])\n",
    "    \n",
    "    # Add small random perturbations to avoid exact grid points\n",
    "    # This helps exploration and reduces sensitivity to specific seed values\n",
    "    np.random.seed(base_seed + 2000)\n",
    "    perturbations = np.random.normal(0, 0.02, size=unit_samples.shape)\n",
    "    unit_samples = np.clip(unit_samples + perturbations, 0, 1)\n",
    "    \n",
    "    for unit_sample in unit_samples:\n",
    "        samples.append(unwarp_parameters(unit_sample))\n",
    "    \n",
    "    print(Colors.cyan(f\"  ✓ Generated {len(samples)} diverse initial samples (base_seed={base_seed})\"))\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "# ============================================================================\n",
    "# ENSEMBLE GP\n",
    "# ============================================================================\n",
    "\n",
    "class EnsembleGP:\n",
    "    \"\"\"Ensemble of Gaussian Processes with different kernels\"\"\"\n",
    "    \n",
    "    def __init__(self, n_models=8):\n",
    "        self.models = []\n",
    "        self.model_weights = []\n",
    "        \n",
    "        kernels = [\n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=1.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[1.0]*N_PARAMS, length_scale_bounds=(1e-3, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[0.5]*N_PARAMS, length_scale_bounds=(1e-3, 1e2), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[2.0]*N_PARAMS, length_scale_bounds=(1e-2, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[0.3]*N_PARAMS, length_scale_bounds=(1e-3, 1e2), nu=1.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            RBF(length_scale=[0.7]*N_PARAMS, length_scale_bounds=(1e-3, 1e3)) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "            \n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * \n",
    "            Matern(length_scale=[1.5]*N_PARAMS, length_scale_bounds=(1e-3, 1e3), nu=2.5) +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1)),\n",
    "        ]\n",
    "        \n",
    "        for kernel in kernels[:n_models]:\n",
    "            self.models.append(GaussianProcessRegressor(\n",
    "                kernel=kernel,\n",
    "                alpha=1e-6,\n",
    "                normalize_y=True,\n",
    "                n_restarts_optimizer=15,\n",
    "                random_state=None\n",
    "            ))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit all models and compute weights based on marginal likelihood\"\"\"\n",
    "        self.model_weights = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            try:\n",
    "                model.fit(X, y)\n",
    "                # Weight by log marginal likelihood\n",
    "                log_ml = model.log_marginal_likelihood()\n",
    "                self.model_weights.append(np.exp(log_ml))\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Model {i} fitting failed: {e}\")\n",
    "                self.model_weights.append(0.0)\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(self.model_weights)\n",
    "        if total_weight > 0:\n",
    "            self.model_weights = [w / total_weight for w in self.model_weights]\n",
    "        else:\n",
    "            self.model_weights = [1.0 / len(self.models)] * len(self.models)\n",
    "    \n",
    "    def predict(self, X, return_std=True):\n",
    "        \"\"\"Weighted ensemble prediction\"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        if return_std:\n",
    "            predictions = []\n",
    "            uncertainties = []\n",
    "            weights = []\n",
    "            \n",
    "            for i, model in enumerate(self.models):\n",
    "                if self.model_weights[i] > 0:\n",
    "                    try:\n",
    "                        mu, sigma = model.predict(X, return_std=True)\n",
    "                        predictions.append(mu)\n",
    "                        uncertainties.append(sigma)\n",
    "                        weights.append(self.model_weights[i])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            if len(predictions) == 0:\n",
    "                return np.zeros(len(X)), np.ones(len(X))\n",
    "            \n",
    "            # Weighted mean and maximum uncertainty\n",
    "            weights = np.array(weights)\n",
    "            mean = np.average(predictions, axis=0, weights=weights)\n",
    "            std = np.max(uncertainties, axis=0)\n",
    "            \n",
    "            return mean, std\n",
    "        else:\n",
    "            predictions = []\n",
    "            weights = []\n",
    "            for i, model in enumerate(self.models):\n",
    "                if self.model_weights[i] > 0:\n",
    "                    try:\n",
    "                        predictions.append(model.predict(X))\n",
    "                        weights.append(self.model_weights[i])\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "            return np.average(predictions, axis=0, weights=weights) if predictions else np.zeros(len(X))\n",
    "    \n",
    "    def get_parameter_importance(self):\n",
    "        \"\"\"Extract parameter importance from length scales\"\"\"\n",
    "        importance_scores = []\n",
    "        \n",
    "        for i, model in enumerate(self.models):\n",
    "            if self.model_weights[i] > 0:\n",
    "                try:\n",
    "                    kernel = model.kernel_\n",
    "                    # Try to extract length scales from different kernel structures\n",
    "                    length_scales = None\n",
    "                    \n",
    "                    # For composite kernels (ConstantKernel * Matern/RBF + WhiteKernel)\n",
    "                    if hasattr(kernel, 'k1') and hasattr(kernel.k1, 'k2'):\n",
    "                        length_scales = kernel.k1.k2.length_scale\n",
    "                    elif hasattr(kernel, 'k2'):\n",
    "                        length_scales = kernel.k2.length_scale\n",
    "                    elif hasattr(kernel, 'length_scale'):\n",
    "                        length_scales = kernel.length_scale\n",
    "                    \n",
    "                    if length_scales is not None and hasattr(length_scales, '__len__'):\n",
    "                        # Inverse of length scale = importance (smaller length scale = more sensitive)\n",
    "                        # Normalize by median to get relative importance\n",
    "                        ls_array = np.array(length_scales)\n",
    "                        importance = 1.0 / (ls_array + 1e-10)\n",
    "                        # Normalize so median = 1.0\n",
    "                        importance = importance / (np.median(importance) + 1e-10)\n",
    "                        importance_scores.append(importance)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "        \n",
    "        if importance_scores and len(importance_scores) > 0:\n",
    "            # Weighted average importance\n",
    "            weights = [w for w in self.model_weights if w > 0][:len(importance_scores)]\n",
    "            weighted_importance = np.average(importance_scores, axis=0, weights=weights)\n",
    "            return weighted_importance\n",
    "        else:\n",
    "            # Fallback: return ones (equal importance)\n",
    "            return np.ones(N_PARAMS)\n",
    "\n",
    "# Trust region with reset capability\n",
    "class TrustRegion:\n",
    "    def __init__(self):\n",
    "        self.trust_radius, self.best_center = 0.5, None\n",
    "        self.success_count, self.fail_count = 0, 0\n",
    "        self.min_radius, self.max_radius = 0.05, 1.0\n",
    "        self.radius_history = []\n",
    "    \n",
    "    def get_trust_region_bounds(self):\n",
    "        if self.best_center is None:\n",
    "            return [(0, 1)] * N_PARAMS\n",
    "        bounds = []\n",
    "        for i in range(N_PARAMS):\n",
    "            center, half_width = self.best_center[i], self.trust_radius / 2\n",
    "            bounds.append((max(0.0, center - half_width), min(1.0, center + half_width)))\n",
    "        return bounds\n",
    "    \n",
    "    def update(self, new_best_found, new_center=None):\n",
    "        if new_best_found:\n",
    "            self.success_count += 1\n",
    "            self.fail_count = 0\n",
    "            if new_center is not None:\n",
    "                self.best_center = new_center\n",
    "            if self.success_count >= 3:\n",
    "                self.trust_radius = min(self.max_radius, self.trust_radius * 1.5)\n",
    "                self.success_count = 0\n",
    "                print(f\"  → Trust region expanded to {self.trust_radius:.2f}\")\n",
    "        else:\n",
    "            self.fail_count += 1\n",
    "            self.success_count = 0\n",
    "            if self.fail_count >= 3:\n",
    "                self.trust_radius = max(self.min_radius, self.trust_radius * 0.5)\n",
    "                self.fail_count = 0\n",
    "                print(f\"  → Trust region shrunk to {self.trust_radius:.2f}\")\n",
    "        \n",
    "        self.radius_history.append(self.trust_radius)\n",
    "    \n",
    "    def reset_for_exploration(self):\n",
    "        self.trust_radius = 0.8\n",
    "        self.success_count, self.fail_count = 0, 0\n",
    "        self.radius_history.append(self.trust_radius)\n",
    "        print(f\"  → Trust region RESET to {self.trust_radius:.2f}\")\n",
    "\n",
    "# NEW: Thompson Sampling for exploration\n",
    "def thompson_sampling(gp, bounds, n_samples=1):\n",
    "    \"\"\"Sample from GP posterior for exploration\"\"\"\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        # Sample a function from GP posterior\n",
    "        X_grid = np.random.uniform([b[0] for b in bounds], [b[1] for b in bounds], size=(500, N_PARAMS))\n",
    "        mu, sigma = gp.predict(X_grid, return_std=True)\n",
    "        \n",
    "        # Sample from posterior at each point\n",
    "        posterior_samples = np.random.normal(mu, sigma)\n",
    "        \n",
    "        # Find minimum of sampled function\n",
    "        best_idx = np.argmin(posterior_samples)\n",
    "        samples.append(X_grid[best_idx])\n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "# Hybrid acquisition with LOCAL PENALIZATION\n",
    "def hybrid_acquisition_with_penalization(X, gp, best_y, X_samples, xi=0.01, kappa=2.0, weight_ei=0.6, penalization_weight=0.3):\n",
    "    \"\"\"Hybrid EI+UCB with local penalization\"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    # Expected Improvement\n",
    "    with np.errstate(divide='warn', invalid='warn'):\n",
    "        imp = best_y - mu - xi\n",
    "        Z = imp / (sigma + 1e-9)\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    # Upper Confidence Bound\n",
    "    ucb = -(mu - kappa * sigma)\n",
    "    \n",
    "    # Normalize\n",
    "    ei_norm = (ei - ei.min()) / (ei.max() - ei.min() + 1e-9)\n",
    "    ucb_norm = (ucb - ucb.min()) / (ucb.max() - ucb.min() + 1e-9)\n",
    "    \n",
    "    # Base acquisition\n",
    "    acq = weight_ei * ei_norm + (1 - weight_ei) * ucb_norm\n",
    "    \n",
    "    # Local penalization\n",
    "    if len(X_samples) > 0 and penalization_weight > 0:\n",
    "        X_samples_warped = np.array([warp_parameters(x) for x in X_samples])\n",
    "        min_distances = np.min([np.linalg.norm(X - x_sample, axis=1) for x_sample in X_samples_warped], axis=0)\n",
    "        penalty = np.exp(-10 * min_distances)\n",
    "        acq = acq * (1 - penalization_weight * penalty)\n",
    "    \n",
    "    return acq\n",
    "\n",
    "# Acquisition optimizer with multi-start\n",
    "def optimize_acquisition_multistart(acquisition_fn, bounds, n_starts=20, n_random=500):\n",
    "    \"\"\"Multi-start optimization of acquisition function\"\"\"\n",
    "    best_acq, best_x = -np.inf, None\n",
    "    \n",
    "    # Random sampling\n",
    "    random_samples = np.random.uniform([b[0] for b in bounds], [b[1] for b in bounds], size=(n_random, N_PARAMS))\n",
    "    acq_random = acquisition_fn(random_samples)\n",
    "    best_random_idx = np.argmax(acq_random)\n",
    "    if acq_random[best_random_idx] > best_acq:\n",
    "        best_acq, best_x = acq_random[best_random_idx], random_samples[best_random_idx]\n",
    "    \n",
    "    # Gradient-based optimization\n",
    "    for _ in range(n_starts):\n",
    "        x0 = np.array([np.random.uniform(b[0], b[1]) for b in bounds])\n",
    "        result = minimize(lambda x: -acquisition_fn(x.reshape(1, -1))[0], x0, method='L-BFGS-B', bounds=bounds)\n",
    "        if result.success and -result.fun > best_acq:\n",
    "            best_acq, best_x = -result.fun, result.x\n",
    "    \n",
    "    return best_x\n",
    "\n",
    "# NEW: Dynamic 2-level multi-fidelity with parameter-based thresholds\n",
    "def get_adaptive_sim_days(iteration, base_days=180):\n",
    "    \"\"\"\n",
    "    Dynamic 2-level fidelity strategy based on number of parameters:\n",
    "    - Initial phase: 4 * N_PARAMS iterations at 30-day fidelity\n",
    "    - Fast phase: 2 * N_PARAMS iterations at 30-day fidelity  \n",
    "    - Full phase: 2 * N_PARAMS iterations at 180-day fidelity\n",
    "    \n",
    "    Returns: (sim_days, description, phase_name)\n",
    "    \"\"\"\n",
    "    n_initial = 4 * N_PARAMS  # 24 for 6 parameters\n",
    "    n_fast = 2 * N_PARAMS      # 12 for 6 parameters\n",
    "    \n",
    "    fast_phase_end = n_initial + n_fast\n",
    "    \n",
    "    if iteration < fast_phase_end:\n",
    "        return 30, \"FAST (30d)\", \"fast\"  # Initial + Fast exploration\n",
    "    else:\n",
    "        return base_days, \"FULL (180d)\", \"full\"  # Full precision\n",
    "\n",
    "# Simulation runner\n",
    "def run_lowres_with_params(params_array, config_base, highres_results, sim_days=180, iteration=0):\n",
    "    from main_comparison import run_simulation\n",
    "    \n",
    "    # Adaptive fidelity\n",
    "    adaptive_days, fidelity_desc, phase_name = get_adaptive_sim_days(iteration, sim_days)\n",
    "    \n",
    "    config = config_base.copy()\n",
    "    config['subgrid_params'] = {PARAM_NAMES[i]: float(params_array[i]) for i in range(N_PARAMS)}\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing parameters - Fidelity: {Colors.cyan(fidelity_desc)}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for param_name, val in config['subgrid_params'].items():\n",
    "        print(f\"  {param_name}: {val:.6e}\")\n",
    "    \n",
    "    try:\n",
    "        results = run_simulation(config, sim_days=adaptive_days, save_interval_hours=12)\n",
    "        # Adaptive loss computation will automatically use appropriate time window\n",
    "        loss, detailed = compute_loss(results, highres_results, return_fields=True, adaptive_window=True)\n",
    "        if not np.isfinite(loss):\n",
    "            print(Colors.yellow(f\"  ⚠ Loss not finite: {loss}\"))\n",
    "            return np.nan, None, None\n",
    "        print(f\"  Loss: {Colors.green(f'{loss:.6f}')}\")\n",
    "        return loss, results, detailed\n",
    "    except Exception as e:\n",
    "        print(Colors.yellow(f\"  ⚠ Simulation failed: {e}\"))\n",
    "        return np.nan, None, None\n",
    "\n",
    "# Loss computation with adaptive time window\n",
    "def compute_loss(lowres_results, highres_results, n_days_avg=30, return_fields=False, adaptive_window=True):\n",
    "    \"\"\"\n",
    "    Compute loss with adaptive time window based on simulation length\n",
    "    \n",
    "    Args:\n",
    "        adaptive_window: If True, adjust time window based on lowres simulation length\n",
    "                        - For 30-day runs: use entire simulation (days 0-30)\n",
    "                        - For 180-day runs: use last 30 days (days 150-180, equilibrated)\n",
    "    \"\"\"\n",
    "    nx_hr, ny_hr = highres_results['config']['nx'], highres_results['config']['ny']\n",
    "    nx_lr, ny_lr = lowres_results['config']['nx'], lowres_results['config']['ny']\n",
    "    coarsen_factor_x, coarsen_factor_y = nx_hr // nx_lr, ny_hr // ny_lr\n",
    "    \n",
    "    times_hr, times_lr = highres_results['times'], lowres_results['times']\n",
    "    \n",
    "    # Adaptive time window based on simulation length\n",
    "    if adaptive_window:\n",
    "        lr_duration = times_lr[-1] - times_lr[0]\n",
    "        \n",
    "        if lr_duration <= 40:  # 30-day runs\n",
    "            # Use entire simulation\n",
    "            time_start, time_end = times_lr[0], times_lr[-1]\n",
    "            print(f\"  → Using entire simulation (days 0-{time_end - time_start:.0f}) for loss\")\n",
    "        else:  # Full 180-day runs\n",
    "            # Use last 30 days for equilibrated state\n",
    "            time_start, time_end = times_lr[-1] - n_days_avg, times_lr[-1]\n",
    "            print(f\"  → Using last {n_days_avg} days for loss (equilibrated state)\")\n",
    "        \n",
    "        # Get matching time window from high-res\n",
    "        if lr_duration <= 40:\n",
    "            # For short runs, match the same absolute time window\n",
    "            indices_hr = np.where((times_hr >= time_start) & (times_hr <= time_end))[0]\n",
    "        else:\n",
    "            # For full runs, use last 30 days of high-res too\n",
    "            indices_hr = np.where(times_hr >= times_hr[-1] - n_days_avg)[0]\n",
    "        \n",
    "        indices_lr = np.where((times_lr >= time_start) & (times_lr <= time_end))[0]\n",
    "    else:\n",
    "        # Original behavior: use last n_days_avg\n",
    "        indices_hr = np.where(times_hr >= times_hr[-1] - n_days_avg)[0]\n",
    "        indices_lr = np.where(times_lr >= times_lr[-1] - n_days_avg)[0]\n",
    "    \n",
    "    q1_hr_avg = np.mean([highres_results['q1_history'][i] for i in indices_hr], axis=0)\n",
    "    q2_hr_avg = np.mean([highres_results['q2_history'][i] for i in indices_hr], axis=0)\n",
    "    q1_lr_avg = np.mean([lowres_results['q1_history'][i] for i in indices_lr], axis=0)\n",
    "    q2_lr_avg = np.mean([lowres_results['q2_history'][i] for i in indices_lr], axis=0)\n",
    "    \n",
    "    model_hr, model_lr = highres_results['model'], lowres_results['model']\n",
    "    psi1_hr_avg, psi2_hr_avg = model_hr.q_to_psi(q1_hr_avg, q2_hr_avg)\n",
    "    psi1_lr_avg, psi2_lr_avg = model_lr.q_to_psi(q1_lr_avg, q2_lr_avg)\n",
    "    \n",
    "    H1, H2, H_total = model_hr.H1, model_hr.H2, model_hr.H1 + model_hr.H2\n",
    "    q_bt_hr = (H1 * q1_hr_avg + H2 * q2_hr_avg) / H_total\n",
    "    psi_bt_hr = (H1 * psi1_hr_avg + H2 * psi2_hr_avg) / H_total\n",
    "    q_bt_lr = (H1 * q1_lr_avg + H2 * q2_lr_avg) / H_total\n",
    "    psi_bt_lr = (H1 * psi1_lr_avg + H2 * psi2_lr_avg) / H_total\n",
    "    \n",
    "    def coarsen(field, fx, fy):\n",
    "        return uniform_filter(field, size=(fy, fx), mode='wrap')[::fy, ::fx]\n",
    "    \n",
    "    q_bt_hr_coarse = coarsen(q_bt_hr, coarsen_factor_x, coarsen_factor_y)\n",
    "    psi_bt_hr_coarse = coarsen(psi_bt_hr, coarsen_factor_x, coarsen_factor_y)\n",
    "    \n",
    "    nrmse = lambda pred, target: np.sqrt(np.mean((pred - target)**2)) / (np.std(target) + 1e-20)\n",
    "    loss_q_bt, loss_psi_bt = nrmse(q_bt_lr, q_bt_hr_coarse), nrmse(psi_bt_lr, psi_bt_hr_coarse)\n",
    "    weight_pv, weight_psi = 0.6, 0.4\n",
    "    total_loss = weight_pv * loss_q_bt + weight_psi * loss_psi_bt\n",
    "    \n",
    "    if return_fields:\n",
    "        return total_loss, {'q_bt_hr_coarse': q_bt_hr_coarse, 'psi_bt_hr_coarse': psi_bt_hr_coarse,\n",
    "                           'q_bt_lr': q_bt_lr, 'psi_bt_lr': psi_bt_lr, 'loss_q_bt': loss_q_bt,\n",
    "                           'loss_psi_bt': loss_psi_bt, 'total_loss': total_loss}\n",
    "    return total_loss\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION SUITE\n",
    "# ============================================================================\n",
    "\n",
    "class OptimizationVisualizer:\n",
    "    \"\"\"Comprehensive visualization of optimization progress\"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.dpi'] = 100\n",
    "        plt.rcParams['savefig.dpi'] = 300\n",
    "    \n",
    "    def plot_comprehensive_analysis(self, save_path='optimization_analysis.png'):\n",
    "        \"\"\"Create comprehensive multi-panel analysis\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Loss evolution\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        self._plot_loss_evolution(ax1)\n",
    "        \n",
    "        # 2. Parameter evolution\n",
    "        ax2 = fig.add_subplot(gs[1, :2])\n",
    "        self._plot_parameter_evolution(ax2)\n",
    "        \n",
    "        # 3. Parameter importance\n",
    "        ax3 = fig.add_subplot(gs[2, :2])\n",
    "        self._plot_parameter_importance(ax3)\n",
    "        \n",
    "        # 4. Trust region evolution\n",
    "        ax4 = fig.add_subplot(gs[0, 2])\n",
    "        self._plot_trust_region(ax4)\n",
    "        \n",
    "        # 5. Convergence diagnostics\n",
    "        ax5 = fig.add_subplot(gs[1, 2])\n",
    "        self._plot_convergence_diagnostics(ax5)\n",
    "        \n",
    "        # 6. Best parameters bar chart\n",
    "        ax6 = fig.add_subplot(gs[2, 2])\n",
    "        self._plot_best_parameters(ax6)\n",
    "        \n",
    "        plt.suptitle('Bayesian Optimization - Comprehensive Analysis', \n",
    "                     fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"\\n✓ Saved comprehensive analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def _plot_loss_evolution(self, ax):\n",
    "        \"\"\"Plot loss vs iterations with best loss tracking and fidelity phases\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        iterations = np.arange(len(y_samples))\n",
    "        \n",
    "        # Plot all losses\n",
    "        ax.scatter(iterations[valid_mask], y_samples[valid_mask], \n",
    "                  alpha=0.6, s=50, c='steelblue', label='Valid evaluations', zorder=3)\n",
    "        ax.scatter(iterations[~valid_mask], np.ones(np.sum(~valid_mask)) * np.nanmax(y_samples) * 1.1, \n",
    "                  alpha=0.4, s=30, c='red', marker='x', label='Failed evaluations', zorder=2)\n",
    "        \n",
    "        # Plot best loss trajectory - SEPARATE FOR EACH FIDELITY\n",
    "        best_trajectory_30d = []\n",
    "        best_trajectory_180d = []\n",
    "        current_best_30d = np.inf\n",
    "        current_best_180d = np.inf\n",
    "        \n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            _, fidelity_desc, _ = get_adaptive_sim_days(i)\n",
    "            \n",
    "            if i < n_fast_phase_end:  # 30-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_30d:\n",
    "                    current_best_30d = loss\n",
    "                best_trajectory_30d.append(current_best_30d if current_best_30d != np.inf else np.nan)\n",
    "                best_trajectory_180d.append(np.nan)\n",
    "            else:  # 180-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_180d:\n",
    "                    current_best_180d = loss\n",
    "                best_trajectory_30d.append(np.nan)\n",
    "                best_trajectory_180d.append(current_best_180d if current_best_180d != np.inf else np.nan)\n",
    "        \n",
    "        # Plot 30-day best loss\n",
    "        valid_30d = [(i, best_trajectory_30d[i]) for i in range(len(best_trajectory_30d)) if np.isfinite(best_trajectory_30d[i])]\n",
    "        if valid_30d:\n",
    "            indices_30d, values_30d = zip(*valid_30d)\n",
    "            ax.plot(indices_30d, values_30d, 'limegreen', linewidth=2.5, \n",
    "                   label='Best loss (30d)', zorder=4, marker='o', markersize=5)\n",
    "        \n",
    "        # Plot 180-day best loss\n",
    "        valid_180d = [(i, best_trajectory_180d[i]) for i in range(len(best_trajectory_180d)) if np.isfinite(best_trajectory_180d[i])]\n",
    "        if valid_180d:\n",
    "            indices_180d, values_180d = zip(*valid_180d)\n",
    "            ax.plot(indices_180d, values_180d, 'darkgreen', linewidth=3, \n",
    "                   label='Best loss (180d)', zorder=4, marker='*', markersize=8)\n",
    "        \n",
    "        # Highlight different fidelity phases with colored backgrounds\n",
    "        n_initial = self.optimizer.n_initial_samples\n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)  # Initial + Fast phase\n",
    "        \n",
    "        ax.axvspan(0, n_initial-1, alpha=0.1, color='orange', label='Initial sampling')\n",
    "        \n",
    "        if len(iterations) > n_initial:\n",
    "            # 30-day runs (fast exploration)\n",
    "            ax.axvspan(n_initial, min(n_fast_phase_end, len(iterations)-1), \n",
    "                      alpha=0.10, color='lightblue', label='30d runs (fast)')\n",
    "        \n",
    "        if len(iterations) > n_fast_phase_end:\n",
    "            # 180-day runs (full precision)\n",
    "            ax.axvspan(n_fast_phase_end, len(iterations)-1, \n",
    "                      alpha=0.10, color='lightcoral', label='180d runs (full)')\n",
    "        \n",
    "        # Mark fidelity transition with vertical line\n",
    "        if len(iterations) > n_fast_phase_end:\n",
    "            ax.axvline(n_fast_phase_end, color='red', linestyle='--', linewidth=2, \n",
    "                      alpha=0.7, label='Fidelity jump')\n",
    "        \n",
    "        # Mark best iteration\n",
    "        ax.scatter([self.optimizer.best_iteration], [self.optimizer.best_loss],\n",
    "                  s=200, c='gold', marker='*', edgecolors='red', linewidth=2,\n",
    "                  label=f'Best (iter {self.optimizer.best_iteration+1})', zorder=5)\n",
    "        \n",
    "        # If best was found in 30d phase, add annotation\n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)\n",
    "        if self.optimizer.best_params_original_iteration is not None and self.optimizer.best_params_original_iteration < n_fast_phase_end:\n",
    "            # Check if we have 180d baseline (meaning re-evaluation happened)\n",
    "            has_full_baseline = 'FULL (180d)' in self.optimizer.baseline_loss_by_fidelity\n",
    "            if has_full_baseline:\n",
    "                annotation_text = f'Found at iter {self.optimizer.best_params_original_iteration+1}\\n(30d phase)\\nRe-eval at 180d'\n",
    "            else:\n",
    "                annotation_text = f'Found at iter {self.optimizer.best_params_original_iteration+1}\\n(30d phase)'\n",
    "            \n",
    "            ax.annotate(annotation_text, \n",
    "                       xy=(self.optimizer.best_params_original_iteration, self.optimizer.best_loss),\n",
    "                       xytext=(self.optimizer.best_params_original_iteration + 10, self.optimizer.best_loss * 1.2),\n",
    "                       arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                       fontsize=7, color='red', fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Loss Evolution (Dynamic 2-Level Multi-Fidelity: 30d → 180d)\\n' +\n",
    "                    f'Initial: {4*N_PARAMS} samples, Fast: {2*N_PARAMS} iters, Full: {2*N_PARAMS}+ iters\\n' +\n",
    "                    'Separate tracking per fidelity', \n",
    "                    fontsize=11, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=7, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add improvement info with all baselines\n",
    "        if self.optimizer.baseline_loss_by_fidelity:\n",
    "            info_lines = []\n",
    "            \n",
    "            # Final improvement (use FULL baseline if available)\n",
    "            final_baseline = self.optimizer.baseline_loss_by_fidelity.get('FULL (180d)')\n",
    "            if final_baseline:\n",
    "                improvement = (final_baseline - self.optimizer.best_loss) / final_baseline * 100\n",
    "                info_lines.append(f'Final improvement: {improvement:+.1f}%')\n",
    "            \n",
    "            # Show all baselines\n",
    "            info_lines.append('Baselines:')\n",
    "            for fid, base in sorted(self.optimizer.baseline_loss_by_fidelity.items()):\n",
    "                info_lines.append(f'  {fid}: {base:.4f}')\n",
    "            \n",
    "            info_text = '\\n'.join(info_lines)\n",
    "            ax.text(0.02, 0.98, info_text, \n",
    "                   transform=ax.transAxes, fontsize=8, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n",
    "    \n",
    "    def _plot_parameter_evolution(self, ax):\n",
    "        \"\"\"Plot how parameters evolved over iterations\"\"\"\n",
    "        X_samples = np.array(self.optimizer.X_samples)\n",
    "        n_iters = len(X_samples)\n",
    "        \n",
    "        # Normalize parameters to [0, 1] for visualization\n",
    "        X_normalized = np.array([warp_parameters(x) for x in X_samples])\n",
    "        \n",
    "        for i, param_name in enumerate(PARAM_NAMES):\n",
    "            ax.plot(range(n_iters), X_normalized[:, i], \n",
    "                   marker='o', markersize=4, alpha=0.7, linewidth=1.5, \n",
    "                   label=param_name)\n",
    "        \n",
    "        # Highlight initial samples phase\n",
    "        n_initial = self.optimizer.n_initial_samples\n",
    "        ax.axvspan(0, n_initial-1, alpha=0.1, color='orange')\n",
    "        \n",
    "        # Mark best iteration\n",
    "        ax.axvline(self.optimizer.best_iteration, color='red', linestyle='--', \n",
    "                  linewidth=2, alpha=0.7, label='Best found')\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Normalized Parameter Value', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Parameter Evolution', fontsize=13, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    def _plot_parameter_importance(self, ax):\n",
    "        \"\"\"Plot parameter sensitivity over time\"\"\"\n",
    "        if not hasattr(self.optimizer, 'importance_history') or not self.optimizer.importance_history:\n",
    "            ax.text(0.5, 0.5, 'Parameter importance\\nnot tracked\\n(Need more iterations)', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "            ax.set_title('Parameter Importance Over Time', fontsize=13, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        importance_array = np.array(self.optimizer.importance_history)\n",
    "        \n",
    "        # Check if all values are constant (indicating a problem)\n",
    "        if importance_array.shape[0] < 2 or np.allclose(importance_array[0], importance_array[-1]):\n",
    "            # Fall back to correlation-based importance from current samples\n",
    "            ax.text(0.5, 0.7, 'GP-based importance unavailable', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=11, style='italic')\n",
    "            ax.text(0.5, 0.5, 'Using correlation-based\\nimportance instead', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.text(0.5, 0.3, '(See parameter_sensitivity.png\\nfor detailed analysis)', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=9, style='italic')\n",
    "            ax.set_title('Parameter Importance Over Time', fontsize=13, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        # Plot importance evolution\n",
    "        iterations = np.arange(len(importance_array)) + self.optimizer.n_initial_samples\n",
    "        \n",
    "        for i, param_name in enumerate(PARAM_NAMES):\n",
    "            ax.plot(iterations, importance_array[:, i], \n",
    "                   marker='o', markersize=3, alpha=0.7, linewidth=1.5,\n",
    "                   label=param_name)\n",
    "        \n",
    "        ax.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Importance Score (1/length_scale)', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Parameter Importance Over Time\\n(Higher = More Sensitive)', fontsize=13, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add interpretation note\n",
    "        ax.text(0.98, 0.02, 'Note: Based on GP length scales\\nSmaller length scale → Higher importance', \n",
    "               transform=ax.transAxes, fontsize=7, ha='right', va='bottom',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    def _plot_trust_region(self, ax):\n",
    "        \"\"\"Plot trust region radius evolution\"\"\"\n",
    "        if not self.optimizer.trust_region.radius_history:\n",
    "            ax.text(0.5, 0.5, 'Trust region\\nhistory empty', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.set_title('Trust Region Evolution', fontsize=11, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        radius_history = self.optimizer.trust_region.radius_history\n",
    "        ax.plot(radius_history, marker='o', markersize=4, linewidth=2, color='purple')\n",
    "        ax.axhline(self.optimizer.trust_region.min_radius, color='red', \n",
    "                  linestyle='--', alpha=0.5, label='Min radius')\n",
    "        ax.axhline(self.optimizer.trust_region.max_radius, color='green', \n",
    "                  linestyle='--', alpha=0.5, label='Max radius')\n",
    "        \n",
    "        ax.set_xlabel('Update Step', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Trust Radius', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Trust Region Evolution', fontsize=11, fontweight='bold')\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def _plot_convergence_diagnostics(self, ax):\n",
    "        \"\"\"Plot convergence metrics\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        # Moving average of improvement\n",
    "        window = 5\n",
    "        improvements = []\n",
    "        for i in range(window, len(y_samples)):\n",
    "            if valid_mask[i]:\n",
    "                recent_best = np.nanmin(y_samples[max(0, i-window):i])\n",
    "                current = y_samples[i]\n",
    "                improvements.append(max(0, recent_best - current))\n",
    "            else:\n",
    "                improvements.append(0)\n",
    "        \n",
    "        iterations = np.arange(window, len(y_samples))\n",
    "        ax.bar(iterations, improvements, alpha=0.6, color='teal')\n",
    "        ax.set_xlabel('Iteration', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Recent Improvement', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Convergence Diagnostics', fontsize=11, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    def _plot_best_parameters(self, ax):\n",
    "        \"\"\"Bar chart of best parameters\"\"\"\n",
    "        if self.optimizer.best_params is None:\n",
    "            ax.text(0.5, 0.5, 'No best\\nparameters yet', \n",
    "                   ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "            ax.set_title('Best Parameters', fontsize=11, fontweight='bold')\n",
    "            return\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        best_normalized = warp_parameters(self.optimizer.best_params)\n",
    "        \n",
    "        colors = plt.cm.viridis(best_normalized)\n",
    "        bars = ax.barh(PARAM_NAMES, best_normalized, color=colors, alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Normalized Value', fontsize=10, fontweight='bold')\n",
    "        ax.set_title('Best Parameters (Normalized)', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Add actual values as text\n",
    "        for i, (bar, name) in enumerate(zip(bars, PARAM_NAMES)):\n",
    "            actual_val = self.optimizer.best_params[i]\n",
    "            ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{actual_val:.2e}', va='center', fontsize=7)\n",
    "    \n",
    "    def plot_parameter_sensitivity_heatmap(self, save_path='parameter_sensitivity.png'):\n",
    "        \"\"\"Create comprehensive parameter sensitivity analysis\"\"\"\n",
    "        X_samples = np.array(self.optimizer.X_samples)\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        if np.sum(valid_mask) < 5:\n",
    "            print(\"Not enough valid samples for sensitivity analysis\")\n",
    "            return\n",
    "        \n",
    "        X_valid = X_samples[valid_mask]\n",
    "        y_valid = y_samples[valid_mask]\n",
    "        \n",
    "        # Normalize parameters\n",
    "        X_normalized = np.array([warp_parameters(x) for x in X_valid])\n",
    "        \n",
    "        # Create comprehensive figure\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.35, wspace=0.35)\n",
    "        \n",
    "        # ========== Panel 1: Parameter-Loss Correlations ==========\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        correlations = []\n",
    "        for i in range(N_PARAMS):\n",
    "            corr = np.corrcoef(X_normalized[:, i], y_valid)[0, 1]\n",
    "            correlations.append(corr)\n",
    "        \n",
    "        colors = ['crimson' if c > 0 else 'forestgreen' for c in correlations]\n",
    "        bars = ax1.barh(PARAM_NAMES, correlations, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax1.axvline(0, color='black', linewidth=2)\n",
    "        ax1.set_xlabel('Correlation with Loss', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Parameter Sensitivity: Correlation with Loss\\n' + \n",
    "                     'RED = Increasing parameter WORSENS performance | GREEN = Increasing parameter IMPROVES performance',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, corr in zip(bars, correlations):\n",
    "            width = bar.get_width()\n",
    "            label = f'{corr:+.3f}'\n",
    "            ax1.text(width + (0.02 if width > 0 else -0.02), \n",
    "                    bar.get_y() + bar.get_height()/2, label,\n",
    "                    va='center', ha='left' if width > 0 else 'right',\n",
    "                    fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 2: Variance Explained ==========\n",
    "        ax2 = fig.add_subplot(gs[0, 2])\n",
    "        \n",
    "        # Simple variance explained: R² from linear fit\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        var_explained = []\n",
    "        for i in range(N_PARAMS):\n",
    "            X_param = X_normalized[:, i].reshape(-1, 1)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_param, y_valid)\n",
    "            r2 = model.score(X_param, y_valid)\n",
    "            var_explained.append(max(0, r2))  # Clip negative R²\n",
    "        \n",
    "        colors_var = plt.cm.RdYlGn_r(np.array(var_explained) / max(var_explained))\n",
    "        ax2.barh(PARAM_NAMES, var_explained, color=colors_var, alpha=0.8, edgecolor='black')\n",
    "        ax2.set_xlabel('Variance Explained (R²)', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Parameter Importance\\n(Higher = More Influential)', fontsize=11, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for i, (val, name) in enumerate(zip(var_explained, PARAM_NAMES)):\n",
    "            ax2.text(val + 0.01, i, f'{val:.3f}', va='center', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 3: Parameter Ranges Explored ==========\n",
    "        ax3 = fig.add_subplot(gs[1, :2])\n",
    "        \n",
    "        # Box plots showing explored ranges\n",
    "        positions = np.arange(N_PARAMS)\n",
    "        bp = ax3.boxplot([X_normalized[:, i] for i in range(N_PARAMS)],\n",
    "                         positions=positions, vert=False, patch_artist=True,\n",
    "                         widths=0.6, showfliers=True)\n",
    "        \n",
    "        for patch, corr in zip(bp['boxes'], correlations):\n",
    "            color = 'lightcoral' if corr > 0 else 'lightgreen'\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.6)\n",
    "        \n",
    "        ax3.set_yticks(positions)\n",
    "        ax3.set_yticklabels(PARAM_NAMES)\n",
    "        ax3.set_xlabel('Normalized Parameter Value [0=min, 1=max]', fontsize=12, fontweight='bold')\n",
    "        ax3.set_title('Parameter Space Exploration\\n(Box = 25th-75th percentile, Whiskers = min-max, Dots = outliers)',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='x')\n",
    "        ax3.set_xlim(-0.05, 1.05)\n",
    "        \n",
    "        # Mark best parameters\n",
    "        if self.optimizer.best_params is not None:\n",
    "            best_normalized = warp_parameters(self.optimizer.best_params)\n",
    "            ax3.scatter(best_normalized, positions, s=200, c='gold', marker='*', \n",
    "                       edgecolors='red', linewidth=2, zorder=10, label='Best Found')\n",
    "            ax3.legend(fontsize=10, loc='upper right')\n",
    "        \n",
    "        # ========== Panel 4: Loss vs Top 2 Parameters (Scatter) ==========\n",
    "        abs_corr = np.abs(correlations)\n",
    "        top_2_indices = np.argsort(abs_corr)[-2:]\n",
    "        \n",
    "        ax4 = fig.add_subplot(gs[1, 2])\n",
    "        param_idx_1, param_idx_2 = top_2_indices[1], top_2_indices[0]\n",
    "        \n",
    "        scatter = ax4.scatter(X_normalized[:, param_idx_1], X_normalized[:, param_idx_2],\n",
    "                            c=y_valid, cmap='viridis_r', s=80, alpha=0.6,\n",
    "                            edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Mark best point\n",
    "        if self.optimizer.best_params is not None:\n",
    "            best_norm = warp_parameters(self.optimizer.best_params)\n",
    "            ax4.scatter(best_norm[param_idx_1], best_norm[param_idx_2],\n",
    "                       s=300, c='gold', marker='*', edgecolors='red', linewidth=2.5,\n",
    "                       zorder=10, label='Best')\n",
    "        \n",
    "        ax4.set_xlabel(f'{PARAM_NAMES[param_idx_1]}', fontsize=11, fontweight='bold')\n",
    "        ax4.set_ylabel(f'{PARAM_NAMES[param_idx_2]}', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title(f'Top 2 Most Influential Parameters\\n(Lower loss = Better)', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        ax4.legend(fontsize=9)\n",
    "        \n",
    "        cbar = plt.colorbar(scatter, ax=ax4)\n",
    "        cbar.set_label('Loss', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 5: Parameter Value Distributions ==========\n",
    "        ax5 = fig.add_subplot(gs[2, :2])\n",
    "        \n",
    "        # Show distribution of sampled values for top 3 parameters\n",
    "        top_3_indices = np.argsort(abs_corr)[-3:]\n",
    "        colors_dist = ['red', 'orange', 'green']\n",
    "        \n",
    "        for idx_rank, param_idx in enumerate(top_3_indices[::-1]):\n",
    "            values = X_normalized[:, param_idx]\n",
    "            ax5.hist(values, bins=15, alpha=0.5, color=colors_dist[idx_rank], \n",
    "                    label=PARAM_NAMES[param_idx], edgecolor='black', linewidth=1)\n",
    "        \n",
    "        ax5.set_xlabel('Normalized Parameter Value', fontsize=12, fontweight='bold')\n",
    "        ax5.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "        ax5.set_title('Sampling Distribution of Top 3 Most Influential Parameters',\n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax5.legend(fontsize=10)\n",
    "        ax5.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # ========== Panel 6: Parameter Importance Summary ==========\n",
    "        ax6 = fig.add_subplot(gs[2, 2])\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # Create summary text\n",
    "        summary_lines = [\n",
    "            \"INTERPRETATION GUIDE:\",\n",
    "            \"\",\n",
    "            \"Correlation:\",\n",
    "            \"  • Positive = increasing parameter worsens loss\",\n",
    "            \"  • Negative = increasing parameter improves loss\",\n",
    "            \"  • Magnitude = strength of relationship\",\n",
    "            \"\",\n",
    "            \"Variance Explained (R²):\",\n",
    "            \"  • How much loss variation this parameter explains\",\n",
    "            \"  • Higher = more important to tune carefully\",\n",
    "            \"\",\n",
    "            \"Top 3 Most Important Parameters:\",\n",
    "        ]\n",
    "        \n",
    "        top_3_with_corr = [(PARAM_NAMES[i], correlations[i], var_explained[i]) \n",
    "                           for i in np.argsort(abs_corr)[-3:][::-1]]\n",
    "        \n",
    "        for rank, (name, corr, var_exp) in enumerate(top_3_with_corr, 1):\n",
    "            direction = \"↑ worsens\" if corr > 0 else \"↓ improves\"\n",
    "            summary_lines.append(f\"  {rank}. {name}\")\n",
    "            summary_lines.append(f\"     Corr: {corr:+.3f} ({direction})\")\n",
    "            summary_lines.append(f\"     R²: {var_exp:.3f}\")\n",
    "        \n",
    "        summary_text = '\\n'.join(summary_lines)\n",
    "        ax6.text(0.05, 0.95, summary_text, transform=ax6.transAxes,\n",
    "                fontsize=10, verticalalignment='top', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Comprehensive Parameter Sensitivity Analysis', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Saved sensitivity analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_computational_efficiency(self, save_path='computational_efficiency.png'):\n",
    "        \"\"\"Analyze computational cost vs improvement\"\"\"\n",
    "        y_samples = np.array(self.optimizer.y_samples)\n",
    "        valid_mask = np.isfinite(y_samples)\n",
    "        \n",
    "        if np.sum(valid_mask) < 5:\n",
    "            print(\"Not enough valid samples for efficiency analysis\")\n",
    "            return\n",
    "        \n",
    "        # Estimate computational cost (30-day = 1 unit, 180-day = 6 units)\n",
    "        cumulative_cost = []\n",
    "        cost_per_iteration = []\n",
    "        total_cost = 0\n",
    "        \n",
    "        for i in range(len(y_samples)):\n",
    "            sim_days, _, _ = get_adaptive_sim_days(i)\n",
    "            cost = sim_days / 30.0  # Normalize to 30-day cost\n",
    "            cost_per_iteration.append(cost)\n",
    "            total_cost += cost\n",
    "            cumulative_cost.append(total_cost)\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(18, 10))\n",
    "        gs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # ========== Panel 1: Cumulative Cost vs Improvement ==========\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        \n",
    "        # Best loss trajectory - split by fidelity\n",
    "        best_trajectory_30d = []\n",
    "        best_trajectory_180d = []\n",
    "        current_best_30d = np.inf\n",
    "        current_best_180d = np.inf\n",
    "        \n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            _, fidelity_desc, _ = get_adaptive_sim_days(i)\n",
    "            \n",
    "            if i < n_fast_phase_end:  # 30-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_30d:\n",
    "                    current_best_30d = loss\n",
    "                best_trajectory_30d.append(current_best_30d if current_best_30d != np.inf else np.nan)\n",
    "                best_trajectory_180d.append(np.nan)  # Not applicable yet\n",
    "            else:  # 180-day fidelity\n",
    "                if np.isfinite(loss) and loss < current_best_180d:\n",
    "                    current_best_180d = loss\n",
    "                best_trajectory_30d.append(np.nan)  # 30-day phase is over\n",
    "                best_trajectory_180d.append(current_best_180d if current_best_180d != np.inf else np.nan)\n",
    "        \n",
    "        ax1_twin = ax1.twinx()\n",
    "        \n",
    "        # Plot cumulative cost\n",
    "        color_cost = 'steelblue'\n",
    "        line1 = ax1.plot(range(len(cumulative_cost)), cumulative_cost, \n",
    "                color=color_cost, linewidth=2.5, label='Cumulative Cost', marker='o', markersize=4)\n",
    "        ax1.set_xlabel('Iteration', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Cumulative Computational Cost (30-day equiv.)', \n",
    "                      fontsize=11, fontweight='bold', color=color_cost)\n",
    "        ax1.tick_params(axis='y', labelcolor=color_cost)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot best loss for 30-day fidelity\n",
    "        color_loss_30d = 'limegreen'\n",
    "        valid_indices_30d = [i for i, loss in enumerate(best_trajectory_30d) if np.isfinite(loss)]\n",
    "        valid_trajectory_30d = [best_trajectory_30d[i] for i in valid_indices_30d]\n",
    "        line2 = ax1_twin.plot(valid_indices_30d, valid_trajectory_30d, \n",
    "                     color=color_loss_30d, linewidth=2.5, label='Best Loss (30d)', \n",
    "                     marker='o', markersize=6, linestyle='-', alpha=0.8)\n",
    "        \n",
    "        # Plot best loss for 180-day fidelity\n",
    "        color_loss_180d = 'darkgreen'\n",
    "        valid_indices_180d = [i for i, loss in enumerate(best_trajectory_180d) if np.isfinite(loss)]\n",
    "        valid_trajectory_180d = [best_trajectory_180d[i] for i in valid_indices_180d]\n",
    "        line3 = ax1_twin.plot(valid_indices_180d, valid_trajectory_180d, \n",
    "                     color=color_loss_180d, linewidth=3, label='Best Loss (180d)', \n",
    "                     marker='*', markersize=8, linestyle='-')\n",
    "        \n",
    "        ax1_twin.set_ylabel('Best Loss', fontsize=11, fontweight='bold', color='darkgreen')\n",
    "        ax1_twin.tick_params(axis='y', labelcolor='darkgreen')\n",
    "        \n",
    "        # Mark fidelity transition\n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)\n",
    "        line4 = ax1.axvline(n_fast_phase_end, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Fidelity Jump')\n",
    "        \n",
    "        # Add annotation explaining the jump\n",
    "        if len(valid_indices_30d) > 0 and len(valid_indices_180d) > 0:\n",
    "            last_30d_loss = valid_trajectory_30d[-1]\n",
    "            first_180d_loss = valid_trajectory_180d[0]\n",
    "            if np.isfinite(last_30d_loss) and np.isfinite(first_180d_loss):\n",
    "                jump_pct = (first_180d_loss - last_30d_loss) / last_30d_loss * 100\n",
    "                ax1_twin.annotate(f'Re-eval: {jump_pct:+.1f}%',\n",
    "                                 xy=(n_fast_phase_end, first_180d_loss), xytext=(n_fast_phase_end + 5, first_180d_loss * 1.1),\n",
    "                                 arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                                 fontsize=8, color='red', fontweight='bold',\n",
    "                                 bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "        \n",
    "        ax1.set_title('Computational Efficiency: Cost vs Improvement Over Time\\n(Separate best loss tracking for each fidelity)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Combine legends from both axes\n",
    "        lines = line1 + line2 + line3 + [line4]\n",
    "        labels = [l.get_label() for l in lines]\n",
    "        ax1.legend(lines, labels, loc='upper left', fontsize=9)\n",
    "        \n",
    "        # ========== Panel 2: Improvement per Cost Unit ==========\n",
    "        ax2 = fig.add_subplot(gs[0, 2])\n",
    "        \n",
    "        # Calculate improvement per cost for each iteration\n",
    "        if self.optimizer.baseline_loss:\n",
    "            improvements = []\n",
    "            for i, loss in enumerate(y_samples):\n",
    "                if np.isfinite(loss):\n",
    "                    improvement = max(0, self.optimizer.baseline_loss - loss)\n",
    "                    improvements.append(improvement / cost_per_iteration[i])\n",
    "                else:\n",
    "                    improvements.append(0)\n",
    "            \n",
    "            # Moving average\n",
    "            window = 5\n",
    "            smooth_improvements = []\n",
    "            for i in range(len(improvements)):\n",
    "                start = max(0, i - window + 1)\n",
    "                smooth_improvements.append(np.mean(improvements[start:i+1]))\n",
    "            \n",
    "            ax2.plot(range(len(smooth_improvements)), smooth_improvements, \n",
    "                    color='purple', linewidth=2.5, label='Smoothed')\n",
    "            ax2.scatter(range(len(improvements)), improvements, \n",
    "                       alpha=0.4, s=30, c='gray', label='Raw')\n",
    "            \n",
    "            ax2.set_xlabel('Iteration', fontsize=11, fontweight='bold')\n",
    "            ax2.set_ylabel('Improvement per Cost Unit', fontsize=10, fontweight='bold')\n",
    "            ax2.set_title('Sample Efficiency\\n(Higher = Better)', fontsize=11, fontweight='bold')\n",
    "            ax2.legend(fontsize=9)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ========== Panel 3: Cost Breakdown by Phase ==========\n",
    "        ax3 = fig.add_subplot(gs[1, 0])\n",
    "        \n",
    "        # Calculate costs by phase with dynamic thresholds\n",
    "        n_init = self.optimizer.n_initial_samples\n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)  # Initial + Fast phase\n",
    "        \n",
    "        phase_names = ['Initial\\nSampling', 'Fast\\nExploration\\n(30d)', 'Full\\nPrecision\\n(180d)']\n",
    "        phase_costs = [0, 0, 0]\n",
    "        phase_iters = [0, 0, 0]\n",
    "        \n",
    "        for i, cost in enumerate(cost_per_iteration):\n",
    "            if i < n_init:\n",
    "                phase_costs[0] += cost\n",
    "                phase_iters[0] += 1\n",
    "            elif i < n_fast_phase_end:\n",
    "                phase_costs[1] += cost\n",
    "                phase_iters[1] += 1\n",
    "            else:\n",
    "                phase_costs[2] += cost\n",
    "                phase_iters[2] += 1\n",
    "        \n",
    "        colors_phase = ['orange', 'lightblue', 'lightcoral']\n",
    "        bars = ax3.bar(phase_names, phase_costs, color=colors_phase, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax3.set_ylabel('Total Computational Cost', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('Cost Breakdown by Phase', fontsize=11, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add iteration counts and percentages\n",
    "        for bar, cost, n_iter in zip(bars, phase_costs, phase_iters):\n",
    "            height = bar.get_height()\n",
    "            pct = cost / sum(phase_costs) * 100\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{cost:.1f}\\n({n_iter} iters)\\n{pct:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 4: Improvements Found by Phase ==========\n",
    "        ax4 = fig.add_subplot(gs[1, 1])\n",
    "        \n",
    "        # Count new bests found in each phase - compare to baseline at SAME fidelity\n",
    "        best_found_phase = [0, 0, 0]\n",
    "        \n",
    "        # Track best at each fidelity level separately\n",
    "        best_30d = self.optimizer.baseline_loss_by_fidelity.get('FAST (30d)', np.inf)\n",
    "        best_180d = self.optimizer.baseline_loss_by_fidelity.get('FULL (180d)', np.inf)\n",
    "        \n",
    "        n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)  # End of fast phase\n",
    "        \n",
    "        for i, loss in enumerate(y_samples):\n",
    "            if not np.isfinite(loss):\n",
    "                continue\n",
    "            \n",
    "            _, fidelity_desc, _ = get_adaptive_sim_days(i)\n",
    "            \n",
    "            # Compare against baseline at same fidelity\n",
    "            if fidelity_desc == 'FAST (30d)':\n",
    "                if loss < best_30d:\n",
    "                    best_30d = loss\n",
    "                    # Classify into phase\n",
    "                    if i < n_init:\n",
    "                        best_found_phase[0] += 1\n",
    "                    else:\n",
    "                        best_found_phase[1] += 1\n",
    "            elif fidelity_desc == 'FULL (180d)':\n",
    "                if loss < best_180d:\n",
    "                    best_180d = loss\n",
    "                    best_found_phase[2] += 1\n",
    "        \n",
    "        bars2 = ax4.bar(phase_names, best_found_phase, color=colors_phase, alpha=0.7, \n",
    "                       edgecolor='black', linewidth=2)\n",
    "        ax4.set_ylabel('Number of Improvements Found', fontsize=11, fontweight='bold')\n",
    "        ax4.set_title('Improvements Discovered by Phase\\n(vs baseline at same fidelity)', fontsize=11, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        for bar, count in zip(bars2, best_found_phase):\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{int(count)}', ha='center', va='bottom', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # ========== Panel 5: Efficiency Summary ==========\n",
    "        ax5 = fig.add_subplot(gs[1, 2])\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        total_simulations = len(y_samples)\n",
    "        total_cost_units = cumulative_cost[-1] if cumulative_cost else 0\n",
    "        avg_cost_per_iter = total_cost_units / total_simulations if total_simulations > 0 else 0\n",
    "        \n",
    "        if self.optimizer.baseline_loss:\n",
    "            total_improvement = self.optimizer.baseline_loss - self.optimizer.best_loss\n",
    "            improvement_pct = total_improvement / self.optimizer.baseline_loss * 100\n",
    "            cost_per_pct_improvement = total_cost_units / improvement_pct if improvement_pct > 0 else np.inf\n",
    "        else:\n",
    "            total_improvement = 0\n",
    "            improvement_pct = 0\n",
    "            cost_per_pct_improvement = np.inf\n",
    "        \n",
    "        # Phase efficiency\n",
    "        phase_efficiency = []\n",
    "        for i in range(3):\n",
    "            if phase_costs[i] > 0 and best_found_phase[i] > 0:\n",
    "                eff = best_found_phase[i] / phase_costs[i]\n",
    "                phase_efficiency.append(eff)\n",
    "            else:\n",
    "                phase_efficiency.append(0)\n",
    "        \n",
    "        summary_lines = [\n",
    "            \"COMPUTATIONAL EFFICIENCY SUMMARY\",\n",
    "            \"=\" * 35,\n",
    "            \"\",\n",
    "            f\"Total Iterations: {total_simulations}\",\n",
    "            f\"Total Cost: {total_cost_units:.1f} units\",\n",
    "            f\"  (1 unit = one 30-day simulation)\",\n",
    "            f\"Avg Cost/Iter: {avg_cost_per_iter:.2f} units\",\n",
    "            \"\",\n",
    "            f\"Total Improvement: {improvement_pct:.1f}%\",\n",
    "            f\"Cost per 1% Improvement: {cost_per_pct_improvement:.2f} units\",\n",
    "            \"\",\n",
    "            \"Phase Efficiency (improvements/cost):\",\n",
    "            f\"  Initial: {phase_efficiency[0]:.3f}\",\n",
    "            f\"  Fast (30d): {phase_efficiency[1]:.3f}\",\n",
    "            f\"  Full (180d): {phase_efficiency[2]:.3f}\",\n",
    "            \"\",\n",
    "            \"INTERPRETATION:\",\n",
    "            \"• Higher efficiency = more improvements\",\n",
    "            \"  per computational cost\",\n",
    "            \"• Fast phase should have high efficiency\",\n",
    "            \"• Full phase validates with precision\",\n",
    "            \"• Improvements in Full phase are vs\",\n",
    "            \"  the 180d baseline (not 30d best)\",\n",
    "        ]\n",
    "        \n",
    "        summary_text = '\\n'.join(summary_lines)\n",
    "        ax5.text(0.05, 0.95, summary_text, transform=ax5.transAxes,\n",
    "                fontsize=9, verticalalignment='top', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Computational Efficiency Analysis', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        \n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        print(f\"✓ Saved efficiency analysis: {save_path}\")\n",
    "        plt.close()\n",
    "    \n",
    "    def create_all_plots(self):\n",
    "        \"\"\"Generate all visualization plots\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING VISUALIZATION SUITE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self.plot_comprehensive_analysis()\n",
    "        self.plot_parameter_sensitivity_heatmap()\n",
    "        self.plot_computational_efficiency()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"✓ All visualizations complete!\")\n",
    "        print(\"  - optimization_analysis.png: Loss curves, parameters, trust region\")\n",
    "        print(\"  - parameter_sensitivity.png: Which parameters matter most\")\n",
    "        print(\"  - computational_efficiency.png: Cost vs improvement analysis\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 3-WAY COMPARISON VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def create_three_way_comparison(highres_results, lowres_default_results, lowres_optimized_results, \n",
    "                                 save_path='three_way_comparison.png'):\n",
    "    \"\"\"\n",
    "    Enhanced 3-way comparison with error differences and improvement maps\n",
    "    Shows spatial fields, errors, and where optimization improved performance\n",
    "    NOTE: Uses last 30 days for all (assumes all are 180-day runs)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING ENHANCED 3-WAY COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Compute losses with FIXED window (last 30 days) for fair comparison\n",
    "    loss_default, fields_default = compute_loss(lowres_default_results, highres_results, \n",
    "                                                n_days_avg=30, return_fields=True, adaptive_window=False)\n",
    "    loss_optimized, fields_optimized = compute_loss(lowres_optimized_results, highres_results, \n",
    "                                                    n_days_avg=30, return_fields=True, adaptive_window=False)\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement_pct = (loss_default - loss_optimized) / loss_default * 100\n",
    "    \n",
    "    # Helper function for consistent contourf plotting\n",
    "    def add_contourf(ax, data, levels, cmap, title=None, colorbar=True):\n",
    "        cf = ax.contourf(data, levels=levels, cmap=cmap, extend='both', origin='lower')\n",
    "        if title:\n",
    "            ax.set_title(title, fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        if colorbar:\n",
    "            plt.colorbar(cf, ax=ax, fraction=0.046, pad=0.04)\n",
    "        return cf\n",
    "    \n",
    "    # Create figure/grid - 4 rows x 3 columns\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    gs = gridspec.GridSpec(4, 3, figure=fig, hspace=0.3, wspace=0.25)\n",
    "    \n",
    "    # ========== Row 1: Potential Vorticity Fields ==========\n",
    "    q_ref = fields_default['q_bt_hr_coarse']\n",
    "    qmin, qmax = float(np.nanmin(q_ref)), float(np.nanmax(q_ref))\n",
    "    q_levels = np.linspace(qmin, qmax, 31)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    add_contourf(ax1, q_ref, q_levels, 'RdBu_r', 'High-Res Reference\\nPotential Vorticity')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    cf2 = add_contourf(ax2, fields_default['q_bt_lr'], q_levels, 'RdBu_r',\n",
    "                       f'DEFAULT (Loss: {loss_default:.4f})')\n",
    "    ax2.title.set_color('darkred')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    cf3 = add_contourf(ax3, fields_optimized['q_bt_lr'], q_levels, 'RdBu_r',\n",
    "                       f'OPTIMIZED (Loss: {loss_optimized:.4f})')\n",
    "    ax3.title.set_color('darkgreen')\n",
    "    \n",
    "    # ========== Row 2: PV Errors + Improvement Map ==========\n",
    "    error_default_pv = np.abs(fields_default['q_bt_lr'] - fields_default['q_bt_hr_coarse'])\n",
    "    error_optimized_pv = np.abs(fields_optimized['q_bt_lr'] - fields_optimized['q_bt_hr_coarse'])\n",
    "    errmax_pv = float(max(np.nanmax(error_default_pv), np.nanmax(error_optimized_pv)))\n",
    "    err_levels_pv = np.linspace(0.0, errmax_pv, 31)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    add_contourf(ax4, error_default_pv, err_levels_pv, 'Reds',\n",
    "                 f'DEFAULT Error\\nNRMSE: {fields_default[\"loss_q_bt\"]:.4f}')\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    add_contourf(ax5, error_optimized_pv, err_levels_pv, 'Reds',\n",
    "                 f'OPTIMIZED Error\\nNRMSE: {fields_optimized[\"loss_q_bt\"]:.4f}')\n",
    "    \n",
    "    # Improvement map: negative values = optimized is better (green), positive = worse (red)\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    error_diff_pv = error_optimized_pv - error_default_pv\n",
    "    diff_max = float(max(abs(np.nanmin(error_diff_pv)), abs(np.nanmax(error_diff_pv))))\n",
    "    diff_levels = np.linspace(-diff_max, diff_max, 31)\n",
    "    cf_diff = add_contourf(ax6, error_diff_pv, diff_levels, 'RdYlGn_r',\n",
    "                          f'Error Difference (Opt - Def)\\nGreen = Improvement')\n",
    "    \n",
    "    # ========== Row 3: Streamfunction Fields ==========\n",
    "    psi_ref = fields_default['psi_bt_hr_coarse']\n",
    "    psi_absmax = float(np.nanmax(np.abs(psi_ref)))\n",
    "    psi_levels = np.linspace(-psi_absmax, psi_absmax, 41)\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[2, 0])\n",
    "    add_contourf(ax7, psi_ref, psi_levels, 'RdBu_r', 'High-Res Reference\\nStreamfunction')\n",
    "    \n",
    "    ax8 = fig.add_subplot(gs[2, 1])\n",
    "    add_contourf(ax8, fields_default['psi_bt_lr'], psi_levels, 'RdBu_r', 'DEFAULT')\n",
    "    \n",
    "    ax9 = fig.add_subplot(gs[2, 2])\n",
    "    add_contourf(ax9, fields_optimized['psi_bt_lr'], psi_levels, 'RdBu_r', 'OPTIMIZED')\n",
    "    \n",
    "    # ========== Row 4: Streamfunction Errors + Improvement Map ==========\n",
    "    error_default_psi = np.abs(fields_default['psi_bt_lr'] - fields_default['psi_bt_hr_coarse'])\n",
    "    error_optimized_psi = np.abs(fields_optimized['psi_bt_lr'] - fields_optimized['psi_bt_hr_coarse'])\n",
    "    errmax_psi = float(max(np.nanmax(error_default_psi), np.nanmax(error_optimized_psi)))\n",
    "    err_levels_psi = np.linspace(0.0, errmax_psi, 31)\n",
    "    \n",
    "    ax10 = fig.add_subplot(gs[3, 0])\n",
    "    add_contourf(ax10, error_default_psi, err_levels_psi, 'Reds',\n",
    "                 f'DEFAULT Error\\nNRMSE: {fields_default[\"loss_psi_bt\"]:.4f}')\n",
    "    \n",
    "    ax11 = fig.add_subplot(gs[3, 1])\n",
    "    add_contourf(ax11, error_optimized_psi, err_levels_psi, 'Reds',\n",
    "                 f'OPTIMIZED Error\\nNRMSE: {fields_optimized[\"loss_psi_bt\"]:.4f}')\n",
    "    \n",
    "    # Improvement map for streamfunction\n",
    "    ax12 = fig.add_subplot(gs[3, 2])\n",
    "    error_diff_psi = error_optimized_psi - error_default_psi\n",
    "    diff_max_psi = float(max(abs(np.nanmin(error_diff_psi)), abs(np.nanmax(error_diff_psi))))\n",
    "    diff_levels_psi = np.linspace(-diff_max_psi, diff_max_psi, 31)\n",
    "    add_contourf(ax12, error_diff_psi, diff_levels_psi, 'RdYlGn_r',\n",
    "                 f'Error Difference (Opt - Def)\\nGreen = Improvement')\n",
    "    \n",
    "    # Add overall summary text box\n",
    "    summary_text = (\n",
    "        f\"OVERALL IMPROVEMENT: {improvement_pct:+.1f}%\\n\"\n",
    "        f\"━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n",
    "        f\"Total Loss:  {loss_default:.4f} → {loss_optimized:.4f}\\n\"\n",
    "        f\"PV Loss:     {fields_default['loss_q_bt']:.4f} → {fields_optimized['loss_q_bt']:.4f} ({(fields_default['loss_q_bt']-fields_optimized['loss_q_bt'])/fields_default['loss_q_bt']*100:+.1f}%)\\n\"\n",
    "        f\"Ψ Loss:      {fields_default['loss_psi_bt']:.4f} → {fields_optimized['loss_psi_bt']:.4f} ({(fields_default['loss_psi_bt']-fields_optimized['loss_psi_bt'])/fields_default['loss_psi_bt']*100:+.1f}%)\\n\"\n",
    "        f\"━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n",
    "        f\"Green regions = Optimized better\\n\"\n",
    "        f\"Red regions = Optimized worse\"\n",
    "    )\n",
    "    \n",
    "    fig.text(0.5, 0.01, summary_text, ha='center', va='bottom', fontsize=10, \n",
    "             family='monospace', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))\n",
    "    \n",
    "    plt.suptitle('Enhanced 3-Way Comparison: Spatial Fields & Error Analysis',\n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    print(f\"✓ Saved enhanced 3-way comparison: {save_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARISON SUMMARY (All using last 30 days)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"High-Res (Reference):\")\n",
    "    print(f\"  Resolution: {highres_results['config']['nx']}x{highres_results['config']['ny']}\")\n",
    "    print(f\"  Time window: last 30 days (equilibrated state)\")\n",
    "    print(f\"\\nLow-Res DEFAULT:\")\n",
    "    print(f\"  Resolution: {lowres_default_results['config']['nx']}x{lowres_default_results['config']['ny']}\")\n",
    "    print(f\"  PV Loss: {fields_default['loss_q_bt']:.6f}\")\n",
    "    print(f\"  Streamfn Loss: {fields_default['loss_psi_bt']:.6f}\")\n",
    "    print(f\"  Total Loss: {loss_default:.6f}\")\n",
    "    print(f\"\\nLow-Res OPTIMIZED:\")\n",
    "    print(f\"  Resolution: {lowres_optimized_results['config']['nx']}x{lowres_optimized_results['config']['ny']}\")\n",
    "    print(f\"  PV Loss: {fields_optimized['loss_q_bt']:.6f} ({(fields_default['loss_q_bt']-fields_optimized['loss_q_bt'])/fields_default['loss_q_bt']*100:+.1f}%)\")\n",
    "    print(f\"  Streamfn Loss: {fields_optimized['loss_psi_bt']:.6f} ({(fields_default['loss_psi_bt']-fields_optimized['loss_psi_bt'])/fields_default['loss_psi_bt']*100:+.1f}%)\")\n",
    "    print(f\"  Total Loss: {loss_optimized:.6f}\")\n",
    "    \n",
    "    # Spatial improvement statistics\n",
    "    pv_improvements = error_default_pv - error_optimized_pv\n",
    "    psi_improvements = error_default_psi - error_optimized_psi\n",
    "    \n",
    "    print(f\"\\nSpatial Improvement Statistics:\")\n",
    "    print(f\"  PV Error Reduction:\")\n",
    "    print(f\"    Mean: {np.mean(pv_improvements):.6f}\")\n",
    "    print(f\"    Median: {np.median(pv_improvements):.6f}\")\n",
    "    print(f\"    % improved points: {100*np.sum(pv_improvements > 0)/pv_improvements.size:.1f}%\")\n",
    "    print(f\"  Streamfunction Error Reduction:\")\n",
    "    print(f\"    Mean: {np.mean(psi_improvements):.6f}\")\n",
    "    print(f\"    Median: {np.median(psi_improvements):.6f}\")\n",
    "    print(f\"    % improved points: {100*np.sum(psi_improvements > 0)/psi_improvements.size:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n{Colors.star(f'TOTAL IMPROVEMENT: {improvement_pct:.1f}%')}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Enhanced GP Optimizer with visualization and warm-start\n",
    "class EnhancedGPOptimizer:\n",
    "    \"\"\"Enhanced GP with visualization, warm-start, and 3-way comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, n_initial_samples=None, random_seed=42):\n",
    "        # Dynamic initial samples based on parameters (4x for good coverage)\n",
    "        self.n_initial_samples = n_initial_samples if n_initial_samples is not None else (4 * N_PARAMS)\n",
    "        self.random_seed = random_seed  # Store for reproducibility\n",
    "        self.X_samples, self.y_samples, self.detailed_outputs = [], [], []\n",
    "        self.best_loss, self.best_params, self.best_iteration = np.inf, None, -1\n",
    "        self.iteration, self.iterations_without_improvement = 0, 0\n",
    "        self.stagnation_threshold = 15\n",
    "        self.gp = EnsembleGP(n_models=8)\n",
    "        self.trust_region = TrustRegion()\n",
    "        self.importance_history = []\n",
    "        self.use_thompson_sampling_prob = 0.1\n",
    "        self.baseline_loss = None  # Track default params loss at FINAL fidelity\n",
    "        self.baseline_loss_by_fidelity = {}  # Track baseline for each fidelity level\n",
    "        self.default_results = None  # Store default results for comparison\n",
    "        self.current_fidelity = None  # Track current fidelity level\n",
    "        self.best_params_original_iteration = None  # Track when best params were first discovered\n",
    "        \n",
    "        # Set numpy random seed for reproducibility\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    def optimize(self, config_base, highres_results, max_iterations=100):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ENHANCED GP: WARM-START + DYNAMIC 2-LEVEL MULTI-FIDELITY + VISUALIZATION\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Features:\")\n",
    "        print(\"  ✓ Warm-start from reference parameters\")\n",
    "        print(\"  ✓ 8-model weighted ensemble\")\n",
    "        print(\"  ✓ Local penalization (space coverage)\")\n",
    "        print(f\"  ✓ Dynamic 2-level multi-fidelity strategy (based on {N_PARAMS} params):\")\n",
    "        print(f\"    • Initial phase: {4*N_PARAMS} iterations at 30-day fidelity\")\n",
    "        print(f\"    • Fast phase: {2*N_PARAMS} iterations at 30-day fidelity\")\n",
    "        print(f\"    • Full phase: {2*N_PARAMS}+ iterations at 180-day fidelity\")\n",
    "        print(\"  ✓ Adaptive time windows for fair comparison:\")\n",
    "        print(\"    • 30-day runs: compare entire simulation (days 0-30)\")\n",
    "        print(\"    • 180-day runs: compare last 30 days (equilibrated)\")\n",
    "        print(\"  ✓ Fidelity-aware baseline tracking\")\n",
    "        print(\"  ✓ Thompson sampling (10% exploration)\")\n",
    "        print(\"  ✓ Anti-stagnation (auto-restart)\")\n",
    "        print(\"  ✓ 3-way comparison visualization\")\n",
    "        print(f\"  Max iterations: {max_iterations}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Phase 1: Initial sampling with WARM-START\n",
    "        n_existing = len(self.X_samples)\n",
    "        if n_existing < self.n_initial_samples:\n",
    "            print(f\"\\n{'='*70}\\nPHASE 1: WARM-START INITIALIZATION (seed={self.random_seed})\\n{'='*70}\")\n",
    "            initial_samples = generate_smart_initial_samples(self.n_initial_samples, \n",
    "                                                            include_default=True,\n",
    "                                                            base_seed=self.random_seed)\n",
    "            \n",
    "            for i, params in enumerate(initial_samples[n_existing:]):\n",
    "                iter_num = i + n_existing\n",
    "                is_default = (iter_num == 0 and n_existing == 0)  # First sample is default\n",
    "                \n",
    "                print(f\"\\n[Initial {iter_num+1}/{self.n_initial_samples}]\" + \n",
    "                      (Colors.star(\" DEFAULT PARAMETERS\") if is_default else \"\"))\n",
    "                \n",
    "                loss, results, detailed = run_lowres_with_params(\n",
    "                    params, config_base, highres_results, iteration=iter_num\n",
    "                )\n",
    "                self.X_samples.append(params)\n",
    "                self.y_samples.append(loss)\n",
    "                self.detailed_outputs.append(detailed)\n",
    "                \n",
    "                # Track baseline from default params\n",
    "                if is_default and np.isfinite(loss):\n",
    "                    _, fidelity_desc, _ = get_adaptive_sim_days(iter_num)\n",
    "                    self.current_fidelity = fidelity_desc\n",
    "                    self.baseline_loss = loss\n",
    "                    self.baseline_loss_by_fidelity[fidelity_desc] = loss\n",
    "                    self.default_results = results\n",
    "                    print(Colors.cyan(f\"  → Baseline loss at {fidelity_desc}: {loss:.6f}\"))\n",
    "                \n",
    "                if np.isfinite(loss) and loss < self.best_loss:\n",
    "                    self.best_loss, self.best_params = loss, params.copy()\n",
    "                    self.best_iteration, self.iterations_without_improvement = len(self.X_samples) - 1, 0\n",
    "                    self.best_params_original_iteration = iter_num  # Track discovery iteration\n",
    "                    if is_default:\n",
    "                        print(Colors.star(f\"BASELINE SET: {Colors.green(f'{loss:.6f}')}\"))\n",
    "                    else:\n",
    "                        # Compare to baseline at SAME fidelity\n",
    "                        _, fidelity_desc, _ = get_adaptive_sim_days(iter_num)\n",
    "                        fidelity_baseline = self.baseline_loss_by_fidelity.get(fidelity_desc, self.baseline_loss)\n",
    "                        if fidelity_baseline:\n",
    "                            improvement = (fidelity_baseline - loss) / fidelity_baseline * 100\n",
    "                            print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')} ({improvement:+.1f}% vs baseline @ {fidelity_desc})\"))\n",
    "                        else:\n",
    "                            print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')}\"))\n",
    "                self.save_progress()\n",
    "        \n",
    "        # Phase 2: Bayesian optimization\n",
    "        print(f\"\\n{'='*70}\\nPHASE 2: BAYESIAN OPTIMIZATION\\n{'='*70}\")\n",
    "        \n",
    "        for iteration in range(len(self.X_samples), max_iterations):\n",
    "            self.iteration, self.iterations_without_improvement = iteration, self.iterations_without_improvement + 1\n",
    "            \n",
    "            print(f\"\\n{'='*70}\\n{Colors.cyan(f'ITERATION {iteration + 1}/{max_iterations}')}\\n{'='*70}\")\n",
    "            \n",
    "            # Check if fidelity level changed - if so, re-evaluate baseline AND best params\n",
    "            _, fidelity_desc, _ = get_adaptive_sim_days(iteration)\n",
    "            if fidelity_desc != self.current_fidelity:\n",
    "                old_fidelity = self.current_fidelity\n",
    "                self.current_fidelity = fidelity_desc\n",
    "                print(Colors.red(f\"\\n{'='*70}\"))\n",
    "                print(Colors.red(f\"⚠ FIDELITY TRANSITION: {old_fidelity} → {fidelity_desc}\"))\n",
    "                print(Colors.red(f\"{'='*70}\"))\n",
    "                \n",
    "                # Re-evaluate baseline at new fidelity if not already done\n",
    "                if fidelity_desc not in self.baseline_loss_by_fidelity:\n",
    "                    print(Colors.cyan(f\"→ Re-evaluating BASELINE at {fidelity_desc} fidelity...\"))\n",
    "                    default_array = params_dict_to_array(DEFAULT_PARAMS)\n",
    "                    baseline_loss, baseline_results, _ = run_lowres_with_params(\n",
    "                        default_array, config_base, highres_results, iteration=iteration\n",
    "                    )\n",
    "                    if np.isfinite(baseline_loss):\n",
    "                        self.baseline_loss_by_fidelity[fidelity_desc] = baseline_loss\n",
    "                        self.baseline_loss = baseline_loss\n",
    "                        # Store the results if this is the final fidelity\n",
    "                        if fidelity_desc == 'FULL (180d)':\n",
    "                            self.default_results = baseline_results\n",
    "                        print(Colors.cyan(f\"→ Baseline at {fidelity_desc}: {baseline_loss:.6f}\"))\n",
    "                    else:\n",
    "                        print(Colors.red(f\"→ Baseline evaluation failed at {fidelity_desc}\"))\n",
    "                \n",
    "                # CRITICAL: Re-evaluate current best parameters at new fidelity!\n",
    "                if self.best_params is not None:\n",
    "                    print(Colors.yellow(f\"\\n→ Re-evaluating BEST PARAMETERS at {fidelity_desc} fidelity...\"))\n",
    "                    print(Colors.yellow(f\"   Old best loss ({old_fidelity}): {self.best_loss:.6f}\"))\n",
    "                    \n",
    "                    best_loss_new_fidelity, _, _ = run_lowres_with_params(\n",
    "                        self.best_params, config_base, highres_results, iteration=iteration\n",
    "                    )\n",
    "                    \n",
    "                    if np.isfinite(best_loss_new_fidelity):\n",
    "                        old_best = self.best_loss\n",
    "                        self.best_loss = best_loss_new_fidelity\n",
    "                        print(Colors.yellow(f\"   New best loss ({fidelity_desc}): {best_loss_new_fidelity:.6f}\"))\n",
    "                        \n",
    "                        # Calculate change\n",
    "                        change_pct = (best_loss_new_fidelity - old_best) / old_best * 100\n",
    "                        if change_pct > 0:\n",
    "                            print(Colors.red(f\"   ⚠ Loss INCREASED by {change_pct:.1f}% at higher fidelity\"))\n",
    "                        else:\n",
    "                            print(Colors.green(f\"   ✓ Loss decreased by {-change_pct:.1f}% at higher fidelity\"))\n",
    "                        \n",
    "                        # Compare to new baseline\n",
    "                        if fidelity_desc in self.baseline_loss_by_fidelity:\n",
    "                            improvement = (self.baseline_loss_by_fidelity[fidelity_desc] - best_loss_new_fidelity) / \\\n",
    "                                        self.baseline_loss_by_fidelity[fidelity_desc] * 100\n",
    "                            print(Colors.cyan(f\"   → Improvement vs {fidelity_desc} baseline: {improvement:+.1f}%\"))\n",
    "                    else:\n",
    "                        print(Colors.red(f\"   ✗ Re-evaluation failed, keeping old best loss\"))\n",
    "                \n",
    "                print(Colors.red(f\"{'='*70}\\n\"))\n",
    "            \n",
    "            # Stagnation check\n",
    "            if self.iterations_without_improvement >= self.stagnation_threshold:\n",
    "                print(Colors.red(f\"\\n⚠ STAGNATION: {self.iterations_without_improvement} iterations w/o improvement\"))\n",
    "                print(Colors.yellow(\"→ Triggering exploration restart\"))\n",
    "                self.trigger_exploration_restart()\n",
    "            \n",
    "            # Fit GP\n",
    "            X_warped = np.array([warp_parameters(x) for x in self.X_samples])\n",
    "            y_array = np.array(self.y_samples)\n",
    "            valid_mask = np.isfinite(y_array)\n",
    "            n_valid = np.sum(valid_mask)\n",
    "            \n",
    "            print(f\"Valid samples: {Colors.cyan(str(n_valid))}/{len(y_array)}\")\n",
    "            \n",
    "            kappa = self.get_adaptive_kappa()\n",
    "            if kappa > 2.0:\n",
    "                print(Colors.yellow(f\"  ℹ Increased exploration: kappa = {kappa:.1f}\"))\n",
    "            \n",
    "            # Thompson sampling with some probability\n",
    "            use_thompson = np.random.rand() < self.use_thompson_sampling_prob\n",
    "            \n",
    "            if n_valid < 5:\n",
    "                print(Colors.yellow(\"  ⚠ Too few valid samples, random exploration\"))\n",
    "                next_params = unwarp_parameters(np.random.uniform(0, 1, N_PARAMS))\n",
    "            elif use_thompson:\n",
    "                print(Colors.cyan(\"  → Using Thompson sampling for exploration\"))\n",
    "                X_valid, y_valid = X_warped[valid_mask], y_array[valid_mask]\n",
    "                self.gp.fit(X_valid, y_valid)\n",
    "                \n",
    "                # Track parameter importance even with Thompson sampling\n",
    "                importance = self.gp.get_parameter_importance()\n",
    "                self.importance_history.append(importance)\n",
    "                \n",
    "                # Print top 3 most important parameters\n",
    "                sorted_indices = np.argsort(importance)[::-1][:3]\n",
    "                print(\"  Top 3 important parameters:\")\n",
    "                for rank, idx in enumerate(sorted_indices, 1):\n",
    "                    print(f\"    {rank}. {PARAM_NAMES[idx]}: {importance[idx]:.3f}\")\n",
    "                \n",
    "                tr_bounds = self.trust_region.get_trust_region_bounds()\n",
    "                thompson_sample = thompson_sampling(self.gp, tr_bounds, n_samples=1)[0]\n",
    "                next_params = unwarp_parameters(thompson_sample)\n",
    "            else:\n",
    "                X_valid, y_valid = X_warped[valid_mask], y_array[valid_mask]\n",
    "                print(\"  Fitting 8-model ensemble GP...\")\n",
    "                self.gp.fit(X_valid, y_valid)\n",
    "                \n",
    "                # Track parameter importance\n",
    "                importance = self.gp.get_parameter_importance()\n",
    "                self.importance_history.append(importance)\n",
    "                \n",
    "                # Print parameter importance (show relative values)\n",
    "                print(\"  Parameter importance (relative):\")\n",
    "                sorted_indices = np.argsort(importance)[::-1]  # Sort descending\n",
    "                for rank, idx in enumerate(sorted_indices, 1):\n",
    "                    name = PARAM_NAMES[idx]\n",
    "                    imp_val = importance[idx]\n",
    "                    if rank <= 3:\n",
    "                        imp_str = f\"{Colors.green('HIGH')}\"\n",
    "                    elif rank <= 5:\n",
    "                        imp_str = f\"{Colors.cyan('med')}\"\n",
    "                    else:\n",
    "                        imp_str = \"low\"\n",
    "                    print(f\"    {rank}. {name}: {imp_val:.3f} ({imp_str})\")\n",
    "                \n",
    "                # Update trust region\n",
    "                if self.best_params is not None:\n",
    "                    self.trust_region.best_center = warp_parameters(self.best_params)\n",
    "                \n",
    "                tr_bounds = self.trust_region.get_trust_region_bounds()\n",
    "                print(f\"  Trust region: {Colors.cyan(f'{self.trust_region.trust_radius:.2f}')}\")\n",
    "                \n",
    "                # Optimize acquisition\n",
    "                print(f\"  Optimizing acquisition (kappa={kappa:.1f})...\")\n",
    "                best_y = np.min(y_valid)\n",
    "                acq_fn = lambda X: hybrid_acquisition_with_penalization(\n",
    "                    X, self.gp, best_y, self.X_samples, xi=0.01, kappa=kappa, penalization_weight=0.3\n",
    "                )\n",
    "                \n",
    "                next_params_warped = optimize_acquisition_multistart(acq_fn, tr_bounds, n_starts=20, n_random=1000)\n",
    "                acq_val = acq_fn(next_params_warped.reshape(1, -1))[0]\n",
    "                print(f\"  Selected point (acq={Colors.cyan(f'{acq_val:.4f}')})\")\n",
    "                next_params = unwarp_parameters(next_params_warped)\n",
    "            \n",
    "            # Evaluate with adaptive fidelity\n",
    "            loss, results, detailed = run_lowres_with_params(\n",
    "                next_params, config_base, highres_results, iteration=iteration\n",
    "            )\n",
    "            self.X_samples.append(next_params)\n",
    "            self.y_samples.append(loss)\n",
    "            self.detailed_outputs.append(detailed)\n",
    "            \n",
    "            # Update best\n",
    "            new_best = False\n",
    "            if np.isfinite(loss) and loss < self.best_loss:\n",
    "                self.best_loss, self.best_params = loss, next_params.copy()\n",
    "                self.best_iteration, self.iterations_without_improvement = iteration, 0\n",
    "                self.best_params_original_iteration = iteration  # Track discovery iteration\n",
    "                new_best = True\n",
    "                # Compare to baseline at CURRENT fidelity\n",
    "                fidelity_baseline = self.baseline_loss_by_fidelity.get(self.current_fidelity, self.baseline_loss)\n",
    "                if fidelity_baseline:\n",
    "                    improvement = (fidelity_baseline - loss) / fidelity_baseline * 100\n",
    "                    print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')} ({improvement:+.1f}% vs baseline @ {self.current_fidelity})\"))\n",
    "                else:\n",
    "                    print(Colors.star(f\"NEW BEST: {Colors.green(f'{loss:.6f}')}\"))\n",
    "            \n",
    "            self.trust_region.update(new_best, warp_parameters(self.best_params) if new_best else None)\n",
    "            self.print_status()\n",
    "            self.save_progress()\n",
    "            \n",
    "            # Generate plots every 10 iterations\n",
    "            if (iteration + 1) % 10 == 0:\n",
    "                print(\"\\n  Generating visualization...\")\n",
    "                visualizer = OptimizationVisualizer(self)\n",
    "                visualizer.create_all_plots()\n",
    "        \n",
    "        # Final visualization\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GENERATING FINAL VISUALIZATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        visualizer = OptimizationVisualizer(self)\n",
    "        visualizer.create_all_plots()\n",
    "        \n",
    "        return self.get_best_params()\n",
    "    \n",
    "    def get_adaptive_kappa(self):\n",
    "        \"\"\"Adaptive kappa: higher when stuck\"\"\"\n",
    "        if self.iterations_without_improvement < 6:\n",
    "            return 2.0\n",
    "        elif self.iterations_without_improvement < 10:\n",
    "            return 3.0\n",
    "        return 4.0\n",
    "    \n",
    "    def trigger_exploration_restart(self):\n",
    "        \"\"\"Reset trust region and add random sample\"\"\"\n",
    "        self.trust_region.reset_for_exploration()\n",
    "        print(Colors.yellow(\"  → Random sample will be added next\"))\n",
    "        self.iterations_without_improvement = 0\n",
    "        print(Colors.green(\"  ✓ Restart complete\"))\n",
    "    \n",
    "    def print_status(self):\n",
    "        \"\"\"Print status with fidelity-aware baseline comparison\"\"\"\n",
    "        n_valid = np.sum(np.isfinite(self.y_samples))\n",
    "        n_failed = len(self.y_samples) - n_valid\n",
    "        print(f\"\\n{Colors.bold('Status:')}\")\n",
    "        print(f\"  Valid: {Colors.cyan(str(n_valid))}/{len(self.y_samples)}\")\n",
    "        print(f\"  Failed: {Colors.yellow(str(n_failed))}\")\n",
    "        \n",
    "        # Show current fidelity\n",
    "        if self.current_fidelity:\n",
    "            print(f\"  Current fidelity: {Colors.cyan(self.current_fidelity)}\")\n",
    "        \n",
    "        # Show baselines for each fidelity\n",
    "        if self.baseline_loss_by_fidelity:\n",
    "            print(f\"  Baselines by fidelity:\")\n",
    "            for fidelity, baseline in sorted(self.baseline_loss_by_fidelity.items()):\n",
    "                print(f\"    {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "        \n",
    "        # Compare best to baseline at current fidelity\n",
    "        if self.best_params_original_iteration is not None:\n",
    "            print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{self.best_loss:.6f}')} \" +\n",
    "                  Colors.cyan(f'(discovered at iteration {self.best_params_original_iteration + 1})'))\n",
    "        else:\n",
    "            print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{self.best_loss:.6f}')} \" +\n",
    "                  Colors.cyan(f'(iteration {self.best_iteration + 1})'))\n",
    "        \n",
    "        if self.current_fidelity and self.current_fidelity in self.baseline_loss_by_fidelity:\n",
    "            fidelity_baseline = self.baseline_loss_by_fidelity[self.current_fidelity]\n",
    "            improvement = (fidelity_baseline - self.best_loss) / fidelity_baseline * 100\n",
    "            print(f\"    → vs {self.current_fidelity} baseline: {Colors.green(f'{improvement:+.1f}%')}\")\n",
    "        \n",
    "        stag_str = f\"{self.iterations_without_improvement}/{self.stagnation_threshold}\"\n",
    "        stag_str = Colors.yellow(stag_str) if self.iterations_without_improvement >= 10 else Colors.cyan(stag_str)\n",
    "        print(f\"  Iterations w/o improvement: {stag_str}\")\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"No valid parameters found!\")\n",
    "        return {PARAM_NAMES[i]: float(self.best_params[i]) for i in range(N_PARAMS)}\n",
    "    \n",
    "    def save_progress(self, filename='enhanced_gp_progress.pkl'):\n",
    "        data = {\n",
    "            'X_samples': self.X_samples, 'y_samples': self.y_samples, 'detailed_outputs': self.detailed_outputs,\n",
    "            'best_loss': self.best_loss, 'best_params': self.best_params, 'best_iteration': self.best_iteration,\n",
    "            'best_params_original_iteration': self.best_params_original_iteration,\n",
    "            'iteration': self.iteration, 'iterations_without_improvement': self.iterations_without_improvement,\n",
    "            'trust_region_state': {'radius': self.trust_region.trust_radius, 'center': self.trust_region.best_center,\n",
    "                                  'success_count': self.trust_region.success_count, 'fail_count': self.trust_region.fail_count},\n",
    "            'importance_history': self.importance_history,\n",
    "            'baseline_loss': self.baseline_loss,\n",
    "            'baseline_loss_by_fidelity': self.baseline_loss_by_fidelity,\n",
    "            'current_fidelity': self.current_fidelity,\n",
    "            'default_results': self.default_results,\n",
    "            'random_seed': self.random_seed\n",
    "        }\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"  ✓ Progress saved\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_progress(cls, filename='enhanced_gp_progress.pkl'):\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        optimizer = cls(random_seed=data.get('random_seed', 42))\n",
    "        optimizer.X_samples, optimizer.y_samples = data['X_samples'], data['y_samples']\n",
    "        optimizer.detailed_outputs = data['detailed_outputs']\n",
    "        optimizer.best_loss, optimizer.best_params = data['best_loss'], data['best_params']\n",
    "        optimizer.best_iteration, optimizer.iteration = data['best_iteration'], data['iteration']\n",
    "        optimizer.best_params_original_iteration = data.get('best_params_original_iteration', optimizer.best_iteration)\n",
    "        optimizer.iterations_without_improvement = data.get('iterations_without_improvement', 0)\n",
    "        optimizer.importance_history = data.get('importance_history', [])\n",
    "        optimizer.baseline_loss = data.get('baseline_loss', None)\n",
    "        optimizer.baseline_loss_by_fidelity = data.get('baseline_loss_by_fidelity', {})\n",
    "        optimizer.current_fidelity = data.get('current_fidelity', None)\n",
    "        optimizer.default_results = data.get('default_results', None)\n",
    "        \n",
    "        if 'trust_region_state' in data:\n",
    "            tr = data['trust_region_state']\n",
    "            optimizer.trust_region.trust_radius, optimizer.trust_region.best_center = tr['radius'], tr['center']\n",
    "            optimizer.trust_region.success_count, optimizer.trust_region.fail_count = tr['success_count'], tr['fail_count']\n",
    "        \n",
    "        print(f\"✓ Loaded checkpoint (seed={optimizer.random_seed}):\")\n",
    "        print(f\"  Iterations: {len(optimizer.X_samples)}\")\n",
    "        n_valid = np.sum(np.isfinite(optimizer.y_samples))\n",
    "        print(f\"  Valid: {Colors.cyan(str(n_valid))}/{len(optimizer.y_samples)}\")\n",
    "        \n",
    "        if optimizer.baseline_loss_by_fidelity:\n",
    "            print(f\"  Baselines by fidelity:\")\n",
    "            for fidelity, baseline in sorted(optimizer.baseline_loss_by_fidelity.items()):\n",
    "                print(f\"    {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "        \n",
    "        print(f\"  {Colors.bold('Best loss:')} {Colors.green(f'{optimizer.best_loss:.6f}')} \" +\n",
    "              Colors.cyan(f'(discovered at iteration {optimizer.best_params_original_iteration + 1})'))\n",
    "        \n",
    "        if optimizer.current_fidelity and optimizer.current_fidelity in optimizer.baseline_loss_by_fidelity:\n",
    "            fidelity_baseline = optimizer.baseline_loss_by_fidelity[optimizer.current_fidelity]\n",
    "            improvement = (fidelity_baseline - optimizer.best_loss) / fidelity_baseline * 100\n",
    "            print(f\"    → vs {optimizer.current_fidelity}: {Colors.green(f'{improvement:+.1f}%')}\")\n",
    "        \n",
    "        return optimizer\n",
    "\n",
    "# Main function with 3-way comparison\n",
    "def main(checkpoint_file='enhanced_gp_progress.pkl', max_iterations=100, random_seed=42):\n",
    "    \"\"\"\n",
    "    Main optimization routine with 3-way comparison\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_file: Path to checkpoint file for resuming\n",
    "        max_iterations: Maximum number of optimization iterations\n",
    "        random_seed: Random seed for reproducibility (affects initial sampling and exploration)\n",
    "    \"\"\"\n",
    "    if not os.path.exists('highres_results.pkl'):\n",
    "        print(\"\\n✗ Error: highres_results.pkl not found!\")\n",
    "        return\n",
    "    \n",
    "    with open('highres_results.pkl', 'rb') as f:\n",
    "        highres_results = pickle.load(f)\n",
    "    print(f\"\\n✓ Loaded high-res: {highres_results['config']['nx']}x{highres_results['config']['ny']}\")\n",
    "    \n",
    "    from main_comparison import config_lowres\n",
    "    config_base = config_lowres.copy()\n",
    "    \n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"\\n✓ Checkpoint found\")\n",
    "        optimizer = EnhancedGPOptimizer.load_progress(checkpoint_file)\n",
    "    else:\n",
    "        print(f\"\\n✓ Starting new optimization (seed={random_seed})\")\n",
    "        print(f\"  Initial samples: {4 * N_PARAMS} (4x parameters)\")\n",
    "        print(f\"  Fast phase: {2 * N_PARAMS} iterations at 30-day fidelity\")\n",
    "        print(f\"  Full phase: {2 * N_PARAMS}+ iterations at 180-day fidelity\")\n",
    "        optimizer = EnhancedGPOptimizer(random_seed=random_seed)  # Will use 4*N_PARAMS initial samples\n",
    "    \n",
    "    best_params = optimizer.optimize(config_base, highres_results, max_iterations)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTIMIZATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    n_valid = np.sum(np.isfinite(optimizer.y_samples))\n",
    "    n_failed = len(optimizer.y_samples) - n_valid\n",
    "    print(f\"\\nTotal iterations: {len(optimizer.y_samples)}\")\n",
    "    print(f\"  Valid: {Colors.cyan(str(n_valid))}\")\n",
    "    print(f\"  Failed: {Colors.yellow(str(n_failed))}\")\n",
    "    \n",
    "    # Show all baselines\n",
    "    if optimizer.baseline_loss_by_fidelity:\n",
    "        print(f\"\\nBaselines by fidelity:\")\n",
    "        for fidelity, baseline in sorted(optimizer.baseline_loss_by_fidelity.items()):\n",
    "            print(f\"  {fidelity}: {Colors.cyan(f'{baseline:.6f}')}\")\n",
    "    \n",
    "    # Final comparison at FULL fidelity\n",
    "    final_baseline = optimizer.baseline_loss_by_fidelity.get('FULL (180d)', optimizer.baseline_loss)\n",
    "    if final_baseline:\n",
    "        improvement = (final_baseline - optimizer.best_loss) / final_baseline * 100\n",
    "        print(f\"\\n{Colors.bold('Final Comparison at FULL (180d) Fidelity:')}\")\n",
    "        print(f\"  Baseline (default): {Colors.cyan(f'{final_baseline:.6f}')}\")\n",
    "        print(f\"  Best loss: {Colors.green(f'{optimizer.best_loss:.6f}')} \" +\n",
    "              Colors.green(f'[{improvement:+.1f}% improvement]'))\n",
    "        \n",
    "        # Show discovery info\n",
    "        if optimizer.best_params_original_iteration is not None:\n",
    "            print(f\"  Best parameters discovered at: iteration {optimizer.best_params_original_iteration + 1}\")\n",
    "            n_fast_phase_end = (4 * N_PARAMS) + (2 * N_PARAMS)\n",
    "            if optimizer.best_params_original_iteration < n_fast_phase_end:\n",
    "                print(Colors.yellow(f\"    (during 30-day fast exploration phase)\"))\n",
    "                print(Colors.cyan(f\"    Loss was re-evaluated at full 180-day fidelity\"))\n",
    "            else:\n",
    "                print(Colors.cyan(f\"    (during 180-day full precision phase)\"))\n",
    "    else:\n",
    "        print(f\"\\n{Colors.bold('Best loss:')} {Colors.green(f'{optimizer.best_loss:.6f}')}\")\n",
    "        print(Colors.yellow(\"  Note: No full-fidelity baseline available\"))\n",
    "    \n",
    "    print(f\"\\n{Colors.bold('Best parameters:')}\")\n",
    "    for name, val in best_params.items():\n",
    "        default_val = DEFAULT_PARAMS[name]\n",
    "        change = (val - default_val) / default_val * 100 if default_val != 0 else 0\n",
    "        print(f\"  {name}: {Colors.cyan(f'{val:.6e}')} (default: {default_val:.6e}, {change:+.1f}%)\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('enhanced_gp_optimal_params.pkl', 'wb') as f:\n",
    "        pickle.dump(best_params, f)\n",
    "    with open('enhanced_gp_optimal_config.txt', 'w') as f:\n",
    "        f.write(\"'subgrid_params': {\\n\")\n",
    "        for name, val in best_params.items():\n",
    "            f.write(f\"    '{name}': {val:.6e},\\n\")\n",
    "        f.write(\"}\\n\")\n",
    "    \n",
    "    print(\"\\n✓ Saved: enhanced_gp_optimal_params.pkl\")\n",
    "    print(\"✓ Saved: enhanced_gp_optimal_config.txt\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NOTE: DYNAMIC 2-LEVEL MULTI-FIDELITY WITH ADAPTIVE BASELINES\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"The optimizer uses a dynamic 2-level fidelity strategy (based on {N_PARAMS} params):\")\n",
    "    print(f\"  Initial phase (iterations 0-{4*N_PARAMS-1}):  30-day runs at low fidelity\")\n",
    "    print(f\"    - {4*N_PARAMS} samples for good initial coverage\")\n",
    "    print(f\"    - Compares entire simulation (days 0-30)\")\n",
    "    print(f\"    - Baseline tracked at 30-day fidelity\")\n",
    "    print(f\"  Fast phase (iterations {4*N_PARAMS}-{4*N_PARAMS + 2*N_PARAMS - 1}):   30-day BO runs\")\n",
    "    print(f\"    - {2*N_PARAMS} iterations of fast exploration\")\n",
    "    print(f\"    - ~6x speedup vs full fidelity\")\n",
    "    print(f\"  Full phase (iterations {4*N_PARAMS + 2*N_PARAMS}+):   180-day BO runs\")\n",
    "    print(f\"    - {2*N_PARAMS}+ iterations at full precision\")\n",
    "    print(\"    - Compares last 30 days (equilibrated state)\")\n",
    "    print(\"    - Baseline tracked at 180-day fidelity\")\n",
    "    print(\"\\nThis ensures:\")\n",
    "    print(\"  ✓ Good initial parameter space coverage\")\n",
    "    print(\"  ✓ Fast exploration in early BO iterations\")\n",
    "    print(\"  ✓ Fair apples-to-apples comparisons at each fidelity\")\n",
    "    print(\"  ✓ Final results use full 180-day simulations\")\n",
    "    print(\"\\nSeed robustness:\")\n",
    "    print(f\"  ✓ Random seed used: {optimizer.random_seed}\")\n",
    "    print(\"  ✓ Multiple complementary seeds used internally\")\n",
    "    print(\"  ✓ Small perturbations added to reduce grid artifacts\")\n",
    "    print(\"  ℹ Different seeds may find best at different iterations\")\n",
    "    print(\"    but final performance should be similar (~5-10% variation)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Run final simulation with optimized parameters for 3-way comparison\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RUNNING FINAL COMPARISON SIMULATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Ensure we have full-fidelity baseline (180 days)\n",
    "    if 'FULL (180d)' not in optimizer.baseline_loss_by_fidelity or optimizer.default_results is None:\n",
    "        print(\"\\nRunning default parameters at FULL fidelity (180 days)...\")\n",
    "        config_default = config_base.copy()\n",
    "        config_default['subgrid_params'] = DEFAULT_PARAMS\n",
    "        from main_comparison import run_simulation\n",
    "        optimizer.default_results = run_simulation(config_default, sim_days=180, save_interval_hours=12)\n",
    "        \n",
    "        # Compute baseline loss at full fidelity\n",
    "        baseline_loss_full, _ = compute_loss(optimizer.default_results, highres_results, \n",
    "                                             n_days_avg=30, return_fields=False, adaptive_window=False)\n",
    "        optimizer.baseline_loss_by_fidelity['FULL (180d)'] = baseline_loss_full\n",
    "        optimizer.baseline_loss = baseline_loss_full\n",
    "        print(f\"  ✓ Default simulation complete - Loss: {baseline_loss_full:.6f}\")\n",
    "    else:\n",
    "        print(\"\\n✓ Using cached default results at FULL fidelity\")\n",
    "    \n",
    "    # Run optimized parameters simulation (full 180 days for final comparison)\n",
    "    print(\"\\nRunning optimized parameters simulation (full 180 days)...\")\n",
    "    config_optimized = config_base.copy()\n",
    "    config_optimized['subgrid_params'] = best_params\n",
    "    from main_comparison import run_simulation\n",
    "    optimized_results = run_simulation(config_optimized, sim_days=180, save_interval_hours=12)\n",
    "    print(f\"  ✓ Optimized simulation complete\")\n",
    "    \n",
    "    # Create 3-way comparison\n",
    "    create_three_way_comparison(highres_results, optimizer.default_results, optimized_results)\n",
    "    \n",
    "    print(\"\\n✓ Saved: optimization_analysis.png\")\n",
    "    print(\"✓ Saved: parameter_sensitivity.png\")\n",
    "    print(\"✓ Saved: computational_efficiency.png\")\n",
    "    print(\"✓ Saved: three_way_comparison.png\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"VISUALIZATION GUIDE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"1. optimization_analysis.png\")\n",
    "    print(\"   → Loss evolution, parameter trajectories, trust region\")\n",
    "    print(\"   → Shows HOW the optimization progressed\")\n",
    "    print(\"\")\n",
    "    print(\"2. parameter_sensitivity.png\")\n",
    "    print(\"   → Correlation analysis, variance explained, ranges explored\")\n",
    "    print(\"   → Shows WHICH parameters matter most\")\n",
    "    print(\"   → Red = increasing parameter worsens loss\")\n",
    "    print(\"   → Green = increasing parameter improves loss\")\n",
    "    print(\"\")\n",
    "    print(\"3. computational_efficiency.png\")\n",
    "    print(\"   → Cost vs improvement, phase breakdown, sample efficiency\")\n",
    "    print(\"   → Shows HOW EFFICIENTLY we found improvements\")\n",
    "    print(\"\")\n",
    "    print(\"4. three_way_comparison.png\")\n",
    "    print(\"   → Spatial fields: high-res vs default vs optimized\")\n",
    "    print(\"   → Shows FINAL RESULTS quality\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return optimizer, best_params\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the random_seed parameter to test different initializations\n",
    "    # The optimizer uses multiple complementary seeds internally for robustness\n",
    "    # n_initial_samples is now dynamic: 4 * N_PARAMS (will be 24 for 6 parameters)\n",
    "    optimizer, best_params = main(max_iterations=50, random_seed=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89ab86-a746-434c-87ed-74b162435abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qg)",
   "language": "python",
   "name": "qg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
